# ========================================================
# PLAY 1: Infrastructure - Deploy K8s (Run:ai Ready)
# åŒ…å«: K8s 1.31, StorageClass, Ingress, MetalLB, TLS Secret
# ========================================================
- name: 1. Infrastructure - Deploy Modern Charmed Kubernetes
  hosts: maasjuju
  gather_facts: yes
  vars:
    test_model: "k8s-cluster-runai"
    k8s_channel: "1.31/stable"
    bundle_path: "{{ ansible_user_dir }}/charmed-k8s-runai.yaml"
    
    # [å·²ä¿®æ­£] MetalLB IP è¨­å®š (é…åˆä½ çš„ç¶²æ®µ 192.168.1.x)
    # æˆ‘å€‘é ç•™ .200 åˆ° .210 çµ¦ Run:ai çš„ Web UI ä½¿ç”¨
    metallb_ip_range: "192.168.1.200-192.168.1.210"

  tasks:
    # --- 1. Environment Cleanup ---
    - name: 1.0 Force cleanup old model
      command: "juju destroy-model {{ test_model }} --no-prompt --force --destroy-storage"
      register: destroy_result
      failed_when: 
        - destroy_result.rc != 0 
        - '"not found" not in destroy_result.stderr'
      ignore_errors: yes

    - name: 1.1 Wait for model release
      pause:
        seconds: 15

    - name: 1.2 Create new Juju Model
      shell: juju add-model {{ test_model }}

    # --- 2. Bundle & Deploy (å« MetalLB & Ingress) ---
    - name: 2.1 Generate Local Bundle
      copy:
        dest: "{{ bundle_path }}"
        mode: '0644'
        content: |
          description: Modern K8s Cluster (Run:ai Ready)
          base: ubuntu@22.04
          
          machines:
            "0":
              constraints: tags=runai
            "1":
              constraints: tags=runai
            "2":
              constraints: tags=runai
          
          applications:
            # K8s æ ¸å¿ƒçµ„ä»¶
            easyrsa:
              charm: easyrsa
              channel: latest/stable
              num_units: 1
              to: ["0"]
            etcd:
              charm: etcd
              channel: latest/stable
              num_units: 1
              to: ["0"]
            
            kubernetes-control-plane:
              charm: kubernetes-control-plane
              channel: {{ k8s_channel }}
              num_units: 1
              to: ["0"]
              options:
                allow-privileged: "true"
            
            kubernetes-worker:
              charm: kubernetes-worker
              channel: {{ k8s_channel }}
              num_units: 2
              to: ["1", "2"]
              expose: true
            
            calico:
              charm: calico
              channel: latest/stable
            containerd:
              charm: containerd
              channel: latest/stable
            
            # --- Run:ai å¿…è¦çµ„ä»¶ ---
            
            # 1. Metrics Server (Run:ai æ’ç¨‹å™¨éœ€è¦)
            kubernetes-metrics-server:
              charm: kubernetes-metrics-server
              channel: stable
              trust: true
            
            # 2. Ingress Controller (Web UI å…¥å£)
            ingress-nginx-k8s:
              charm: ingress-nginx-k8s
              channel: stable
              trust: true
            
            # 3. MetalLB (æä¾›å¤–éƒ¨ IP 192.168.1.2xx çµ¦ Ingress)
            metallb:
              charm: metallb
              channel: stable
              options:
                iprange: "{{ metallb_ip_range }}"

          relations:
            # K8s æ ¸å¿ƒé€£æ¥
            - ["kubernetes-control-plane:kube-control", "kubernetes-worker:kube-control"]
            - ["kubernetes-control-plane:certificates", "easyrsa:client"]
            - ["etcd:certificates", "easyrsa:client"]
            - ["kubernetes-control-plane:etcd", "etcd:db"]
            - ["kubernetes-worker:certificates", "easyrsa:client"]
            - ["calico:etcd", "etcd:db"]
            - ["calico:cni", "kubernetes-control-plane:cni"]
            - ["calico:cni", "kubernetes-worker:cni"]
            - ["containerd:containerd", "kubernetes-worker:container-runtime"]
            - ["containerd:containerd", "kubernetes-control-plane:container-runtime"]
            
            # ç›£æ§èˆ‡ Ingress é€£æ¥
            - ["kubernetes-metrics-server:kube-control", "kubernetes-control-plane:kube-control"]
            - ["ingress-nginx-k8s:kube-control", "kubernetes-control-plane:kube-control"]

    - name: 2.2 Deploy Bundle
      shell: |
        juju deploy {{ bundle_path }} --model {{ test_model }} --trust
      register: deploy_out
      until: deploy_out.rc == 0
      retries: 3
      delay: 10

    # --- 3. Infra Monitoring (Wait Loop) ---
    - name: 3.1 Wait for Juju Apps Active
      shell: |
        echo "â³ Monitoring Juju status (Timeout: 45min)..."
        for i in {1..540}; do
          JSON=$(juju status --model {{ test_model }} --format json)
          # æª¢æŸ¥ä¸»è¦çµ„ä»¶
          CP=$(echo "$JSON" | jq -r '.applications["kubernetes-control-plane"]["application-status"].current // "unknown"')
          WK=$(echo "$JSON" | jq -r '.applications["kubernetes-worker"]["application-status"].current // "unknown"')
          
          if [[ "$CP" == "active" && "$WK" == "active" ]]; then
            echo "âœ… Core Juju Apps are Active!"
            exit 0
          fi
          if (( i % 12 == 0 )); then echo "   [$i/540] Waiting... (CP=$CP, WK=$WK)"; fi
          sleep 5
        done
        echo "âŒ Timeout waiting for Juju apps."
        exit 1
      args:
        executable: /bin/bash
      register: juju_wait
      changed_when: false

    # --- 4. Storage Class Setup ---
    - name: 4.1 Install Local Path Provisioner
      shell: |
        juju ssh --model {{ test_model }} 0 -- \
        "kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.30/deploy/local-path-storage.yaml"
      register: install_sc
      changed_when: "'created' in install_sc.stdout or 'configured' in install_sc.stdout"

    - name: 4.2 Set Default StorageClass
      shell: |
        juju ssh --model {{ test_model }} 0 -- \
        "kubectl patch storageclass local-path -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}'"
      register: patch_sc
      changed_when: "'patched' in patch_sc.stdout"

    # --- 5. Run:ai Specific Requirements (TLS & Namespace) ---
    - name: 5.1 Generate TLS Secret for Run:ai
      shell: |
        juju ssh --model {{ test_model }} 0 -- bash -s <<'EOS'
        set -e
        # 1. å»ºç«‹ Run:ai Backend Namespace (æ–°ç‰ˆå¼·åˆ¶è¦æ±‚)
        kubectl create namespace runai-backend --dry-run=client -o yaml | kubectl apply -f -
        
        # 2. ç”¢ç”Ÿè‡ªç°½æ†‘è­‰ (Self-Signed Cert)
        # Run:ai Control Plane å•Ÿå‹•æ™‚éœ€è¦æ›è¼‰é€™å€‹ Secret
        # é€™è£¡è¨­å®š CN=runai.lab.localï¼Œè«‹è¨˜å¾—ä¹‹å¾Œè¦åœ¨ä½ çš„ Mac è¨­å®š hosts
        openssl req -x509 -newkey rsa:4096 -sha256 -days 3650 -nodes \
          -keyout private.pem -out fullchain.pem \
          -subj "/CN=runai.lab.local"
        
        # 3. å»ºç«‹ Secret (å¦‚æœä¸å­˜åœ¨)
        if ! kubectl get secret runai-backend-tls -n runai-backend; then
            kubectl create secret tls runai-backend-tls -n runai-backend \
              --cert=fullchain.pem \
              --key=private.pem
            echo "âœ… Created TLS Secret: runai-backend-tls"
        else
            echo "â„¹ï¸ TLS Secret already exists."
        fi
        
        # æ¸…ç†æš«å­˜æª”
        rm -f private.pem fullchain.pem
        EOS
      register: tls_setup

    # --- 6. Final K8s Health Check ---
    - name: 6.1 Wait for K8s Nodes & System Pods
      shell: |
        juju ssh --model {{ test_model }} 0 -- bash -s <<'EOS'
        set -e
        echo "â³ Waiting for K8s Nodes & System Pods (Timeout: 15min)..."
        
        # ç­‰å¾… 3 å€‹ç¯€é» Ready
        echo "   -> Waiting for 3 nodes to be Ready..."
        for i in {1..60}; do
           READY_COUNT=$(kubectl get nodes --no-headers | grep -w "Ready" | wc -l)
           if [ "$READY_COUNT" -ge 3 ]; then
               echo "   âœ… Found $READY_COUNT Ready nodes."
               break
           fi
           sleep 10
        done
        kubectl wait --for=condition=Ready node --all --timeout=600s

        # ç­‰å¾…ç³»çµ± Pods
        echo "   -> Waiting for System Pods..."
        kubectl -n kube-system wait pod -l k8s-app=calico-node --for=condition=Ready --timeout=600s
        # ç¢ºä¿ Ingress Controller å–å¾— LoadBalancer IP
        echo "   -> Waiting for Ingress Controller External IP..."
        sleep 20 # çµ¦ MetalLB ä¸€é»æ™‚é–“åæ‡‰
        kubectl -n ingress-nginx wait deployment/ingress-nginx-controller --for=condition=Available --timeout=300s
        
        # å–å¾—åˆ†é…åˆ°çš„ IP
        LB_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
        echo "---------------------------------------------------------"
        echo "âœ… K8s Infrastructure is Ready!"
        echo "ğŸ”‘ Ingress IP Assigned: $LB_IP"
        echo "ğŸ“ ACTION: Please add '$LB_IP runai.lab.local' to your /etc/hosts"
        echo "---------------------------------------------------------"
        EOS
      changed_when: false
