# ====================================================
    # 3. è‡ªå‹•å¯«å…¥æ¸¬è©¦èˆ‡ç›£æ§è…³æœ¬
    # ====================================================
    
    # 3.1 éƒ¨ç½² Burn GPU (å«ç›£æ§çš„ç‡’æ©Ÿè…³æœ¬)
    - name: 3.1 éƒ¨ç½² burn_gpu.py (å£“åŠ›æ¸¬è©¦ + å„€è¡¨æ¿)
      shell: |
        juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }} "
          cat <<EOF > burn_gpu.py
          import torch
          import time
          import os
          import sys

          # 1. æª¢æŸ¥ GPU
          if not torch.cuda.is_available():
              print('âŒ Error: No GPU found!')
              sys.exit(1)

          device = torch.device('cuda')
          try:
              name = torch.cuda.get_device_name(0)
          except:
              name = 'Unknown Device'

          print(f'âœ… Dedicated GPU: {name}')
          print('ğŸ”¥ Starting Stress Test... Press [Ctrl+C] to STOP! ğŸ”¥')
          print('-' * 80)

          # 2. æº–å‚™å¤§çŸ©é™£ (10000x10000)
          N = 10000
          x = torch.randn(N, N, device=device)
          y = torch.randn(N, N, device=device)

          try:
              while True:
                  # --- éšæ®µ A: ç”¢ç”Ÿç†±é‡ ---
                  for _ in range(10):
                      z = torch.mm(x, y)
                  
                  # --- éšæ®µ B: ç›£æ§æ•¸æ“š ---
                  cmd = 'nvidia-smi --query-gpu=temperature.gpu,fan.speed,utilization.gpu,power.draw --format=csv,noheader,nounits'
                  try:
                      output = os.popen(cmd).read().strip()
                      # ç›¸å®¹æ€§è™•ç†: æœ‰äº›é©…å‹•è¼¸å‡ºé€—è™Ÿå¾Œæ²’æœ‰ç©ºæ ¼
                      parts = output.split(',')
                      if len(parts) >= 4:
                          # å»é™¤ç©ºç™½
                          temp = parts[0].strip()
                          fan = parts[1].strip()
                          util = parts[2].strip()
                          power = parts[3].strip()
                      else:
                          raise ValueError
                  except:
                      temp = fan = util = power = 'N/A'

                  # --- éšæ®µ C: é¡¯ç¤ºè³‡è¨Š ---
                  sys.stdout.write(f'\rğŸŒ¡ï¸  Temp: {temp:>3}Â°C | ğŸŒªï¸ Fan: {fan:>3}% | ğŸ“Š Load: {util:>3}% | âš¡ Power: {power:>6}W | Status: BURNING... ')
                  sys.stdout.flush()
                  
                  time.sleep(0.5)

          except KeyboardInterrupt:
              print('\n\nğŸ›‘ Test Stopped by User. Cooling down...')
              del x, y, z
              torch.cuda.empty_cache()
          EOF
        "

    # 3.2 éƒ¨ç½² Watch GPU (ç´”ç›£æ§è…³æœ¬)
    - name: 3.2 éƒ¨ç½² watch_gpu.py (ç´”ç›£æ§ä¸ç‡’æ©Ÿ)
      shell: |
        juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }} "
          cat <<EOF > watch_gpu.py
          import time
          import os
          import sys

          print('ğŸ” GPU Monitor Started... Press [Ctrl+C] to STOP!')
          print('-' * 60)

          try:
              while True:
                  # é€é nvidia-smi æŠ“å–æ•¸æ“š
                  cmd = 'nvidia-smi --query-gpu=temperature.gpu,fan.speed,utilization.gpu,power.draw --format=csv,noheader,nounits'
                  output = os.popen(cmd).read().strip()
                  
                  try:
                      # è§£ææ•¸æ“š (è™•ç†å¯èƒ½çš„æ ¼å¼å·®ç•°)
                      parts = output.split(',')
                      if len(parts) >= 4:
                          temp = parts[0].strip()
                          fan = parts[1].strip()
                          util = parts[2].strip()
                          power = parts[3].strip()
                      else:
                          temp = fan = util = power = 'N/A'
                  except:
                      temp = fan = util = power = 'N/A'

                  # é¡¯ç¤ºè³‡è¨Š
                  sys.stdout.write(f'\rğŸŒ¡ï¸  Temp: {temp}Â°C | ğŸŒªï¸ Fan: {fan}% | ğŸ“Š Load: {util}% | âš¡ Power: {power}W    ')
                  sys.stdout.flush()
                  
                  time.sleep(1)

          except KeyboardInterrupt:
              print('\n\nğŸ›‘ Monitoring Stopped.')
          EOF
        "

    - name: ğŸš€ å®Œæˆæç¤º
      debug:
        msg: 
          - "ç’°å¢ƒéƒ¨ç½²å®Œç•¢ï¼è«‹ç™»å…¥ Worker: juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }}"
          - "1. åŸ·è¡Œç‡’æ©Ÿæ¸¬è©¦: ./gpu-test-env/bin/python burn_gpu.py"
          - "2. åƒ…åŸ·è¡Œç›£æ§:   ./gpu-test-env/bin/python watch_gpu.py"
