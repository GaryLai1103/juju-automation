- name: éƒ¨ç½² PyTorch GPU æ¸¬è©¦ç’°å¢ƒ (å«æ’ç¨‹æ¸¬è©¦å·¥å…·)
  hosts: maasjuju
  gather_facts: no
  vars:
    # é€™æ˜¯é è¨­å€¼ï¼Œå¯¦éš›æœƒè¢« AWX Survey è¦†è“‹
    slurm_model: "hpc-lab"
    worker_tag: "slurm-node"

  tasks:
    # ====================================================
    # 1. è‡ªå‹•åµæ¸¬ GPU Worker çš„ ID
    # ====================================================
    - name: 1. åµæ¸¬ GPU Worker ID
      shell: |
        STATUS=$(juju machines -m {{ slurm_model }} --format json)
        WORKER_ID=$(echo $STATUS | jq -r '.machines | to_entries[] | select(.value.constraints | contains("tags={{ worker_tag }}")) | .key' | head -n 1)
        if [ -z "$WORKER_ID" ]; then echo "1"; else echo "$WORKER_ID"; fi
      register: worker_id_result
      changed_when: false

    - name: 1.1 é¡¯ç¤ºåµæ¸¬åˆ°çš„ Worker ID
      debug:
        msg: "å³å°‡éƒ¨ç½²åˆ° Model: {{ slurm_model }}, Machine ID: {{ worker_id_result.stdout }}"

    # ====================================================
    # 2. é ç«¯å®‰è£ Python ç’°å¢ƒèˆ‡ PyTorch
    # ====================================================
    - name: 2. å®‰è£ venv ä¸¦å»ºç«‹ PyTorch ç’°å¢ƒ
      shell: |
        juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }} "
          echo 'ğŸ“¦ Updating apt...'
          sudo apt-get update -qq
          sudo apt-get install -y python3-venv python3-pip

          if [ ! -d 'gpu-test-env' ]; then
            echo 'ğŸ“‚ Creating virtual environment...'
            python3 -m venv gpu-test-env
          fi

          echo 'ğŸ”¥ Installing PyTorch (CUDA 12.1)...'
          ./gpu-test-env/bin/pip install --upgrade pip
          ./gpu-test-env/bin/pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
        "
      async: 1800
      poll: 10

    # ====================================================
    # 3. è‡ªå‹•å¯«å…¥æ¸¬è©¦è…³æœ¬ (å…± 3 å€‹)
    # ====================================================

    # 3.1 éƒ¨ç½² Burn GPU (ç„¡é™è¿´åœˆå£“åŠ›æ¸¬è©¦)
    - name: 3.1 éƒ¨ç½² burn_gpu.py (ç„¡é™ç‡’æ©Ÿ + å„€è¡¨æ¿)
      shell: |
        juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }} "
        cat << 'EOF' > burn_gpu.py
        import torch
        import time
        import os
        import sys

        if not torch.cuda.is_available():
            print('âŒ Error: No GPU found!')
            sys.exit(1)

        device = torch.device('cuda')
        try:
            name = torch.cuda.get_device_name(0)
        except:
            name = 'Unknown Device'

        print(f'âœ… Dedicated GPU: {name}')
        print('ğŸ”¥ Starting Infinite Stress Test... Press [Ctrl+C] to STOP! ğŸ”¥')
        print('-' * 80)

        N = 10000
        x = torch.randn(N, N, device=device)
        y = torch.randn(N, N, device=device)

        try:
            while True:
                for _ in range(10):
                    z = torch.mm(x, y)
                
                cmd = 'nvidia-smi --query-gpu=temperature.gpu,fan.speed,utilization.gpu,power.draw --format=csv,noheader,nounits'
                try:
                    output = os.popen(cmd).read().strip()
                    parts = output.split(',')
                    if len(parts) >= 4:
                        temp, fan, util, power = [p.strip() for p in parts]
                    else:
                        raise ValueError
                except:
                    temp = fan = util = power = 'N/A'

                sys.stdout.write(f'\rğŸŒ¡ï¸  Temp: {temp:>3}Â°C | ğŸŒªï¸ Fan: {fan:>3}% | ğŸ“Š Load: {util:>3}% | âš¡ Power: {power:>6}W | Status: BURNING... ')
                sys.stdout.flush()
                time.sleep(0.5)

        except KeyboardInterrupt:
            print('\n\nğŸ›‘ Test Stopped by User. Cooling down...')
        EOF
        "

    # 3.2 éƒ¨ç½² Watch GPU (ç´”ç›£æ§)
    - name: 3.2 éƒ¨ç½² watch_gpu.py (ç´”ç›£æ§)
      shell: |
        juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }} "
        cat << 'EOF' > watch_gpu.py
        import time
        import os
        import sys

        print('ğŸ” GPU Monitor Started... Press [Ctrl+C] to STOP!')
        print('-' * 60)

        try:
            while True:
                cmd = 'nvidia-smi --query-gpu=temperature.gpu,fan.speed,utilization.gpu,power.draw --format=csv,noheader,nounits'
                output = os.popen(cmd).read().strip()
                try:
                    parts = output.split(',')
                    if len(parts) >= 4:
                        temp, fan, util, power = [p.strip() for p in parts]
                    else:
                        raise ValueError
                except:
                    temp = fan = util = power = 'N/A'

                sys.stdout.write(f'\rğŸŒ¡ï¸  Temp: {temp:>3}Â°C | ğŸŒªï¸ Fan: {fan:>3}% | ğŸ“Š Load: {util:>3}% | âš¡ Power: {power:>6}W    ')
                sys.stdout.flush()
                time.sleep(1)

        except KeyboardInterrupt:
            print('\n\nğŸ›‘ Monitoring Stopped.')
        EOF
        "

    # 3.3 éƒ¨ç½² SLURM æ’ç¨‹æ¸¬è©¦è…³æœ¬ (æ–°å¢çš„éƒ¨åˆ†)
    - name: 3.3 éƒ¨ç½² Job_queue.py (30ç§’æ’ç¨‹æ¸¬è©¦ + SLURM æ•´åˆ)
      shell: |
        juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }} "
        cat << 'EOF' > Job_queue.py
        import torch
        import time
        import os
        import socket
        import sys

        # 1. ç²å– SLURM è³‡è¨Š
        job_id = os.environ.get('SLURM_JOB_ID', 'Local')
        task_id = os.environ.get('SLURM_ARRAY_TASK_ID', '0')
        node_name = socket.gethostname()

        print(f'[{time.strftime(\"%H:%M:%S\")}] ğŸš€ Job {job_id} (Task {task_id}) started on {node_name}')

        # 2. æª¢æŸ¥ GPU
        if not torch.cuda.is_available():
            print('âŒ Error: No GPU found! Exiting.')
            sys.exit(1)

        device = torch.device('cuda')
        name = torch.cuda.get_device_name(0)
        print(f'    - GPU Detected: {name}')

        # 3. æº–å‚™å¤§çŸ©é™£
        N = 10000
        x = torch.randn(N, N, device=device)
        y = torch.randn(N, N, device=device)

        # --- è¨­å®š 30 ç§’ ---
        duration = 30
        print(f'    - ğŸ”¥ Status: BURNING GPU for {duration} seconds with Live Monitor...')
        print('-' * 80)

        # 4. ç‡’æ©Ÿè¿´åœˆ
        start_time = time.time()

        try:
            while (time.time() - start_time) < duration:
                # A. ç”¢ç”Ÿè² è¼‰
                for _ in range(10):
                    z = torch.mm(x, y)

                # B. ç›£æ§æ•¸æ“š
                cmd = 'nvidia-smi --query-gpu=temperature.gpu,fan.speed,utilization.gpu,power.draw --format=csv,noheader,nounits'
                try:
                    output = os.popen(cmd).read().strip()
                    parts = output.split(',')
                    if len(parts) >= 4:
                        temp = parts[0].strip()
                        fan = parts[1].strip()
                        util = parts[2].strip()
                        power = parts[3].strip()
                    else:
                        raise ValueError
                except:
                    temp = fan = util = power = 'N/A'

                # C. é¡¯ç¤ºè³‡è¨Š
                elapsed = time.time() - start_time
                remain = max(0, duration - elapsed)

                msg = f'\râ³ {remain:4.1f}s | ğŸŒ¡ï¸  Temp: {temp:>3}Â°C | ğŸŒªï¸ Fan: {fan:>3}% | ğŸ“Š Load: {util:>3}% | âš¡ Power: {power:>6}W '
                sys.stdout.write(msg)
                sys.stdout.flush()

                time.sleep(0.5)

        except KeyboardInterrupt:
            pass

        sys.stdout.write('\n')
        print('-' * 80)
        print(f'[{time.strftime(\"%H:%M:%S\")}] âœ… Job {job_id} finished. GPU cooldown initiated.')
        EOF
        "

    # ====================================================
    # 4. å®Œæˆæç¤º
    # ====================================================
    - name: ğŸš€ å®Œæˆæç¤º
      debug:
        msg: 
          - "ç’°å¢ƒéƒ¨ç½²å®Œç•¢ï¼è«‹ç™»å…¥ Worker: juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }}"
          - "---------------------------------------------------------"
          - "æª”æ¡ˆ 1 (æ‰‹å‹•å£“åŠ›æ¸¬è©¦): ./gpu-test-env/bin/python burn_gpu.py"
          - "æª”æ¡ˆ 2 (åƒ…ç›£æ§å„€è¡¨æ¿): ./gpu-test-env/bin/python watch_gpu.py"
          - "æª”æ¡ˆ 3 (SLURM æ’ç¨‹ç”¨): ./gpu-test-env/bin/python Job_queue.py"
          - "---------------------------------------------------------"
