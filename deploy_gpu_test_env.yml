- name: éƒ¨ç½² PyTorch GPU æ¸¬è©¦ç’°å¢ƒ (Restore Burn Tool)
  hosts: maasjuju
  gather_facts: no
  vars:
    # é€™æ˜¯é è¨­å€¼ï¼Œå¯¦éš›æœƒè¢« AWX Survey è¦†è“‹
    slurm_model: "hpc-lab"
    worker_tag: "slurm-node"

  tasks:
    # ====================================================
    # 1. è‡ªå‹•åµæ¸¬ GPU Worker çš„ ID (Machine 1)
    # ====================================================
    - name: 1. åµæ¸¬ GPU Worker ID
      shell: |
        # æŠ“å– Juju æ©Ÿå™¨åˆ—è¡¨ä¸¦è§£æ JSON
        STATUS=$(juju machines -m {{ slurm_model }} --format json)
        
        # ä½¿ç”¨ jq éæ¿¾å‡ºå¸¶æœ‰ 'slurm-node' æ¨™ç±¤çš„æ©Ÿå™¨ ID
        # å¦‚æœæ‚¨çš„æ¨™ç±¤ä¸åŒï¼Œè«‹ä¿®æ”¹ä¸Šé¢çš„ vars
        WORKER_ID=$(echo $STATUS | jq -r '.machines | to_entries[] | select(.value.constraints | contains("tags={{ worker_tag }}")) | .key' | head -n 1)
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œé è¨­å›é€€åˆ° '1' (å‡è¨­ Machine 1)
        if [ -z "$WORKER_ID" ]; then echo "1"; else echo "$WORKER_ID"; fi
      register: worker_id_result
      changed_when: false

    - name: 1.1 é¡¯ç¤ºåµæ¸¬åˆ°çš„ Worker ID
      debug:
        msg: "å³å°‡éƒ¨ç½²åˆ° Model: {{ slurm_model }}, Machine ID: {{ worker_id_result.stdout }}"

    # ====================================================
    # 2. é ç«¯å®‰è£ Python ç’°å¢ƒèˆ‡ PyTorch
    # ====================================================
    - name: 2. å®‰è£ venv ä¸¦å»ºç«‹ PyTorch ç’°å¢ƒ (é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜)
      shell: |
        juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }} "
          # A. å®‰è£ç³»çµ±å¥—ä»¶
          echo 'ğŸ“¦ Updating apt and installing venv...'
          sudo apt-get update -qq
          sudo apt-get install -y python3-venv python3-pip

          # B. å»ºç«‹è™›æ“¬ç’°å¢ƒ (å¦‚æœå·²å­˜åœ¨å‰‡è·³é)
          if [ ! -d 'gpu-test-env' ]; then
            echo 'ğŸ“‚ Creating virtual environment...'
            python3 -m venv gpu-test-env
          fi

          # C. å®‰è£ PyTorch (ç›´æ¥å‘¼å« venv è£¡çš„ pipï¼Œç¢ºä¿è£åœ¨è™›æ“¬ç’°å¢ƒå…§)
          echo 'ğŸ”¥ Installing PyTorch (CUDA 12.1)... This takes time!'
          ./gpu-test-env/bin/pip install --upgrade pip
          ./gpu-test-env/bin/pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
        "
      # è¨­å®šè¼ƒé•·çš„ timeoutï¼Œå› ç‚ºä¸‹è¼‰ PyTorch å¾ˆæ…¢ (30åˆ†é˜)
      async: 1800
      poll: 10

    # ====================================================
    # 3. è‡ªå‹•å¯«å…¥æ¸¬è©¦èˆ‡ç›£æ§è…³æœ¬
    # ====================================================
    
    # 3.1 éƒ¨ç½² Burn GPU (å«ç›£æ§çš„ç‡’æ©Ÿè…³æœ¬)
    - name: 3.1 éƒ¨ç½² burn_gpu.py (å£“åŠ›æ¸¬è©¦ + å„€è¡¨æ¿)
      shell: |
        juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }} "
          cat <<EOF > burn_gpu.py
          import torch
          import time
          import os
          import sys
    
          # 1. æª¢æŸ¥ GPU
          if not torch.cuda.is_available():
              print('âŒ Error: No GPU found!')
              sys.exit(1)
    
          device = torch.device('cuda')
          try:
              name = torch.cuda.get_device_name(0)
          except:
              name = 'Unknown Device'
    
          print(f'âœ… Dedicated GPU: {name}')
          print('ğŸ”¥ Starting Stress Test... Press [Ctrl+C] to STOP! ğŸ”¥')
          print('-' * 80)
    
          # 2. æº–å‚™å¤§çŸ©é™£ (10000x10000)
          N = 10000
          x = torch.randn(N, N, device=device)
          y = torch.randn(N, N, device=device)
    
          try:
              while True:
                  # --- éšæ®µ A: ç”¢ç”Ÿç†±é‡ ---
                  for _ in range(10):
                      z = torch.mm(x, y)
                  
                  # --- éšæ®µ B: ç›£æ§æ•¸æ“š ---
                  cmd = 'nvidia-smi --query-gpu=temperature.gpu,fan.speed,utilization.gpu,power.draw --format=csv,noheader,nounits'
                  try:
                      output = os.popen(cmd).read().strip()
                      # ç›¸å®¹æ€§è™•ç†: æœ‰äº›é©…å‹•è¼¸å‡ºé€—è™Ÿå¾Œæ²’æœ‰ç©ºæ ¼
                      parts = output.split(',')
                      if len(parts) >= 4:
                          # å»é™¤ç©ºç™½
                          temp = parts[0].strip()
                          fan = parts[1].strip()
                          util = parts[2].strip()
                          power = parts[3].strip()
                      else:
                          raise ValueError
                  except:
                      temp = fan = util = power = 'N/A'
    
                  # --- éšæ®µ C: é¡¯ç¤ºè³‡è¨Š ---
                  sys.stdout.write(f'\rğŸŒ¡ï¸  Temp: {temp:>3}Â°C | ğŸŒªï¸ Fan: {fan:>3}% | ğŸ“Š Load: {util:>3}% | âš¡ Power: {power:>6}W | Status: BURNING... ')
                  sys.stdout.flush()
                  
                  time.sleep(0.5)
    
          except KeyboardInterrupt:
              print('\n\nğŸ›‘ Test Stopped by User. Cooling down...')
              del x, y, z
              torch.cuda.empty_cache()
          EOF
        "
    
    # 3.2 éƒ¨ç½² Watch GPU (ç´”ç›£æ§è…³æœ¬)
    - name: 3.2 éƒ¨ç½² watch_gpu.py (ç´”ç›£æ§ä¸ç‡’æ©Ÿ)
      shell: |
        juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }} "
          cat <<EOF > watch_gpu.py
          import time
          import os
          import sys
    
          print('ğŸ” GPU Monitor Started... Press [Ctrl+C] to STOP!')
          print('-' * 60)
    
          try:
              while True:
                  # é€é nvidia-smi æŠ“å–æ•¸æ“š
                  cmd = 'nvidia-smi --query-gpu=temperature.gpu,fan.speed,utilization.gpu,power.draw --format=csv,noheader,nounits'
                  output = os.popen(cmd).read().strip()
                  
                  try:
                      # è§£ææ•¸æ“š (è™•ç†å¯èƒ½çš„æ ¼å¼å·®ç•°)
                      parts = output.split(',')
                      if len(parts) >= 4:
                          temp = parts[0].strip()
                          fan = parts[1].strip()
                          util = parts[2].strip()
                          power = parts[3].strip()
                      else:
                          temp = fan = util = power = 'N/A'
                  except:
                      temp = fan = util = power = 'N/A'
    
                  # é¡¯ç¤ºè³‡è¨Š
                  sys.stdout.write(f'\rğŸŒ¡ï¸  Temp: {temp}Â°C | ğŸŒªï¸ Fan: {fan}% | ğŸ“Š Load: {util}% | âš¡ Power: {power}W    ')
                  sys.stdout.flush()
                  
                  time.sleep(1)
    
          except KeyboardInterrupt:
              print('\n\nğŸ›‘ Monitoring Stopped.')
          EOF
        "
    
    - name: ğŸš€ å®Œæˆæç¤º
      debug:
        msg: 
          - "ç’°å¢ƒéƒ¨ç½²å®Œç•¢ï¼è«‹ç™»å…¥ Worker: juju ssh -m {{ slurm_model }} {{ worker_id_result.stdout }}"
          - "1. åŸ·è¡Œç‡’æ©Ÿæ¸¬è©¦: ./gpu-test-env/bin/python burn_gpu.py"
          - "2. åƒ…åŸ·è¡Œç›£æ§:   ./gpu-test-env/bin/python watch_gpu.py"
