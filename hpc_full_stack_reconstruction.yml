# ==========================================
# SKU: HPC-Full-Stack-Reconstruction-v3-Parallel
# ==========================================
- name: 1. 控制端佈署與運算端硬體準備
  hosts: maasjuju
  gather_facts: no
  vars:
    slurm_model: "hpc-lab"
    target_os: "ubuntu@24.04"

  tasks:
    - name: 1.1 建立全新 Model
      command: "juju add-model {{ slurm_model }}"
      ignore_errors: yes

    - name: 1.2 佈署控制端 (slurmctld)
      command: "juju deploy slurmctld -m {{ slurm_model }} --constraints tags=virtual --base {{ target_os }} --channel=23.11/stable"
      ignore_errors: yes   

    - name: 1.3 向 MAAS 請求 GPU 節點 (強制指定 OS 版本)
      command: "juju add-machine -m {{ slurm_model }} --constraints tags=slurm-node --base {{ target_os }}"
      register: add_machine_result
      
       # k3s 安裝段 ----
    - name: 1.2a Gate：等待 slurmctld/0 可 SSH（machine 0 ready）
      shell: |
        set -euo pipefail
        MODEL="{{ slurm_model }}"
        echo "[1.2a] wait slurmctld/0 sshable in model=${MODEL}"
        while true; do
          if juju ssh -m "$MODEL" slurmctld/0 -- 'echo up' >/dev/null 2>&1; then
            echo "[1.2a] slurmctld/0 SSH is ready"
            break
          fi
          echo "[1.2a] waiting..."
          sleep 5
        done
      args:
        executable: /bin/bash
      environment:
        JUJU_DATA: "/home/gary/.local/share/juju"
      changed_when: false

    - name: 1.2b Install k3s on machine 0 (slurmctld/0 host) + gate
      shell: |
        set -euo pipefail
        MODEL="{{ slurm_model }}"
        echo "[1.2b] install k3s on slurmctld/0 host, model=${MODEL}"
        juju ssh -m "$MODEL" slurmctld/0 -- '
          set -euo pipefail
          echo "[k3s] HOST=$(hostname)"
          echo "[k3s] IPs=$(hostname -I || true)"
          if ! command -v curl >/dev/null 2>&1; then
            echo "[k3s] install curl"
            sudo apt-get update
            sudo apt-get install -y curl
          fi
          if command -v k3s >/dev/null 2>&1 && sudo systemctl is-active --quiet k3s; then
            echo "[k3s] already installed and running"
          else
            echo "[k3s] installing..."
            curl -sfL https://get.k3s.io | sudo sh -s - server \
              --write-kubeconfig-mode 644 \
              --disable traefik \
              --disable servicelb
          fi
          echo "[k3s] wait node ready..."
          while true; do
            if sudo k3s kubectl get nodes 2>/dev/null | grep -q " Ready "; then
              echo "[k3s] READY"
              sudo k3s kubectl get nodes -o wide
              break
            fi
            sudo k3s kubectl get nodes || true
            sleep 5
          done
          echo "[k3s] kubeconfig=/etc/rancher/k3s/k3s.yaml"
        '
      args:
        executable: /bin/bash
      environment:
        JUJU_DATA: "/home/gary/.local/share/juju"
      changed_when: false

    - name: 1.4 取得運算節點 Machine ID（從 add-machine stdout 解析，AWX 相容）
      set_fact:
        target_machine_id: >-
          {{
            (
              add_machine_result.stdout | default('', true) |
              regex_search('(?i)machine\\s+(\\d+)') | default('', true)
            )
            | regex_replace('(?i).*machine\\s+(\\d+).*', '\\1')
            | trim
          }}

    - name: 1.4b 若解析不到（含 None/空字串），改用 juju machines --format=json 取最大 Machine ID（不靠 jq）
      when: (target_machine_id | default('', true) | string | trim) == ''
      block:
        - name: 讀取 machines json
          command: "juju machines -m {{ slurm_model }} --format=json"
          register: machines_json
          changed_when: false

        - name: 由 machines json 推導 target_machine_id（取最大 id）
          set_fact:
            target_machine_id: >-
              {{
                (
                  (machines_json.stdout | from_json).machines
                  | dict2items
                  | map(attribute='key')
                  | map('int')
                  | list
                  | max
                ) | string
              }}

    - name: DEBUG target_machine_id
      debug:
        msg: "target_machine_id={{ target_machine_id | default('', true) | string | trim }}"

    - name: 1.5 Gate-1：等待 Juju Machine 狀態穩定（running/started/idle）- AWX loop (clean)
      shell: |
        set -euo pipefail
        MID="{{ target_machine_id | default('', true) | string | trim }}"
        MODEL="{{ slurm_model | default('', true) | string | trim }}"
    
        echo "[Gate-1] MID='${MID}' MODEL='${MODEL}'"
        juju whoami
    
        if [ -z "${MID}" ] || [ "${MID}" = "None" ]; then
          echo "[Gate-1] ERROR: target_machine_id is empty/None"
          exit 2
        fi
    
        while true; do
          JSON="$(juju show-machine "${MID}" -m "${MODEL}" --format=json 2>&1)" || {
            echo "[Gate-1] ERROR: juju show-machine failed:"
            echo "${JSON}"
            exit 1
          }
    
          echo "${JSON}" | jq -r --arg mid "${MID}" '
            "[Gate-1] machine-status=" + (.machines[$mid]["machine-status"].current // "NA") +
            " juju-status=" + (.machines[$mid]["juju-status"].current // "NA") +
            " modification-status=" + (.machines[$mid]["modification-status"].current // "NA")
          '
    
          echo "${JSON}" | jq -e --arg mid "${MID}" '
            (.machines[$mid]["machine-status"].current=="running")
            and (.machines[$mid]["juju-status"].current=="started")
            and (.machines[$mid]["modification-status"].current=="idle")
          ' >/dev/null && { echo "[Gate-1] READY"; exit 0; }
    
          sleep 5
        done
      args:
        executable: /bin/bash
      environment:
        JUJU_DATA: "/home/gary/.local/share/juju"
      changed_when: false


    - name: 1.5b Gate-2：等待 OS cloud-init 完成（boot-finished）- AWX loop
      shell: |
        set -euo pipefail
        MID="{{ target_machine_id | default('') | string | trim }}"
        MODEL="{{ slurm_model }}"
        echo "[Gate-2] waiting cloud-init MID=${MID} MODEL=${MODEL}"

        while true; do
          if juju ssh -m "$MODEL" "$MID" -- "test -f /var/lib/cloud/instance/boot-finished" >/dev/null 2>&1; then
            echo "[Gate-2] cloud-init DONE"
            exit 0
          fi
          echo "[Gate-2] not done yet..."
          sleep 5
        done
      args:
        executable: /bin/bash
      environment:
        JUJU_DATA: "/home/gary/.local/share/juju"
      changed_when: false

    - name: 1.5c（可選）列印 cloud-init 狀態做紀錄
      command: >
        juju ssh -m {{ slurm_model }} {{ target_machine_id }}
        -- "cloud-init status || true"
      register: ci_status
      changed_when: false

    - name: 1.6 安裝 NVIDIA Driver + DCGM Snap (修正 Service Race Condition)
      shell: |
        set -euo pipefail
        MODEL="{{ slurm_model }}"
        MID="{{ target_machine_id | default('', true) | string | trim }}"
        
        echo "[1.6] MODEL=$MODEL MID=$MID"
        
        # --- 1. 驅動安裝檢查 (這部分你已經過了，但保留邏輯以防萬一) ---
        if ! juju ssh -m "$MODEL" "$MID" -- 'nvidia-smi >/dev/null 2>&1'; then
          echo "[1.6] Installing NVIDIA driver..."
          juju ssh -m "$MODEL" "$MID" -- '
            sudo apt-get update
            sudo DEBIAN_FRONTEND=noninteractive apt-get install -y nvidia-driver-580 nvidia-utils-580
            sudo reboot
          ' || true
          
          echo "[1.6] Waiting for reboot..."
          sleep 10
          while ! juju ssh -m "$MODEL" "$MID" -- 'echo up' >/dev/null 2>&1; do 
            echo "Waiting for SSH..."; sleep 5
          done
          
          # 等待 nvidia-smi 就緒
          echo "[1.6] Waiting for GPU initialization..."
          for i in {1..20}; do
            if juju ssh -m "$MODEL" "$MID" -- 'nvidia-smi >/dev/null 2>&1'; then break; fi
            sleep 5
          done
        fi

        # --- 2. DCGM Snap 安裝與啟動 (重點修正區) ---
        echo "[1.6] Setting up DCGM Snap..."
        juju ssh -m "$MODEL" "$MID" -- '
          set -euo pipefail
          
          # 安裝 Snap (如果已安裝會跳過)
          sudo snap install dcgm || true
          
          # [修正] 給 Snapd 一點時間喘息
          sleep 5
          
          # 啟用並啟動服務 (分開執行並加入延遲)
          echo "Starting nv-hostengine..."
          sudo snap start --enable dcgm.nv-hostengine || true
          sleep 5
          
          echo "Starting dcgm-exporter..."
          sudo snap start --enable dcgm.dcgm-exporter || true
          sleep 5
          
          # [修正] 只在必要時重啟，並使用迴圈重試以避開 "change in progress"
          echo "Ensuring services are active..."
          for service in dcgm.nv-hostengine dcgm.dcgm-exporter; do
            for retry in {1..5}; do
              if sudo snap restart $service; then
                echo "$service restarted successfully."
                break
              else
                echo "Snap busy, retrying $service in 5s..."
                sleep 5
              fi
            done
          done

          # 啟用 Persistence Mode
          sudo nvidia-smi -pm 1
          
          # 檢查 Port 9400 是否有在聽
          if sudo ss -lntp | grep -q 9400; then
            echo "DCGM Exporter is listening on port 9400."
          else
            echo "WARNING: Port 9400 not listening yet."
            sudo snap logs dcgm.dcgm-exporter | tail -n 10
          fi
        '
      changed_when: false



# ==========================================
# 第二階段：佈署運算端並建立連動
# ==========================================
- name: 2. 佈署 Slurm 運算端
  hosts: all
  vars:
    slurm_model: "hpc-lab"
  tasks:
    - name: 2.1 佈署運算端至指定已就緒機器
      # 使用 1.4 抓到的動態 ID
      command: "juju deploy slurmd -m {{ slurm_model }} --to {{ target_machine_id }} --channel=23.11/stable"
      ignore_errors: yes

    - name: 2.2 建立整合關係 (大腦與手腳連線)
      command: "juju integrate slurmctld slurmd -m {{ slurm_model }}"
      ignore_errors: yes

# ==========================================
# 第三階段：深度修正 (插件、網路、DCGM Exporter)
# ==========================================
- name: 3. 執行自動化環境修正
  hosts: all
  tasks:
    - name: 3.1 修正控制端 (slurmctld)
      shell: |
        juju ssh -m hpc-lab slurmctld/0 "
        REAL_HOSTNAME=\$(hostname)
        sudo sed -i \"/127.0.0.1/s/$/ \$REAL_HOSTNAME slurm-master/\" /etc/hosts
        sudo sed -i 's/SlurmctldHost=.*/SlurmctldHost='\$REAL_HOSTNAME'/g' /etc/slurm/slurm.conf
        sudo sed -i 's/select\/cons_res/select\/cons_tres/g' /etc/slurm/slurm.conf
        sudo sed -i '/MungeSocketDir/d' /etc/slurm/slurm.conf
        sudo sed -i '1i SlurmdParameters=config_overrides' /etc/slurm/slurm.conf
        sudo mkdir -p /var/spool/slurmctld && sudo chown slurm:slurm /var/spool/slurmctld
        sudo systemctl restart munge && sudo systemctl restart slurmctld
        "

    - name: 3.2 修正運算端與安裝 DCGM Exporter
      shell: |
        juju ssh -m hpc-lab slurmd/0 "
        # 1. 網路與 Slurm 修正
        CTLD_IP=\$(juju ssh -m hpc-lab slurmctld/0 'hostname -I' | awk '{print \$1}')
        sudo sed -i '/slurm-master/d' /etc/hosts
        echo \"\$CTLD_IP slurm-master\" | sudo tee -a /etc/hosts
        sudo sed -i 's/select\/cons_res/select\/cons_tres/g' /etc/slurm/slurm.conf
        sudo sed -i '/MungeSocketDir/d' /etc/slurm/slurm.conf
        echo 'Name=gpu Type=rtx4090 File=/dev/nvidia0' | sudo tee /etc/slurm/gres.conf
        sudo sed -i '/NodeName=gpu-node01/c\NodeName=gpu-node01 CPUs=18 Sockets=1 CoresPerSocket=18 ThreadsPerCore=1 RealMemory=128646 Gres=gpu:rtx4090:1 State=UNKNOWN' /etc/slurm/slurm.conf
        
        # 2. DCGM Exporter 安裝
        if [ ! -f /usr/bin/dcgm-exporter ]; then
          wget https://github.com/NVIDIA/dcgm-exporter/releases/download/v3.3.5-3.4.1/dcgm-exporter_3.3.5-3.4.1_amd64.deb
          sudo dpkg -i dcgm-exporter_3.3.5-3.4.1_amd64.deb
          sudo systemctl enable --now dcgm-exporter
        fi

        sudo mkdir -p /run/slurm && sudo chown slurm:slurm /run/slurm
        sudo systemctl restart munge && sudo systemctl restart slurmd
        "

    - name: 3.3 最終節點喚醒
      shell: |
        juju ssh -m hpc-lab slurmctld/0 "sudo scontrol update nodename=gpu-node01 state=resume"
