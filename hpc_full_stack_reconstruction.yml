# ==========================================
# SKU: HPC-Full-Stack-Reconstruction-v3-Parallel
# ==========================================
- name: 1. 控制端佈署與運算端硬體準備
  hosts: maasjuju
  gather_facts: no
  vars:
    slurm_model: "hpc-lab"
    target_os: "ubuntu@24.04"

  tasks:
    - name: 1.1 建立全新 Model
      command: "juju add-model {{ slurm_model }}"
      ignore_errors: yes

    - name: 1.2 佈署控制端 (slurmctld)
      command: "juju deploy slurmctld -m {{ slurm_model }} --constraints tags=virtual --base {{ target_os }} --channel=23.11/stable"
      ignore_errors: yes

    - name: 1.3 向 MAAS 請求 GPU 節點 (強制指定 OS 版本)
      command: "juju add-machine -m {{ slurm_model }} --constraints tags=slurm-node --base {{ target_os }}"
      register: add_machine_result

    - name: 1.4 取得運算節點 Machine ID（從 add-machine stdout 解析，AWX 相容）
      set_fact:
        target_machine_id: >-
          {{
            (
              add_machine_result.stdout | default('', true) |
              regex_search('(?i)machine\\s+(\\d+)') | default('', true)
            )
            | regex_replace('(?i).*machine\\s+(\\d+).*', '\\1')
            | trim
          }}

    - name: 1.4b 若解析不到（含 None/空字串），改用 juju machines --format=json 取最大 Machine ID（不靠 jq）
      when: (target_machine_id | default('', true) | string | trim) == ''
      block:
        - name: 讀取 machines json
          command: "juju machines -m {{ slurm_model }} --format=json"
          register: machines_json
          changed_when: false

        - name: 由 machines json 推導 target_machine_id（取最大 id）
          set_fact:
            target_machine_id: >-
              {{
                (
                  (machines_json.stdout | from_json).machines
                  | dict2items
                  | map(attribute='key')
                  | map('int')
                  | list
                  | max
                ) | string
              }}

    - name: DEBUG target_machine_id
      debug:
        msg: "target_machine_id={{ target_machine_id | default('', true) | string | trim }}"

    - name: 1.5 Gate-1：等待 Juju Machine 狀態穩定（running/started/idle）- AWX loop (clean)
      shell: |
        set -euo pipefail
        MID="{{ target_machine_id | default('', true) | string | trim }}"
        MODEL="{{ slurm_model | default('', true) | string | trim }}"
    
        echo "[Gate-1] MID='${MID}' MODEL='${MODEL}'"
        juju whoami
    
        if [ -z "${MID}" ] || [ "${MID}" = "None" ]; then
          echo "[Gate-1] ERROR: target_machine_id is empty/None"
          exit 2
        fi
    
        while true; do
          JSON="$(juju show-machine "${MID}" -m "${MODEL}" --format=json 2>&1)" || {
            echo "[Gate-1] ERROR: juju show-machine failed:"
            echo "${JSON}"
            exit 1
          }
    
          echo "${JSON}" | jq -r --arg mid "${MID}" '
            "[Gate-1] machine-status=" + (.machines[$mid]["machine-status"].current // "NA") +
            " juju-status=" + (.machines[$mid]["juju-status"].current // "NA") +
            " modification-status=" + (.machines[$mid]["modification-status"].current // "NA")
          '
    
          echo "${JSON}" | jq -e --arg mid "${MID}" '
            (.machines[$mid]["machine-status"].current=="running")
            and (.machines[$mid]["juju-status"].current=="started")
            and (.machines[$mid]["modification-status"].current=="idle")
          ' >/dev/null && { echo "[Gate-1] READY"; exit 0; }
    
          sleep 5
        done
      args:
        executable: /bin/bash
      environment:
        JUJU_DATA: "/home/gary/.local/share/juju"
      changed_when: false


    - name: 1.5b Gate-2：等待 OS cloud-init 完成（boot-finished）- AWX loop
      shell: |
        set -euo pipefail
        MID="{{ target_machine_id | default('') | string | trim }}"
        MODEL="{{ slurm_model }}"
        echo "[Gate-2] waiting cloud-init MID=${MID} MODEL=${MODEL}"

        while true; do
          if juju ssh -m "$MODEL" "$MID" -- "test -f /var/lib/cloud/instance/boot-finished" >/dev/null 2>&1; then
            echo "[Gate-2] cloud-init DONE"
            exit 0
          fi
          echo "[Gate-2] not done yet..."
          sleep 5
        done
      args:
        executable: /bin/bash
      environment:
        JUJU_DATA: "/home/gary/.local/share/juju"
      changed_when: false

    - name: 1.5c（可選）列印 cloud-init 狀態做紀錄
      command: >
        juju ssh -m {{ slurm_model }} {{ target_machine_id }}
        -- "cloud-init status || true"
      register: ci_status
      changed_when: false

    - name: 1.6 安裝 NVIDIA Driver + reboot + 啟動 DCGM Exporter（含 metrics gate）
      shell: |
        set -euo pipefail
        MODEL="{{ slurm_model }}"
        MID="{{ target_machine_id | default('', true) | string | trim }}"

        echo "[1.6] MODEL=$MODEL MID=$MID"
        if [ -z "$MID" ] || [ "$MID" = "None" ]; then
          echo "[1.6] ERROR: target_machine_id is empty/None"
          exit 2
        fi

        # 0) 確保 curl 存在（後面 metrics gate 需要）
        juju ssh -m "$MODEL" "$MID" -- '
          set -euo pipefail
          command -v curl >/dev/null 2>&1 || (sudo apt-get update && sudo apt-get install -y curl)
          echo "[1.6] curl OK: $(command -v curl)"
        '

        echo "[1.6] check driver/pkg"
        # 1) 檢查：若 driver 不在，就安裝（安裝後一定 reboot）
        NEED_REBOOT=0

        if ! juju ssh -m "$MODEL" "$MID" -- 'command -v nvidia-smi >/dev/null 2>&1'; then
          echo "[1.6] nvidia-smi missing -> install nvidia driver then reboot"
          juju ssh -m "$MODEL" "$MID" -- '
            set -euo pipefail
            sudo apt-get update
            # 先嘗試你指定的 580；若 repo 沒有，再 fallback ubuntu-drivers
            if apt-cache show nvidia-driver-580 >/dev/null 2>&1; then
              sudo DEBIAN_FRONTEND=noninteractive apt-get install -y nvidia-driver-580 nvidia-utils-580
            else
              echo "[1.6] WARN: nvidia-driver-580 not found in repo, fallback ubuntu-drivers"
              sudo apt-get install -y ubuntu-drivers-common
              sudo ubuntu-drivers autoinstall
            fi
          '
          NEED_REBOOT=1
        else
          echo "[1.6] nvidia-smi exists -> skip driver install"
        fi

        # 2) 標準流程：只要本次有安裝 driver，就 reboot
        if [ "$NEED_REBOOT" = "1" ]; then
          echo "[1.6] reboot now"
          juju ssh -m "$MODEL" "$MID" -- 'sudo reboot' || true

          echo "[1.6] wait for SSH back"
          # 等 machine 回來：能 juju ssh 進去就算回來
          while true; do
            if juju ssh -m "$MODEL" "$MID" -- 'echo up' >/dev/null 2>&1; then
              echo "[1.6] SSH is back"
              break
            fi
            echo "[1.6] waiting..."
            sleep 5
          done
        fi

        # 3) reboot 後 gate：nvidia-smi 一定要成功（driver 真正生效的證據）
        echo "[1.6] gate: nvidia-smi"
        while true; do
          if juju ssh -m "$MODEL" "$MID" -- 'nvidia-smi >/dev/null 2>&1'; then
            juju ssh -m "$MODEL" "$MID" -- 'nvidia-smi | head -n 20'
            echo "[1.6] nvidia-smi OK"
            break
          fi
          echo "[1.6] nvidia-smi not ready yet..."
          sleep 5
        done

        # 4) DCGM：用 snap（你已驗證可行），並確保服務啟動/9400 監聽
        echo "[1.6] install/start dcgm snap"
        juju ssh -m "$MODEL" "$MID" -- '
          set -euo pipefail
          sudo snap install dcgm || true
          sudo snap start --enable dcgm.nv-hostengine
          sudo snap start --enable dcgm.dcgm-exporter
          sudo snap restart dcgm.nv-hostengine
          sudo snap restart dcgm.dcgm-exporter
          snap services dcgm || true
          sudo ss -lntp | grep 9400 || true
        '

        # 5) metrics gate：HTTP 200 + 內容有 # HELP
        echo "[1.6] gate: metrics endpoint"
        juju ssh -m "$MODEL" "$MID" -- '
          set -euo pipefail
          code=$(curl -sS -o /dev/null -w "%{http_code}" http://127.0.0.1:9400/metrics)
          echo "[1.6] http_code=$code"
          [ "$code" = "200" ] || { echo "[1.6] ERROR: metrics http_code=$code"; exit 20; }
          curl -sS --max-time 5 http://127.0.0.1:9400/metrics | head -n 5 | tee /dev/stderr | grep -q "^# HELP" \
            || { echo "[1.6] ERROR: metrics content invalid"; sudo snap logs dcgm.dcgm-exporter -n 50 || true; exit 21; }
          echo "[1.6] metrics OK"
        '
      args:
        executable: /bin/bash
      environment:
        JUJU_DATA: "/home/gary/.local/share/juju"
      changed_when: false



# ==========================================
# 第二階段：佈署運算端並建立連動
# ==========================================
- name: 2. 佈署 Slurm 運算端
  hosts: all
  vars:
    slurm_model: "hpc-lab"
  tasks:
    - name: 2.1 佈署運算端至指定已就緒機器
      # 使用 1.4 抓到的動態 ID
      command: "juju deploy slurmd -m {{ slurm_model }} --to {{ target_machine_id }} --channel=23.11/stable"
      ignore_errors: yes

    - name: 2.2 建立整合關係 (大腦與手腳連線)
      command: "juju integrate slurmctld slurmd -m {{ slurm_model }}"
      ignore_errors: yes

# ==========================================
# 第三階段：深度修正 (插件、網路、DCGM Exporter)
# ==========================================
- name: 3. 執行自動化環境修正
  hosts: all
  tasks:
    - name: 3.1 修正控制端 (slurmctld)
      shell: |
        juju ssh -m hpc-lab slurmctld/0 "
        REAL_HOSTNAME=\$(hostname)
        sudo sed -i \"/127.0.0.1/s/$/ \$REAL_HOSTNAME slurm-master/\" /etc/hosts
        sudo sed -i 's/SlurmctldHost=.*/SlurmctldHost='\$REAL_HOSTNAME'/g' /etc/slurm/slurm.conf
        sudo sed -i 's/select\/cons_res/select\/cons_tres/g' /etc/slurm/slurm.conf
        sudo sed -i '/MungeSocketDir/d' /etc/slurm/slurm.conf
        sudo sed -i '1i SlurmdParameters=config_overrides' /etc/slurm/slurm.conf
        sudo mkdir -p /var/spool/slurmctld && sudo chown slurm:slurm /var/spool/slurmctld
        sudo systemctl restart munge && sudo systemctl restart slurmctld
        "

    - name: 3.2 修正運算端與安裝 DCGM Exporter
      shell: |
        juju ssh -m hpc-lab slurmd/0 "
        # 1. 網路與 Slurm 修正
        CTLD_IP=\$(juju ssh -m hpc-lab slurmctld/0 'hostname -I' | awk '{print \$1}')
        sudo sed -i '/slurm-master/d' /etc/hosts
        echo \"\$CTLD_IP slurm-master\" | sudo tee -a /etc/hosts
        sudo sed -i 's/select\/cons_res/select\/cons_tres/g' /etc/slurm/slurm.conf
        sudo sed -i '/MungeSocketDir/d' /etc/slurm/slurm.conf
        echo 'Name=gpu Type=rtx4090 File=/dev/nvidia0' | sudo tee /etc/slurm/gres.conf
        sudo sed -i '/NodeName=gpu-node01/c\NodeName=gpu-node01 CPUs=18 Sockets=1 CoresPerSocket=18 ThreadsPerCore=1 RealMemory=128646 Gres=gpu:rtx4090:1 State=UNKNOWN' /etc/slurm/slurm.conf
        
        # 2. DCGM Exporter 安裝
        if [ ! -f /usr/bin/dcgm-exporter ]; then
          wget https://github.com/NVIDIA/dcgm-exporter/releases/download/v3.3.5-3.4.1/dcgm-exporter_3.3.5-3.4.1_amd64.deb
          sudo dpkg -i dcgm-exporter_3.3.5-3.4.1_amd64.deb
          sudo systemctl enable --now dcgm-exporter
        fi

        sudo mkdir -p /run/slurm && sudo chown slurm:slurm /run/slurm
        sudo systemctl restart munge && sudo systemctl restart slurmd
        "

    - name: 3.3 最終節點喚醒
      shell: |
        juju ssh -m hpc-lab slurmctld/0 "sudo scontrol update nodename=gpu-node01 state=resume"
