# ==========================================
# SKU: HPC-Full-Stack-Reconstruction-v4.1 (Compatibility Fix)
# ==========================================
- name: 1. 控制端佈署與運算端硬體準備
  hosts: maasjuju
  gather_facts: no
  vars:
    slurm_model: "hpc-lab"
    # 維持 22.04 以支援 MicroK8s
    target_os: "ubuntu@22.04"

  tasks:
    - name: 1.1 建立全新 Model
      command: "juju add-model {{ slurm_model }}"
      ignore_errors: yes

    - name: 1.2 佈署控制端 (slurmctld)
      # [修正] 改用 latest/edge，這是目前唯一支援 22.04 的 Slurm Charm 通道
      command: "juju deploy slurmctld -m {{ slurm_model }} --constraints tags=virtual --base {{ target_os }} --channel=latest/edge"
      ignore_errors: yes

    # =========================================================
    # 運算節點 (GPU Node) - Part-1
    # =========================================================
    - name: 1.3 向 MAAS 請求 GPU 節點
      command: "juju add-machine -m {{ slurm_model }} --constraints tags=slurm-node --base {{ target_os }}"
      register: add_machine_result

    # =========================================================
    # MicroK8s (原生支援 22.04)
    # =========================================================
    - name: 1.2b 在 Slurm 控制端上共同部署 MicroK8s
      command: "juju deploy microk8s --to slurmctld/0 --channel=1.28/stable"
      register: deploy_k8s
      failed_when: "(deploy_k8s.rc != 0) and ('already exists' not in deploy_k8s.stderr)"
    - name: 1.2c Gate：等待 MicroK8s 就緒
      command: "juju wait-for unit microk8s/0 -m {{ slurm_model }} --query='workload-status==\"active\"' --timeout 20m"

    # =========================================================
    # 運算節點 (GPU Node) - Part-2
    # =========================================================
    
    - name: 1.4 取得運算節點 Machine ID
      set_fact:
        target_machine_id: >-
          {{
            (
              add_machine_result.stdout | default('', true) |
              regex_search('(?i)machine\\s+(\\d+)') | default('', true)
            )
            | regex_replace('(?i).*machine\\s+(\\d+).*', '\\1')
            | trim
          }}

    - name: 1.4b 若解析不到，改用 CLI JSON 解析
      when: (target_machine_id | default('', true) | string | trim) == ''
      block:
        - name: 讀取 machines json
          command: "juju machines -m {{ slurm_model }} --format=json"
          register: machines_json
          changed_when: false
        - name: 由 machines json 推導 target_machine_id
          set_fact:
            target_machine_id: >-
              {{
                ((machines_json.stdout | from_json).machines.keys() | list | map('int') | max) | string
              }}

    - name: 1.5 Gate-1：等待運算節點 SSH 連線就緒
      shell: |
        set -euo pipefail
        MID="{{ target_machine_id }}"
        MODEL="{{ slurm_model }}"
        echo "Waiting for SSH on Machine $MID..."
        while ! juju ssh -m "$MODEL" "$MID" -- 'echo up' >/dev/null 2>&1; do
           sleep 5
        done
        echo "Machine $MID SSH Ready"
      args:
        executable: /bin/bash
      changed_when: false

    - name: 1.6 安裝 NVIDIA Driver + DCGM Snap (Ubuntu 22.04)
      shell: |
        set -euo pipefail
        MODEL="{{ slurm_model }}"
        MID="{{ target_machine_id }}"
        
        if ! juju ssh -m "$MODEL" "$MID" -- 'nvidia-smi >/dev/null 2>&1'; then
          echo "Installing NVIDIA driver..."
          juju ssh -m "$MODEL" "$MID" -- '
            sudo apt-get update
            # 22.04 需要 Keyring 才能抓到 580
            wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
            sudo dpkg -i cuda-keyring_1.1-1_all.deb
            sudo apt-get update
            sudo DEBIAN_FRONTEND=noninteractive apt-get install -y nvidia-driver-580 nvidia-utils-580 datacenter-gpu-manager
            sudo reboot
          ' || true
          
          echo "Waiting for reboot..."
          sleep 10
          while ! juju ssh -m "$MODEL" "$MID" -- 'echo up' >/dev/null 2>&1; do sleep 5; done
          
          for i in {1..20}; do
            if juju ssh -m "$MODEL" "$MID" -- 'nvidia-smi >/dev/null 2>&1'; then break; fi
            sleep 5
          done
        fi

        juju ssh -m "$MODEL" "$MID" -- '
          set -euo pipefail
          sudo snap install dcgm || true
          sleep 5
          sudo snap start --enable dcgm.nv-hostengine || true
          sleep 3
          sudo snap start --enable dcgm.dcgm-exporter || true
          sleep 3
          sudo nvidia-smi -pm 1
        '
      args:
        executable: /bin/bash
      changed_when: false

# ==========================================
# 第二階段：佈署 Slurm 運算端
# ==========================================
- name: 2. 佈署 Slurm 運算端
  hosts: maasjuju
  vars:
    slurm_model: "hpc-lab"
  tasks:
    - name: 2.1 佈署運算端至指定機器
      # [修正] 同步改用 latest/edge
      command: "juju deploy slurmd -m {{ slurm_model }} --to {{ target_machine_id }} --channel=latest/edge"
      ignore_errors: yes

    - name: 2.2 建立整合關係
      command: "juju integrate slurmctld slurmd -m {{ slurm_model }}"
      ignore_errors: yes

    - name: 2.3 Gate：等待 slurmd 安裝完成
      command: "juju wait-for unit slurmd/0 -m {{ slurm_model }} --query='agent-status==\"idle\"' --timeout 15m"

# ==========================================
# 第三階段：深度修正
# ==========================================
- name: 3. 執行自動化環境修正
  hosts: maasjuju
  tasks:
    - name: 3.0 預先獲取 slurmctld IP
      shell: "juju ssh -m {{ slurm_model }} slurmctld/0 'hostname -I' | awk '{print $1}'"
      register: ctld_ip_result

    - name: 3.1 修正控制端 (slurmctld)
      shell: |
        juju ssh -m {{ slurm_model }} slurmctld/0 "
        REAL_HOSTNAME=\$(hostname)
        sudo sed -i \"/127.0.0.1/s/$/ \$REAL_HOSTNAME slurm-master/\" /etc/hosts
        sudo sed -i 's/SlurmctldHost=.*/SlurmctldHost='\$REAL_HOSTNAME'/g' /etc/slurm/slurm.conf
        # 修正：Slurm Edge 版可能預設插件不同，保險起見強制設定
        sudo sed -i 's/select\/cons_res/select\/cons_tres/g' /etc/slurm/slurm.conf
        sudo sed -i '/MungeSocketDir/d' /etc/slurm/slurm.conf
        sudo sed -i '1i SlurmdParameters=config_overrides' /etc/slurm/slurm.conf
        sudo mkdir -p /var/spool/slurmctld && sudo chown slurm:slurm /var/spool/slurmctld
        sudo systemctl restart munge && sudo systemctl restart slurmctld
        "

    - name: 3.2 修正運算端
      shell: |
        MASTER_IP="{{ ctld_ip_result.stdout }}"
        juju ssh -m {{ slurm_model }} slurmd/0 "
        sudo sed -i '/slurm-master/d' /etc/hosts
        echo \"\$MASTER_IP slurm-master\" | sudo tee -a /etc/hosts
        
        sudo sed -i 's/select\/cons_res/select\/cons_tres/g' /etc/slurm/slurm.conf
        sudo sed -i '/MungeSocketDir/d' /etc/slurm/slurm.conf
        echo 'Name=gpu Type=rtx4090 File=/dev/nvidia0' | sudo tee /etc/slurm/gres.conf
        
        sudo sed -i '/NodeName=gpu-node01/c\NodeName=gpu-node01 CPUs=18 Sockets=1 CoresPerSocket=18 ThreadsPerCore=1 RealMemory=128646 Gres=gpu:rtx4090:1 State=UNKNOWN' /etc/slurm/slurm.conf
        
        sudo mkdir -p /run/slurm && sudo chown slurm:slurm /run/slurm
        sudo systemctl restart munge && sudo systemctl restart slurmd
        "

    - name: 3.3 最終節點喚醒
      shell: |
        juju ssh -m {{ slurm_model }} slurmctld/0 "sudo scontrol update nodename=gpu-node01 state=resume"
