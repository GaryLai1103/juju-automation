---
# ========================================================
# Scenario: Real User AI Environment (Offline/Air-Gap)
# Goal: Distribute offline wheel -> Install -> Run Training
# ========================================================
- name: éƒ¨ç½²çœŸå¯¦ä½¿ç”¨è€… PyTorch ç’°å¢ƒ (é›¢ç·šç‰ˆ)
  hosts: maasjuju
  gather_facts: no
  vars:
    # ---- ä½ çš„æª”æ¡ˆä½ç½® ----
    local_wheel_path: "/home/gary/torch.whl"  # Jumpbox ä¸Šçš„è·¯å¾‘
    
    # ---- Slinky è¨­å®š ----
    test_model: "slinky-cluster"
    k8s_machine: "0"
    slurm_ns: "slurm"
    controller_pod: "slurm-controller-0"
    shared_dir: "/home/slurm"

  tasks:
    # ----------------------------------------------------
    # 1. æª¢æŸ¥å¿…è¦çš„å®‰è£æª”æ˜¯å¦å­˜åœ¨
    # ----------------------------------------------------
    - name: 1.1 æª¢æŸ¥ Jumpbox ä¸Šæ˜¯å¦æœ‰ torch.whl
      stat:
        path: "{{ local_wheel_path }}"
      register: wheel_stat
      failed_when: not wheel_stat.stat.exists

    - name: 1.2 æª¢æŸ¥ Controller Pod ç‹€æ…‹
      shell: |
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- \
          "kubectl get pod -n {{ slurm_ns }} {{ controller_pod }} -o jsonpath='{.status.phase}'"
      register: pod_status
      failed_when: "'Running' not in pod_status.stdout"

    # ----------------------------------------------------
    # 2. å°‡å®‰è£æª”æ¬é‹åˆ° NFS å…±äº«ç›®éŒ„ (æ‰€æœ‰ç¯€é»å¯è¦‹)
    # ----------------------------------------------------
    - name: 2.1 ä¸Šå‚³ torch.whl åˆ° Controller Pod
      # ç‚ºäº†é¿å… Ansible å‚³å¤§æª”è¶…æ™‚ï¼Œæˆ‘å€‘è®“ Juju æ©Ÿå™¨è‡ªå·±ç”¨ scp/kubectl è™•ç†
      shell: |
        # 1. å…ˆå‚³åˆ° Machine 0 çš„ /tmp
        juju scp {{ local_wheel_path }} {{ test_model }}/{{ k8s_machine }}:/tmp/torch.whl
        
        # 2. å†å¾ Machine 0 è¤‡è£½é€² Pod çš„å…±äº«ç›®éŒ„
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- \
          "kubectl cp /tmp/torch.whl {{ slurm_ns }}/{{ controller_pod }}:{{ shared_dir }}/torch.whl"
        
        # 3. æ¸…ç† Machine 0 çš„æš«å­˜
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- "rm -f /tmp/torch.whl"
      async: 1200 # å…è¨±è·‘ 20 åˆ†é˜ (å‚³è¼¸å¤§æª”)
      poll: 10
      register: upload_res

    # ----------------------------------------------------
    # 3. å»ºç«‹ Python venv ä¸¦é›¢ç·šå®‰è£
    # ----------------------------------------------------
    - name: 3.1 å»ºç«‹ venv ä¸¦é›¢ç·šå®‰è£ PyTorch
      shell: |
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- bash -s <<'EOS'
          # åœ¨ Pod è£¡é¢ç”¢ç”Ÿå®‰è£è…³æœ¬
          cat << 'SCRIPT' > /tmp/install_env.sh
          #!/bin/bash
          cd {{ shared_dir }}
          
          echo "ğŸ“‚ Creating Virtual Environment..."
          # å¦‚æœå·²å­˜åœ¨å…ˆä¸åˆªé™¤ï¼Œç¯€çœæ™‚é–“ï¼Œä½†çœŸå¯¦å ´æ™¯å¯èƒ½éœ€è¦ --clear
          python3 -m venv ai-env

          echo "ğŸ“¦ Installing PyTorch from Offline Wheel..."
          source ai-env/bin/activate
          
          # [é—œéµ] é›¢ç·šå®‰è£æŒ‡ä»¤ï¼Œä¸é€£ç¶²
          pip install {{ shared_dir }}/torch.whl --no-index --find-links {{ shared_dir }}
          
          # é©—è­‰å®‰è£
          python3 -c "import torch; print(f'âœ… PyTorch Installed: {torch.__version__}, CUDA: {torch.version.cuda}')"
          SCRIPT
          
          chmod +x /tmp/install_env.sh
          
          # è¤‡è£½é€²å»ä¸¦åŸ·è¡Œ
          kubectl cp /tmp/install_env.sh {{ slurm_ns }}/{{ controller_pod }}:/tmp/install_env.sh
          kubectl exec -n {{ slurm_ns }} {{ controller_pod }} -- /tmp/install_env.sh
        EOS
      async: 600
      poll: 10

    # ----------------------------------------------------
    # 4. æº–å‚™çœŸå¯¦çš„è¨“ç·´ç¨‹å¼ (Matrix Multiplication)
    # ----------------------------------------------------
    - name: 4.1 æ³¨å…¥ train.py (çœŸå¯¦ GPU è² è¼‰)
      shell: |
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- bash -s <<'EOS'
          cat << 'PY' > /tmp/train.py
        import torch
        import time
        import os
        import socket

        # 1. å–å¾—ç¯€é»è³‡è¨Š
        node_name = socket.gethostname()
        job_id = os.environ.get('SLURM_JOB_ID', 'Local')
        print(f"ğŸš€ [Job {job_id}] Training started on {node_name}")

        # 2. ç¢ºèª GPU
        if torch.cuda.is_available():
            dev = torch.device("cuda")
            print(f"âœ… GPU Found: {torch.cuda.get_device_name(0)}")
        else:
            print("âŒ No GPU found! Training on CPU (Slow).")
            dev = torch.device("cpu")

        # 3. æ¨¡æ“¬è¨“ç·´ (çŸ©é™£ä¹˜æ³•)
        N = 8000
        print(f"ğŸ”¥ Allocating Tensors ({N}x{N})...")
        a = torch.randn(N, N, device=dev)
        b = torch.randn(N, N, device=dev)

        print("ğŸ”„ Starting Compute Loop (10 iterations)...")
        start = time.time()
        for i in range(10):
            c = torch.mm(a, b)
            # å¼·åˆ¶åŒæ­¥ä»¥æ¸¬é‡çœŸå¯¦ GPU æ™‚é–“
            torch.cuda.synchronize()
            print(f"   -> Batch {i+1} done.")
            
        end = time.time()
        print(f"âœ… Training Finished in {end - start:.2f} seconds.")
        PY
          
          kubectl cp /tmp/train.py {{ slurm_ns }}/{{ controller_pod }}:{{ shared_dir }}/train.py
        EOS

    # ----------------------------------------------------
    # 5. ç”¢ç”Ÿ sbatch è…³æœ¬ (ä½¿ç”¨è€…æ“ä½œä»‹é¢)
    # ----------------------------------------------------
    - name: 5.1 ç”¢ç”Ÿ run_job.sh
      shell: |
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- bash -s <<'EOS'
          cat << 'SBATCH' > /tmp/run_job.sh
        #!/bin/bash
        #SBATCH --job-name=real-ai-train
        #SBATCH --output=train-%j.out
        #SBATCH --ntasks=1
        #SBATCH --gres=gpu:1
        #SBATCH --time=00:05:00
        #SBATCH --partition=slinky

        echo "â¡ï¸  Loading Environment..."
        source {{ shared_dir }}/ai-env/bin/activate

        echo "â¡ï¸  Running Training Script..."
        python {{ shared_dir }}/train.py
        SBATCH
        
          kubectl cp /tmp/run_job.sh {{ slurm_ns }}/{{ controller_pod }}:{{ shared_dir }}/run_job.sh
        EOS

    - name: ğŸš€ å®Œæˆæç¤º
      debug:
        msg: 
          - "éƒ¨ç½²æˆåŠŸï¼çœŸå¯¦ä½¿ç”¨è€…å ´æ™¯å·²å°±ç·’ã€‚"
          - "----------------------------------------------------"
          - "è«‹é€²å…¥ Pod åŸ·è¡Œæ¸¬è©¦ï¼š"
          - "1. ç™»å…¥: juju ssh -m {{ test_model }} 0 -- kubectl exec -it -n slurm slurm-controller-0 -- bash"
          - "2. é€²å…¥ç›®éŒ„: cd /home/slurm"
          - "3. é€å‡ºè¨“ç·´ä»»å‹™: sbatch run_job.sh"
          - "4. æŸ¥çœ‹ Log: cat train-*.out"
          - "----------------------------------------------------"
