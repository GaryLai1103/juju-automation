---
# ==========================================
# SKU: Slinky-K8s-v1.5-Final
# ä¿®æ­£ï¼š
#   1. å°‡ etcd channel æ”¹ç‚º latest/stable ä»¥ç¬¦åˆ ubuntu@22.04
#   2. ä¿æŒ slinky-cluster æ¨¡å‹åç¨±èˆ‡ 1.31/stable ç‰ˆæœ¬
# ==========================================
- name: Infrastructure Test - Deploy Modern Charmed Kubernetes
  hosts: maasjuju
  gather_facts: yes
  vars:
    test_model: "slinky-cluster"
    k8s_channel: "1.31/stable"
    bundle_path: "{{ ansible_user_dir }}/charmed-k8s-modern.yaml"

  tasks:
    # 1. ç’°å¢ƒæ¸…ç†
    - name: 1.0 å¼·åˆ¶æ¸…ç†èˆŠæ¨¡å‹
      command: "juju destroy-model {{ test_model }} --no-prompt --force --destroy-storage"
      register: destroy_result
      failed_when: 
        - destroy_result.rc != 0 
        - '"not found" not in destroy_result.stderr'
      ignore_errors: yes

    - name: 1.1 ç­‰å¾…æ¨¡å‹é‡‹æ”¾
      pause:
        seconds: 15

    - name: 1.2 å»ºç«‹å…¨æ–° Juju Model
      shell: juju add-model {{ test_model }}

    # 2. è£½ä½œè—åœ–
    - name: 2.0 æ¸…é™¤èˆŠçš„ Bundle æª”æ¡ˆ (é¿å…æ¬Šé™è¡çª)
      become: yes
      file:
        path: "{{ bundle_path }}"
        state: absent
    - name: 2.1 ç”¢ç”Ÿæœ¬åœ° Bundle æª”æ¡ˆ
      copy:
        dest: "{{ bundle_path }}"
        mode: '0644'
        content: |
          description: Slinky Modern K8s Cluster
          base: ubuntu@22.04
          
          machines:
            "0":
              constraints: tags=virtual
            "1":
              constraints: tags=slurm-node

          applications:
            easyrsa:
              charm: easyrsa
              channel: latest/stable
              num_units: 1
              to: ["0"]
            
            etcd:
              charm: etcd
              # ä¿®æ­£ï¼šé€™è£¡æ”¹ç”¨ latest/stableï¼Œå› ç‚º 3.4/stable ä¸æ”¯æ´ 22.04 base
              channel: latest/stable
              num_units: 1
              to: ["0"]

            kubernetes-control-plane:
              charm: kubernetes-control-plane
              channel: {{ k8s_channel }}
              num_units: 1
              to: ["0"]
              options:
                allow-privileged: "true"

            kubernetes-worker:
              charm: kubernetes-worker
              channel: {{ k8s_channel }}
              num_units: 1
              to: ["1"]
              expose: true

            calico:
              charm: calico
              channel: latest/stable
              
            containerd:
              charm: containerd
              channel: latest/stable

          relations:
            - ["kubernetes-control-plane:kube-control", "kubernetes-worker:kube-control"]
            - ["kubernetes-control-plane:certificates", "easyrsa:client"]
            - ["etcd:certificates", "easyrsa:client"]
            - ["kubernetes-control-plane:etcd", "etcd:db"]
            - ["kubernetes-worker:certificates", "easyrsa:client"]
            - ["calico:etcd", "etcd:db"]
            - ["calico:cni", "kubernetes-control-plane:cni"]
            - ["calico:cni", "kubernetes-worker:cni"]
            - ["containerd:containerd", "kubernetes-worker:container-runtime"]
            - ["containerd:containerd", "kubernetes-control-plane:container-runtime"]

    # 3. åŸ·è¡Œéƒ¨ç½²
    - name: 3.1 éƒ¨ç½² Bundle
      shell: |
        juju deploy {{ bundle_path }} --model {{ test_model }} --trust
      register: deploy_out
      until: deploy_out.rc == 0
      retries: 3
      delay: 10

    # -----------------------------------------------------------
    # 4. ç›£æ§èˆ‡é©—æ”¶ (æ”¹ç”¨ Shell Loop è®“ Log è®Šä¹¾æ·¨)
    # -----------------------------------------------------------
    - name: 4.1 ç­‰å¾… K8s ç‹€æ…‹è®Šç‚º Active (Clean Log)
      shell: |
        echo "â³ é–‹å§‹ç›£æ¸¬ Kubernetes ç‹€æ…‹..."
        START_TIME=$(date +%s)
        TIMEOUT=1200  # è¨­å®šè¶…æ™‚ 20 åˆ†é˜
        
        while true; do
          # 1. ç²å– Worker ç‹€æ…‹
          STATUS=$(juju status --model {{ test_model }} --format json | jq -r '.applications["kubernetes-worker"]["application-status"].current')
          
          # 2. ç²å– Control Plane ç‹€æ…‹
          CP_STATUS=$(juju status --model {{ test_model }} --format json | jq -r '.applications["kubernetes-control-plane"]["application-status"].current')

          # 3. åˆ¤æ–·æ˜¯å¦å…©è€…çš†ç‚º active
          if [ "$STATUS" == "active" ] && [ "$CP_STATUS" == "active" ]; then
            echo "âœ… Kubernetes Cluster is Ready! (Worker: $STATUS, Control-Plane: $CP_STATUS)"
            exit 0
          fi

          # 4. æª¢æŸ¥è¶…æ™‚
          CURRENT_TIME=$(date +%s)
          ELAPSED_TIME=$((CURRENT_TIME - START_TIME))
          if [ $ELAPSED_TIME -ge $TIMEOUT ]; then
            echo "âŒ Timeout waiting for Kubernetes to become active."
            exit 1
          fi

          # 5. ç­‰å¾…ä¸¦é‡è©¦ (æ¯ 10 ç§’æª¢æŸ¥ä¸€æ¬¡)
          sleep 10
        done
      args:
        executable: /bin/bash
      register: k8s_wait_result
      changed_when: false 
      async: 1500
      poll: 10

    # -----------------------------------------------------------
    # è£œæ•‘æªæ–½ï¼šè§£æ±º "Unable to find pip3" èˆ‡ "kubernetes module" éŒ¯èª¤
    # -----------------------------------------------------------
    
    # ğŸŸ¢ [æ–°å¢æ­¥é©Ÿ] å…ˆå®‰è£ pip3 æœ¬é«” (é€™æ˜¯æ‚¨ç¼ºå°‘çš„æ­¥é©Ÿ)
    - name: 4.1.5 å®‰è£ç³»çµ±ç´š python3-pip
      become: yes
      ansible.builtin.apt:
        name: python3-pip
        state: present
        update_cache: yes
      # ç‚ºäº†ç¢ºä¿ä¸æœƒå¡é–ï¼Œå¯ä»¥åŠ å€‹é‡è©¦
      register: apt_result
      until: apt_result is success
      retries: 3
      delay: 5

    # ğŸŸ¢ [åŸæœ¬æ­¥é©Ÿ] æœ‰äº† pip3 ä¹‹å¾Œï¼Œæ‰èƒ½åŸ·è¡Œé€™ä¸€æ­¥
    - name: 4.2 å®‰è£ Ansible K8s æ¨¡çµ„æ‰€éœ€çš„ Python ä¾è³´åº«
      become: yes
      ansible.builtin.pip:
        name: 
          - kubernetes
          - PyYAML
        state: present
        executable: pip3

    # -----------------------------------------------------------
    # 5. Local Path Provisioner
    # -----------------------------------------------------------
    - name: 5.1 å®‰è£ Local Path Provisioner
      kubernetes.core.k8s:
        state: present
        src: https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.30/deploy/local-path-storage.yaml
      environment:
        KUBECONFIG: "/home/gary/.kube/config"

    # æ–°å¢é€™ä¸€æ®µï¼šç¢ºä¿ maasjuju æœ¬æ©Ÿæœ‰åŸ·è¡Œ k8s æ¨¡çµ„æ‰€éœ€çš„ Python åº«
    - name: 4.2 å®‰è£ Ansible K8s æ¨¡çµ„æ‰€éœ€çš„ Python ä¾è³´åº«
      become: yes  # éœ€è¦ sudo æ¬Šé™ä¾†å®‰è£ç³»çµ±å±¤ç´šçš„ Python åº«
      ansible.builtin.pip:
        name: 
          - kubernetes
          - PyYAML
        state: present
        executable: pip3

    # 5. Local Path Provisioner
    - name: 5.1 å®‰è£ Local Path Provisioner
      kubernetes.core.k8s:
        state: present
        src: https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.30/deploy/local-path-storage.yaml
      environment:
        KUBECONFIG: "/home/gary/.kube/config"

    - name: 5.2 è¨­å®šç‚ºé è¨­ StorageClass
      shell: |
        kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'

    - name: âœ… éƒ¨ç½²å®Œæˆ
      debug:
        msg: "Charmed Kubernetes å·²æˆåŠŸé–‹å§‹éƒ¨ç½²ã€‚etcd å·²ä¿®æ­£ç‚º latest/stable ä»¥æ”¯æ´ Ubuntu 22.04ã€‚"
