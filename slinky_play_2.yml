---
# ========================================================
# SKU: Slinky-App-Standalone-v4.3-FixWorkerNFS
# ä¿®æ­£ï¼š
#   1. [Critical Fix] åœ¨æ‰€æœ‰ç¯€é»å®‰è£ nfs-common (è§£æ±º mount bad option éŒ¯èª¤)
#   2. ä¿æŒ V4.2 çš„æ‰€æœ‰æ­£ç¢ºè¨­å®š (Clean Helm + Disable Rook)
# ========================================================
- name: Application Layer - Deploy Slurm (Install NFS Client)
  hosts: maasjuju
  gather_facts: yes
  vars:
    test_model: "slinky-cluster"
    release_name: "slinky"
    namespace: "slurm-cluster"
    slurm_git_url: "https://github.com/stackhpc/slurm-k8s-cluster.git"
    nfs_path: "/srv/nfs/kubedata"
    nfs_server_ip: "192.168.1.96"

  tasks:
    # -----------------------------------------------------------
    # 1. [é—œéµä¿®å¾©] ç‚ºå¢é›†å…§ "æ‰€æœ‰æ©Ÿå™¨" å®‰è£ NFS Client
    # -----------------------------------------------------------
    - name: 1.1 ç²å–æ‰€æœ‰æ©Ÿå™¨çš„ ID
      shell: juju status --model {{ test_model }} --format json | jq -r '.machines | keys[]'
      register: all_machines
    
    - name: 1.2 åœ¨æ¯ä¸€å°æ©Ÿå™¨ä¸Šå®‰è£ nfs-common
      # é€™ä¸€æ­¥æœƒè·‘è¿´åœˆï¼Œç¢ºä¿ 0, 1, 2... æ¯ä¸€å°éƒ½è£ä¸Š driver
      shell: |
        juju ssh --model {{ test_model }} {{ item }} -- \
        "sudo apt-get update && \
         sudo DEBIAN_FRONTEND=noninteractive apt-get install -y nfs-common"
      loop: "{{ all_machines.stdout_lines }}"
      changed_when: true

    # -----------------------------------------------------------
    # 2. ç¢ºä¿ PV å’Œ PVC å­˜åœ¨ (æ²¿ç”¨ V4.2 é‚è¼¯)
    # -----------------------------------------------------------
    - name: 2.1 åˆªé™¤æ“‹è·¯çš„æ‰‹å‹• PVC (å¦‚æœæœ‰çš„è©±)
      shell: |
        juju ssh --model {{ test_model }} 0 -- \
        "kubectl delete pvc slurm-shared-storage -n {{ namespace }} --wait=false 2>/dev/null || true"
      changed_when: true

    - name: 2.2 å¯«å…¥ä¸¦æ‡‰ç”¨ PV (Base64)
      vars:
        pv_yaml_content: |
          apiVersion: v1
          kind: PersistentVolume
          metadata:
            name: slurm-nfs-pv
            labels:
              type: nfs-static
          spec:
            capacity:
              storage: 20Gi
            accessModes:
              - ReadWriteMany
            persistentVolumeReclaimPolicy: Retain
            storageClassName: ""
            nfs:
              path: {{ nfs_path }}
              server: {{ nfs_server_ip }}
      shell: |
        juju ssh --model {{ test_model }} 0 -- \
        "echo '{{ pv_yaml_content | b64encode }}' | base64 -d > /home/ubuntu/slurm-pv.yaml && \
         kubectl apply -f /home/ubuntu/slurm-pv.yaml"
      changed_when: true

    # -----------------------------------------------------------
    # 3. éƒ¨ç½² Slurm
    # -----------------------------------------------------------
    - name: 3.1 ç”¢ç”Ÿ Values (å®Œç¾è¨­å®šç‰ˆ)
      vars:
        values_content: |
          global:
            clusterName: {{ test_model }}
          rook-nfs:
            enabled: false
          volumeClaim:
            create: true
            name: slurm-shared-storage
            storageClassName: ""
            volumeName: slurm-nfs-pv
            accessModes:
              - ReadWriteMany
            size: 20Gi
          controller:
            size: 10Gi
            storageClassName: "local-path"
            resources:
              limits:
                cpu: 2
                memory: 4Gi
          slurmdbd:
            enabled: true
            storageClassName: "local-path"
            size: 10Gi
          login:
            service:
              type: NodePort
              nodePort: 30022
            ssh:
              enabled: true
          worker:
            replicas: 1
            resources:
              limits:
                cpu: 8
                memory: 16Gi
      shell: |
        juju ssh --model {{ test_model }} 0 -- \
        "echo '{{ values_content | b64encode }}' | base64 -d > /home/ubuntu/slurm-static-values.yaml"
      changed_when: false

    - name: 3.2 éƒ¨ç½² Slurm
      shell: |
        juju ssh --model {{ test_model }} 0 -- \
        "helm upgrade --install {{ release_name }} ./slurm-k8s-cluster/slurm-cluster-chart \
          --namespace {{ namespace }} \
          --create-namespace \
          -f /home/ubuntu/slurm-static-values.yaml \
          --wait --timeout 15m"
      register: helm_deploy

    - name: âœ… å®Œæˆ
      debug:
        msg: 
          - "ğŸ‰ V4.3 éƒ¨ç½²æˆåŠŸï¼"
          - "æ‰€æœ‰ç¯€é»å·²å®‰è£ nfs-commonã€‚"
          - "Worker Node ç¾åœ¨æ‡‰è©²å¯ä»¥æˆåŠŸæ›è¼‰ NFS äº†ã€‚"
          - "è«‹æª¢æŸ¥ Pod: kubectl get pods -n slurm-cluster"
