---
# ========================================================
# SKU: Slinky-SlurmOnK8s-Standardized (Merged, Repeatable)
#
# Two-mode:
#   reset_before_install=true  : clean rebuild (testing)
#   reset_before_install=false : normal upgrade (daily)
#
# Includes:
#   1) NFS server (machine0) + nfs-subdir-external-provisioner + StorageClass
#   2) NVIDIA k8s-device-plugin (Helm) with tolerations + nodeSelector + affinity={}
#   3) cert-manager + slurm-operator-crds + slurm-operator + slurm (OCI chart)
#
# Pitfalls avoided:
#   - NEVER kubectl patch Controller.extraConf (Helm conflict)
#   - Partitions do NOT depend on Feature
#   - Device-plugin MUST toleration + nodeSelector; also clear affinity to avoid NFD dependency
# ========================================================

- name: Application Layer - Deploy Slinky Slurm on K8s (Standardized Merged)
  hosts: maasjuju
  gather_facts: yes

  vars:
    # ---- Mode ----
    reset_before_install: true

    # ---- Juju / machines ----
    test_model: "slinky-cluster"
    machine0: "0"                 # control-plane node (slurmhn)
    machine1: "1"                 # gpu worker node (gpu-node01)

    # ---- K8s nodes ----
    controlplane_hostname: "slurmhn"
    gpu_node_hostname: "gpu-node01"

    # ---- Namespaces ----
    ns_nfs: "nfs-provisioner"
    ns_nvidia: "nvidia-device-plugin"
    ns_certmgr: "cert-manager"
    ns_slurm_operator: "slinky"
    ns_slurm: "slurm"

    # ---- NFS (server on machine0) ----
    nfs_server_setup: true
    nfs_server: ""                # leave empty => use machine0_ip
    nfs_export_path: "/srv/nfs/k8s"
    nfs_storageclass: "nfs-rwx"
    nfs_make_default_sc: false     # if you want nfs-rwx as default SC => true

    # ---- NVIDIA device plugin ----
    gpu_taint_key: "node-role.anxpert/gpu"
    gpu_taint_value: "true"
    slurm_gpu_count: 1

    # ---- Versions ----
    cert_manager_chart_version: "v1.19.2"
    slurm_operator_chart_ver: "1.0.1"
    slurm_chart_ver: "1.0.1"

  tasks:
    # -----------------------------------------------------------
    # 1) Discover machine IPs from Juju
    # -----------------------------------------------------------
    - name: 1.1 Get Juju model status (json)
      shell: "juju status --model {{ test_model }} --format json"
      register: juju_status_raw
      changed_when: false

    - name: 1.2 Parse machine0/machine1 IPv4
      set_fact:
        machine0_ip: "{{ (juju_status_raw.stdout | from_json).machines[machine0]['ip-addresses'] | select('match','^[0-9.]+$') | first }}"
        machine1_ip: "{{ (juju_status_raw.stdout | from_json).machines[machine1]['ip-addresses'] | select('match','^[0-9.]+$') | first }}"

    - name: 1.3 Show discovered IPs
      debug:
        msg:
          - "Machine0 (control-plane) IP: {{ machine0_ip }}"
          - "Machine1 (gpu worker)    IP: {{ machine1_ip }}"

    - name: 1.4 Decide NFS server IP
      set_fact:
        nfs_server_ip: "{{ (nfs_server | trim) if (nfs_server | trim != '') else machine0_ip }}"

    # -----------------------------------------------------------
    # 2) Ensure Helm exists on machine0
    # -----------------------------------------------------------
    - name: 2.1 Install Helm on machine0 if missing
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -e
          if ! command -v helm >/dev/null 2>&1; then
            echo "[INFO] Installing Helm..."
            curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          else
            echo "[INFO] Helm already installed"
          fi
        '
      changed_when: false

    # -----------------------------------------------------------
    # 0) Reset (two-mode)
    # -----------------------------------------------------------
    - name: 0.1 Reset (helm uninstall releases)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set +e
          echo "[RESET] uninstall releases..."
          helm -n {{ ns_slurm }} uninstall slurm 2>/dev/null || true
          helm -n {{ ns_slurm_operator }} uninstall slurm-operator 2>/dev/null || true
          helm -n default uninstall slurm-operator-crds 2>/dev/null || true
          helm -n {{ ns_certmgr }} uninstall cert-manager 2>/dev/null || true
          helm -n {{ ns_nvidia }} uninstall nvidia-device-plugin 2>/dev/null || true
          helm -n {{ ns_nfs }} uninstall nfs-provisioner 2>/dev/null || true
        '
      when: reset_before_install | bool
      changed_when: true

    - name: 0.2 Reset (delete namespaces)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set +e
          echo "[RESET] delete namespaces..."
          kubectl delete ns {{ ns_slurm }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_slurm_operator }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_certmgr }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_nvidia }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_nfs }} --ignore-not-found=true --wait=true || true
        '
      when: reset_before_install | bool
      changed_when: true

    # -----------------------------------------------------------
    # 3) (Optional) Setup NFS server on machine0
    # -----------------------------------------------------------
    - name: 3.1 Setup NFS server export on machine0 (optional)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -e
          sudo apt-get update -y
          sudo apt-get install -y nfs-kernel-server
          sudo mkdir -p {{ nfs_export_path }}
          sudo chmod 777 {{ nfs_export_path }}

          EXPORT_LINE="{{ nfs_export_path }} *(rw,sync,no_subtree_check,no_root_squash)"
          if ! sudo grep -qF "{{ nfs_export_path }}" /etc/exports; then
            echo "$EXPORT_LINE" | sudo tee -a /etc/exports
          fi

          sudo exportfs -ra
          sudo systemctl enable --now nfs-server

          echo "[INFO] exportfs:"
          sudo exportfs -v | sed -n "1,120p"
        '
      when: nfs_server_setup | bool
      changed_when: true

    # -----------------------------------------------------------
    # 4) Install NFS provisioner (no heredoc)
    # -----------------------------------------------------------
    - name: 4.1 Create namespace for NFS provisioner
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          kubectl create ns {{ ns_nfs }} --dry-run=client -o yaml | kubectl apply -f -
        '
      changed_when: false

    - name: 4.2 Install/upgrade nfs-subdir-external-provisioner via Helm (values file via printf)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -euo pipefail
          helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/ >/dev/null 2>&1 || true
          helm repo update >/dev/null 2>&1

          f=/tmp/nfs-values.yaml
          : > $f
          printf "nfs:\n" >> $f
          printf "  server: %s\n" "{{ nfs_server_ip }}" >> $f
          printf "  path: %s\n" "{{ nfs_export_path }}" >> $f
          printf "storageClass:\n" >> $f
          printf "  name: %s\n" "{{ nfs_storageclass }}" >> $f
          printf "  defaultClass: %s\n" "{{ (nfs_make_default_sc | bool) | lower }}" >> $f
          printf "  reclaimPolicy: Delete\n" >> $f
          printf "  archiveOnDelete: true\n" >> $f

          helm upgrade --install nfs-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \
            -n {{ ns_nfs }} --create-namespace \
            -f $f

          echo "[INFO] storageclass:"
          kubectl get sc | sed -n "1,120p"
        '
      changed_when: true

    # -----------------------------------------------------------
    # 5) NVIDIA device plugin (Aæ–¹æ¡ˆï¼šæ¸…ç©º affinityï¼Œé¿å… NFD ä¾è³´)
    # -----------------------------------------------------------
    - name: 5.0 Precheck gpu node labels/taints
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -e
          echo "== gpu node labels =="
          kubectl get node {{ gpu_node_hostname }} --show-labels | tr "," "\n" | egrep -n "kubernetes.io/hostname|hostname" || true
          echo
          echo "== gpu node taints =="
          kubectl describe node {{ gpu_node_hostname }} | egrep -n "Taints:" -A2 || true
        '
      changed_when: false

    - name: 5.1 Create namespace for NVIDIA device plugin
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          kubectl create ns {{ ns_nvidia }} --dry-run=client -o yaml | kubectl apply -f -
        '
      changed_when: false

    - name: "5.2 Install/upgrade NVIDIA device plugin (Fix: use Heredoc)"
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -euo pipefail
          helm repo add nvidia https://nvidia.github.io/k8s-device-plugin >/dev/null 2>&1 || true
          helm repo update >/dev/null 2>&1

          # ä½¿ç”¨ Heredoc å»ºç«‹ values æª”æ¡ˆ (è§£æ±º printf ç„¡æ³•è™•ç†é–‹é ­ "-" çš„å•é¡Œ)
          cat <<EOF > /tmp/nvidia-values.yaml
          affinity: {}
          nodeSelector:
            kubernetes.io/hostname: {{ gpu_node_hostname }}
          tolerations:
          - key: {{ gpu_taint_key }}
            operator: Equal
            value: "{{ gpu_taint_value }}"
            effect: NoSchedule
          EOF

          echo "== Generated Values File =="
          cat /tmp/nvidia-values.yaml

          helm upgrade --install nvidia-device-plugin nvidia/nvidia-device-plugin \
            -n {{ ns_nvidia }} --create-namespace \
            -f /tmp/nvidia-values.yaml

          kubectl -n {{ ns_nvidia }} rollout status ds/nvidia-device-plugin --timeout=240s
        '
      changed_when: true

    - name: 5.3 Verify nvidia.com/gpu on gpu node
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -e
          kubectl describe node {{ gpu_node_hostname }} | egrep -n "Taints:|Capacity:|Allocatable:|nvidia.com/gpu" -n
        '
      changed_when: false

    # -----------------------------------------------------------
    # 6) cert-manager
    # -----------------------------------------------------------
    - name: 6.1 Create namespace cert-manager
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          kubectl create ns {{ ns_certmgr }} --dry-run=client -o yaml | kubectl apply -f -
        '
      changed_when: false

    - name: 6.2 Install/upgrade cert-manager via Helm
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -euo pipefail
          helm repo add jetstack https://charts.jetstack.io >/dev/null 2>&1 || true
          helm repo update >/dev/null 2>&1

          helm upgrade --install cert-manager jetstack/cert-manager \
            -n {{ ns_certmgr }} --create-namespace \
            --version {{ cert_manager_chart_version }} \
            --set crds.enabled=true

          kubectl -n {{ ns_certmgr }} rollout status deploy/cert-manager --timeout=240s
          kubectl -n {{ ns_certmgr }} rollout status deploy/cert-manager-webhook --timeout=240s
          kubectl -n {{ ns_certmgr }} rollout status deploy/cert-manager-cainjector --timeout=240s
        '
      changed_when: true

    # -----------------------------------------------------------
    # 7) slurm-operator-crds + slurm-operator (OCI charts)
    # -----------------------------------------------------------
    - name: 7.1 Create namespace for slurm operator
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          kubectl create ns {{ ns_slurm_operator }} --dry-run=client -o yaml | kubectl apply -f -
        '
      changed_when: false

    - name: 7.2 Install/upgrade slurm-operator-crds (OCI)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -euo pipefail
          helm upgrade --install slurm-operator-crds oci://ghcr.io/slinkyproject/charts/slurm-operator-crds \
            -n default --create-namespace \
            --version {{ slurm_operator_chart_ver }}
        '
      changed_when: true

    - name: 7.3 Install/upgrade slurm-operator (OCI)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -euo pipefail
          helm upgrade --install slurm-operator oci://ghcr.io/slinkyproject/charts/slurm-operator \
            -n {{ ns_slurm_operator }} --create-namespace \
            --version {{ slurm_operator_chart_ver }}

          kubectl -n {{ ns_slurm_operator }} rollout status deploy/slurm-operator --timeout=240s
        '
      changed_when: true

    # -----------------------------------------------------------
    # [NEW] 7.4 å¼·åˆ¶ç­‰å¾… Webhook Service æœ‰ Endpoints
    # -----------------------------------------------------------
    - name: 7.4 Wait for Slurm Operator Webhook to be functional
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -e
          echo "[INFO] Waiting for webhook service to map endpoints..."
          # è¿´åœˆæª¢æŸ¥ Service æ˜¯å¦æœ‰æ›è¼‰ IP (ä»£è¡¨ Pod Ready ä¸” Service é—œè¯æˆåŠŸ)
          for i in {1..60}; do
            EP=$(kubectl -n {{ ns_slurm_operator }} get ep slurm-operator-webhook -o jsonpath="{.subsets[*].addresses[*].ip}")
            if [ -n "$EP" ]; then
              echo "Webhook is ready with endpoints: $EP"
              exit 0
            fi
            echo "Waiting for webhook endpoints... ($i/60)"
            sleep 5
          done
          echo "[ERROR] Webhook service timed out!"
          kubectl -n {{ ns_slurm_operator }} describe pod -l control-plane=controller-manager
          exit 1
        '
      changed_when: false
      
    # -----------------------------------------------------------
    # 8) slurm chart (OCI) with stable partitions + GRES autodetect
    # -----------------------------------------------------------
    - name: 8.1 Create namespace slurm
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          kubectl create ns {{ ns_slurm }} --dry-run=client -o yaml | kubectl apply -f -
        '
      changed_when: false

    - name: 8.2 Install/upgrade slurm chart (OCI) with Heredoc & Explicit Storage
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -euo pipefail

          # ä½¿ç”¨ Heredoc ç”¢ç”Ÿ values
          cat <<EOF > /tmp/slurm-values.yaml
          controller:
            # [FIX] æ˜ç¢ºæŒ‡å®š StorageClassï¼Œä¸å†ä¾è³´å¢é›† Default
            persistence:
              enabled: true
              size: 10Gi
              storageClassName: "{{ nfs_storageclass }}"
            
            extraConf: ""
            extraConfMap: {}
            
          nodesets:
            slinky:
              enabled: true
              partition:
                enabled: false
              podSpec:
                nodeSelector:
                  kubernetes.io/hostname: {{ gpu_node_hostname }}
                  kubernetes.io/os: linux
                tolerations:
                - effect: NoSchedule
                  key: {{ gpu_taint_key }}
                  operator: Equal
                  value: "{{ gpu_taint_value }}"
                useResourceLimits: true
                slurmd:
                  resources:
                    limits:
                      nvidia.com/gpu: {{ slurm_gpu_count }}
                  args:
                  - --conf
                  - Gres=gpu:{{ slurm_gpu_count }}
          partitions:
            all:
              enabled: true
              nodesets: [ALL]
              configMap:
                Default: "YES"
                MaxTime: UNLIMITED
                State: UP
            slinky:
              enabled: true
              nodesets: [ALL]
              configMap:
                Default: "NO"
                MaxTime: UNLIMITED
                State: UP
          configFiles:
            gres.conf: |
              AutoDetect=nvidia
          EOF

          helm upgrade --install slurm oci://ghcr.io/slinkyproject/charts/slurm \
            -n {{ ns_slurm }} --create-namespace \
            --version {{ slurm_chart_ver }} \
            -f /tmp/slurm-values.yaml
        '
      changed_when: true

    # -----------------------------------------------------------
    # 9) Restart controller + worker (Robust & Debug mode)
    # -----------------------------------------------------------
    - name: 9.1 Restart slurm controller + worker pods (Robust)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -e
          echo "[INFO] 1. Deleting old pods (Waiting for termination)..."
          # --wait=true ç¢ºä¿èˆŠ Pod çœŸæ­£æ¶ˆå¤±æ‰æœƒå¾€ä¸‹ä¸€è¡ŒåŸ·è¡Œ
          kubectl -n {{ ns_slurm }} delete pod slurm-controller-0 --ignore-not-found=true --wait=true
          kubectl -n {{ ns_slurm }} delete pod slurm-worker-slinky-0 --ignore-not-found=true --wait=true

          echo "[INFO] 2. Sleeping 10s to allow StatefulSet to recreate pods..."
          sleep 10

          echo "[INFO] 3. Waiting for NEW pods to be Ready..."
          # é€™è£¡åŠ äº† || false æ•æ‰éŒ¯èª¤ï¼Œä¸¦åœ¨å¤±æ•—æ™‚å°å‡ºé™¤éŒ¯è³‡è¨Š
          if ! kubectl -n {{ ns_slurm }} wait --for=condition=Ready pod/slurm-controller-0 --timeout=300s; then
            echo "================ DEBUG INFO (Controller) ================"
            kubectl -n {{ ns_slurm }} get pods
            kubectl -n {{ ns_slurm }} describe pod slurm-controller-0
            kubectl -n {{ ns_slurm }} get pvc
            exit 1
          fi

          if ! kubectl -n {{ ns_slurm }} wait --for=condition=Ready pod/slurm-worker-slinky-0 --timeout=300s; then
            echo "================ DEBUG INFO (Worker) ================"
            kubectl -n {{ ns_slurm }} describe pod slurm-worker-slinky-0
            exit 1
          fi

          echo "[INFO] 4. All pods Ready!"
          kubectl -n {{ ns_slurm }} get pods -o wide
        '
      changed_when: true

    # -----------------------------------------------------------
    # 10) Verify (inside slurmctld pod)
    # -----------------------------------------------------------
    - name: 10.1 Verify partitions/nodes/GRES and run GPU job (inside slurmctld)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -e
          echo "== sinfo =="
          kubectl -n {{ ns_slurm }} exec slurm-controller-0 -c slurmctld -- bash -lc \
            '"'"'sinfo -o "%P %a %l %D %t %N"'"'"'

          echo
          echo "== slurm.conf partitions =="
          kubectl -n {{ ns_slurm }} exec slurm-controller-0 -c slurmctld -- bash -lc \
            '"'"'grep -n "^PartitionName=" /etc/slurm/slurm.conf'"'"'

          echo
          echo "== node GRES =="
          kubectl -n {{ ns_slurm }} exec slurm-controller-0 -c slurmctld -- bash -lc \
            '"'"'scontrol show node slinky-0 | egrep -i "NodeName=|State=|Reason=|Gres=|CfgTRES="'"'"'

          echo
          echo "== srun GPU test (default partition=all) =="
          kubectl -n {{ ns_slurm }} exec slurm-controller-0 -c slurmctld -- bash -lc \
            '"'"'srun -N1 -n1 --gres=gpu:{{ slurm_gpu_count }} bash -lc "ls -l /dev/nvidia0 && echo GPU_OK"'"'"'

          echo
          echo "== srun GPU test (partition=slinky) =="
          kubectl -n {{ ns_slurm }} exec slurm-controller-0 -c slurmctld -- bash -lc \
            '"'"'srun -p slinky -N1 -n1 --gres=gpu:{{ slurm_gpu_count }} bash -lc "ls -l /dev/nvidia0 && echo GPU_OK"'"'"'
        '
      changed_when: false

    - name: Done
      debug:
        msg:
          - "ğŸ‰ Standardized Slinky Slurm on K8s deployed"
          - "Mode reset_before_install={{ reset_before_install }}"
          - "NFS SC={{ nfs_storageclass }} (default={{ nfs_make_default_sc }})"
          - "NVIDIA device-plugin ns={{ ns_nvidia }} (nodeSelector={{ gpu_node_hostname }}, toleration {{ gpu_taint_key }}={{ gpu_taint_value }}, affinity cleared)"
          - "Slurm ns={{ ns_slurm }} partitions=all(default)+slinky, GRES autodetect nvidia"
