---
# ========================================================
# SKU: Slinky-SlurmOnK8s-Golden (IPv6-Disabled, Robust)
#
# Fixes applied:
#   1. Nuclear cleanup of conflicting NVIDIA APT repos.
#   2. System-wide IPv6 Disable (Kernel level).
#   3. Force-kill K8s processes to refresh /etc/hosts (fix ::1 resolution).
#   4. Aggressive Kube-Cache cleaning to fix Helm connection errors.
#   5. Robust Bash syntax (HereDoc) to avoid quoting errors.
# ========================================================

- name: Application Layer - Deploy Slinky Slurm on K8s (Golden Standard)
  hosts: maasjuju
  gather_facts: yes

  vars:
    # ---- Mode ----
    reset_before_install: true

    # ---- Juju / machines ----
    test_model: "slinky-cluster"
    machine0: "0"                 # control-plane node (slurmhn)
    machine1: "1"                 # gpu worker node (gpu-node01)

    # ---- K8s nodes ----
    controlplane_hostname: "slurmhn"
    gpu_node_hostname: "gpu-node01"

    # ---- Namespaces ----
    ns_nfs: "nfs-provisioner"
    ns_nvidia: "nvidia-device-plugin"
    ns_certmgr: "cert-manager"
    ns_slurm_operator: "slinky"
    ns_slurm: "slurm"

    # ---- NFS (server on machine0) ----
    nfs_server_setup: true
    nfs_server: ""                # leave empty => use machine0_ip
    nfs_export_path: "/srv/nfs/k8s"
    nfs_storageclass: "nfs-rwx"
    nfs_make_default_sc: false

    # ---- NVIDIA device plugin ----
    gpu_taint_key: "node-role.anxpert/gpu"
    gpu_taint_value: "true"
    slurm_gpu_count: 1

    # ---- Versions ----
    cert_manager_chart_version: "v1.19.2"
    slurm_operator_chart_ver: "1.0.1"
    slurm_chart_ver: "1.0.1"

  tasks:
    # -----------------------------------------------------------
    # 1) Discover machine IPs from Juju
    # -----------------------------------------------------------
    - name: 1.1 Get Juju model status (json)
      shell: "juju status --model {{ test_model }} --format json"
      register: juju_status_raw
      changed_when: false

    - name: 1.2 Parse machine0/machine1 IPv4
      set_fact:
        machine0_ip: "{{ (juju_status_raw.stdout | from_json).machines[machine0]['ip-addresses'] | select('match','^[0-9.]+$') | first }}"
        machine1_ip: "{{ (juju_status_raw.stdout | from_json).machines[machine1]['ip-addresses'] | select('match','^[0-9.]+$') | first }}"

    - name: 1.3 Show discovered IPs
      debug:
        msg:
          - "Machine0 (control-plane) IP: {{ machine0_ip }}"
          - "Machine1 (gpu worker)    IP: {{ machine1_ip }}"

    - name: 1.4 Decide NFS server IP
      set_fact:
        nfs_server_ip: "{{ (nfs_server | trim) if (nfs_server | trim != '') else machine0_ip }}"

    # -----------------------------------------------------------
    # 2) Ensure Helm exists on machine0
    # -----------------------------------------------------------
    - name: 2.1 Install Helm on machine0 if missing
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
          set -e
          if ! command -v helm >/dev/null 2>&1; then
            echo "[INFO] Installing Helm..."
            curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          else
            echo "[INFO] Helm already installed"
          fi
        EOS
      changed_when: false

    # -----------------------------------------------------------
    # 0) Reset (two-mode)
    # -----------------------------------------------------------
    - name: 0.1 Reset (helm uninstall releases)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
          set +e
          echo "[RESET] uninstall releases..."
          helm -n {{ ns_slurm }} uninstall slurm 2>/dev/null || true
          helm -n {{ ns_slurm_operator }} uninstall slurm-operator 2>/dev/null || true
          helm -n default uninstall slurm-operator-crds 2>/dev/null || true
          helm -n {{ ns_certmgr }} uninstall cert-manager 2>/dev/null || true
          helm -n {{ ns_nvidia }} uninstall nvidia-device-plugin 2>/dev/null || true
          helm -n {{ ns_nfs }} uninstall nfs-provisioner 2>/dev/null || true
        EOS
      when: reset_before_install | bool
      changed_when: true

    - name: 0.2 Reset (delete namespaces)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
          set +e
          echo "[RESET] delete namespaces..."
          kubectl delete ns {{ ns_slurm }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_slurm_operator }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_certmgr }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_nvidia }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_nfs }} --ignore-not-found=true --wait=true || true
        EOS
      when: reset_before_install | bool
      changed_when: true

    - name: 0.3 Reset (webhooks cleanup)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
          set +e
          echo "[RESET] Cleaning up all Webhooks..."
          kubectl delete mutatingwebhookconfigurations -l app.kubernetes.io/name=slurm-operator --ignore-not-found=true
          kubectl delete validatingwebhookconfigurations -l app.kubernetes.io/name=slurm-operator --ignore-not-found=true
        EOS
      when: reset_before_install | bool
      changed_when: true

    # -----------------------------------------------------------
    # 3) Install NFS Utils (With Repo Cleanup First)
    # -----------------------------------------------------------
    - name: 3.0 Setup NFS server export on machine0
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
        set -euo pipefail
        export DEBIAN_FRONTEND=noninteractive NEEDRESTART_MODE=a
        sudo -n true

        echo "[INFO] wait dpkg lock..."
        while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do echo "[WAIT]"; sleep 5; done
        
        # Cleanup potential bad repos first
        sudo rm -f /etc/apt/sources.list.d/nvidia-*.list 2>/dev/null || true
        
        timeout 600 sudo apt-get -o Acquire::ForceIPv4=true update -y
        timeout 600 sudo apt-get -o Acquire::ForceIPv4=true install -y nfs-kernel-server

        sudo mkdir -p {{ nfs_export_path }}
        sudo chmod 777 {{ nfs_export_path }}
        sudo mkdir -p /etc/exports.d
        sudo touch /etc/exports
        
        EXPORT_LINE="{{ nfs_export_path }} *(rw,sync,no_subtree_check,no_root_squash)"
        echo "$EXPORT_LINE" | sudo tee /etc/exports.d/k8s.exports >/dev/null
        sudo exportfs -ra
        sudo systemctl enable --now nfs-server
        EOS
      when: nfs_server_setup | bool
      changed_when: true

    - name: 3.1 Install nfs-common on k8s nodes (CLEANUP BROKEN REPOS FIRST)
      shell: |
        juju ssh --model {{ test_model }} {{ item }} -- bash -s <<'EOS'
        set -euo pipefail
        export DEBIAN_FRONTEND=noninteractive NEEDRESTART_MODE=a
        sudo -n true

        # --- [CRITICAL FIX] ---
