---
# ========================================================
# Scenario: Post-Deployment - DCGM & KubeSphere Registration
# Goal: Deploy K8s-native DCGM & Register Cluster to Host
# ========================================================
- name: 4. è¨­å®šç›£æ§èˆ‡å¤šå¢é›†å°æ¥
  hosts: maasjuju
  gather_facts: no
  vars:
    # ---- Juju / Model è¨­å®š ----
    test_model: "slinky-cluster"
    machine0: "0"  # Control Plane (slurmhn)
    
    # ---- KubeSphere Host è¨­å®š (è«‹ä¿®æ”¹é€™è£¡) ----
    ks_host_ip: "192.168.100.4"      # ä½ çš„ KubeSphere ä¸»æ©Ÿ IP
    ks_host_user: "ubuntu"           # SSH ä½¿ç”¨è€…
    k8s_cluster_name: "slinky-k8s"   # åœ¨ KubeSphere ä¸Šé¡¯ç¤ºçš„åç¨±

  tasks:
    # -----------------------------------------------------------
    # 1. éƒ¨ç½² K8s åŸç”Ÿç‰ˆ DCGM Exporter
    #    (å–ä»£èˆŠçš„ Snap å®‰è£ï¼Œé€™æ˜¯ Cloud Native çš„åšæ³•)
    # -----------------------------------------------------------
    - name: 1.1 å®‰è£ DCGM Exporter (Helm / Manifest)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
        set -euo pipefail
        
        # 1. åŠ å…¥ NVIDIA Helm Repo
        helm repo add nvidia https://nvidia.github.io/dcgm-exporter/helm-charts >/dev/null 2>&1 || true
        helm repo update >/dev/null 2>&1

        # 2. å®‰è£ DCGM Exporter (DaemonSet)
        # é€™æ¨£æœƒè‡ªå‹•åœ¨æ‰€æœ‰ GPU ç¯€é» (gpu-node01) ä¸Šè·‘ä¸€å€‹ Pod
        helm upgrade --install dcgm-exporter nvidia/dcgm-exporter \
          -n kubesphere-monitoring-system --create-namespace \
          --set serviceMonitor.enabled=true \
          --set serviceMonitor.additionalLabels.app\.kubernetes\.io/vendor=kubesphere
        
        # 3. ç­‰å¾… Pod å•Ÿå‹•
        kubectl -n kubesphere-monitoring-system rollout status daemonset/dcgm-exporter --timeout=300s
        EOS
      changed_when: true

    # -----------------------------------------------------------
    # 2. ç²å– Kubeconfig ç”¨æ–¼è¨»å†Š
    # -----------------------------------------------------------
    - name: 2.1 ç²å– Machine 0 (Master) å¯¦é«” IP
      shell: "juju ssh --model {{ test_model }} {{ machine0 }} 'hostname -I' | awk '{print $1}'"
      register: master_ip_result

    - name: 2.2 æŠ“å–ä¸¦ä¿®æ­£ Kubeconfig (Base64)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
          # è®€å– configï¼Œå°‡å…§éƒ¨ IP (127.0.0.1) æ›¿æ›ç‚ºå¤–éƒ¨å¯¦é«” IP
          # é€™æ¨£ KubeSphere Host æ‰èƒ½é€£éä¾†
          cat ~/.kube/config | sed "s/127.0.0.1/{{ master_ip_result.stdout | trim }}/g" | sed "s/localhost/{{ master_ip_result.stdout | trim }}/g" | base64 -w 0
        EOS
      register: kubeconfig_b64

    # -----------------------------------------------------------
    # 3. æº–å‚™ KubeSphere Host é€£ç·š
    # -----------------------------------------------------------
    - name: 3.1 åŠ å…¥ KubeSphere Host åˆ° Inventory
      add_host:
        name: "ks_host"
        ansible_host: "{{ ks_host_ip }}"
        ansible_user: "{{ ks_host_user }}"
        cluster_name: "{{ k8s_cluster_name }}"
        cluster_config: "{{ kubeconfig_b64.stdout }}"

# ========================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šåœ¨ KubeSphere Host ä¸ŠåŸ·è¡Œè¨»å†Š
# ========================================================
- name: 5. åŸ·è¡Œ KubeSphere è¨»å†Š
  hosts: ks_host
  gather_facts: no
  vars:
    member_config_file: "/tmp/kubeconfig-{{ cluster_name }}"

  tasks:
    - name: 5.1 æ³¨å…¥ Member Cluster CRD
      shell: |
        cat <<EOF | kubectl apply -f -
        apiVersion: cluster.kubesphere.io/v1alpha1
        kind: Cluster
        metadata:
          name: {{ cluster_name }}
          labels:
            kubesphere.io/managed: "true"
            cluster-role.kubesphere.io/member: ""
        spec:
          provider: kubernetes
          joinFederation: true
          connection:
            type: direct
            kubeconfig: {{ cluster_config }}
        EOF

    # --------------------------------------------------------
    # 5.2 ç¢ºä¿ç›£æ§æ•¸æ“šå°æ¥ (ServiceMonitor)
    # --------------------------------------------------------
    - name: 5.2 å»ºç«‹ ServiceMonitor è£œä¸ (ç¢ºä¿ KS èƒ½æŠ“åˆ° DCGM)
      shell: |
        # è§£ç¢¼ kubeconfig åˆ°è‡¨æ™‚æª”ï¼Œä»¥ä¾¿æ“ä½œ Member Cluster
        echo "{{ cluster_config }}" | base64 -d > {{ member_config_file }}

        # åœ¨ Member Cluster (Slurm K8s) è£¡é¢è£œä¸Šç‰¹å®šçš„ ServiceMonitor è¨­å®š
        # é›–ç„¶ Helm è£äº† ServiceMonitorï¼Œä½†æœ‰æ™‚å€™ Label å°ä¸ä¸Š KS çš„é è¨­æŠ“å–è¦å‰‡
        cat <<EOF | kubectl --kubeconfig {{ member_config_file }} apply -f -
        apiVersion: monitoring.coreos.com/v1
        kind: ServiceMonitor
        metadata:
          name: dcgm-exporter-ks-patch
          namespace: kubesphere-monitoring-system
          labels:
            app.kubernetes.io/vendor: kubesphere  # é€™æ˜¯é—œéµ Label
        spec:
          selector:
            matchLabels:
              app.kubernetes.io/name: dcgm-exporter
          endpoints:
          - port: metrics
            path: /metrics
            interval: 15s
          namespaceSelector:
            matchNames:
            - kubesphere-monitoring-system
        EOF

    - name: 5.3 æ¸…ç†
      file:
        path: "{{ member_config_file }}"
        state: absent

    - name: ğŸš€ å®Œæˆæç¤º
      debug:
        msg: 
          - "âœ… DCGM Exporter å·²å®‰è£åœ¨ K8s å¢é›†å…§ (DaemonSet æ¨¡å¼)"
          - "âœ… å¢é›† '{{ cluster_name }}' å·²è¨»å†Šåˆ° KubeSphere"
          - "âš ï¸  è«‹å‰å¾€ KubeSphere ä»‹é¢ -> 'å¹³å°ç®¡ç†' -> 'å¢é›†ç®¡ç†'"
          - "   ç¢ºèª {{ cluster_name }} ç‹€æ…‹ç‚º 'é‹è¡Œä¸­'ã€‚"
          - "   ç­‰å¾…ç´„ 3-5 åˆ†é˜ï¼ŒGPU ç›£æ§æ•¸æ“šæ‡‰æœƒè‡ªå‹•å‡ºç¾åœ¨å„€è¡¨æ¿ã€‚"
