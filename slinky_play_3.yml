---
# ========================================================
# Scenario: Post-Deployment - DCGM & KubeSphere Registration
# Goal: Deploy K8s-native DCGM (Restricted to GPU Node)
# ========================================================
- name: 4. è¨­å®šç›£æ§èˆ‡å¤šå¢é›†å°æ¥
  hosts: maasjuju
  gather_facts: no
  vars:
    # ---- Juju / Model è¨­å®š ----
    test_model: "slinky-cluster"
    machine0: "0"
    
    # ---- é—œéµä¿®æ­£ï¼šæŒ‡å®š GPU ç¯€é»åç¨± ----
    # (å¿…é ˆè·Ÿä½ åœ¨ K8s è£¡çœ‹åˆ°çš„ Node Name ä¸€æ¨£ï¼Œé€šå¸¸æ˜¯ gpu-node01)
    gpu_node_hostname: "gpu-node01" 
    
    # ---- KubeSphere Host è¨­å®š ----
    ks_host_ip: "192.168.100.4"
    ks_host_user: "ubuntu"
    k8s_cluster_name: "slinky-k8s"

  tasks:
    # -----------------------------------------------------------
    # 1. éƒ¨ç½² K8s åŸç”Ÿç‰ˆ DCGM Exporter
    # -----------------------------------------------------------
    
    # [æ­¥é©Ÿ 1.0] é å…ˆå®‰è£ ServiceMonitor CRD
    - name: 1.0 é å…ˆå®‰è£ Prometheus CRD (ServiceMonitor)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
        set -euo pipefail
        kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.68.0/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml
        EOS
      changed_when: true

    # [æ­¥é©Ÿ 1.1] å®‰è£ DCGM Exporter (Fix: å¢åŠ  NodeSelector)
    - name: 1.1 å®‰è£ DCGM Exporter (Restricted to GPU Nodes)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
        set -euo pipefail
        
        # 1. åŠ å…¥ Repo
        helm repo add gpu-helm-charts https://nvidia.github.io/dcgm-exporter/helm-charts >/dev/null 2>&1 || true
        helm repo update >/dev/null 2>&1

        # 2. å»ºç«‹ Values æª”æ¡ˆ (é‡é»ä¿®æ­£ï¼šnodeSelector)
        cat > /tmp/dcgm-values.yaml <<EOF
        serviceMonitor:
          enabled: true
          additionalLabels:
            app.kubernetes.io/vendor: kubesphere
        
        resources:
          limits:
            cpu: 500m
            memory: 512Mi
          requests:
            cpu: 100m
            memory: 128Mi
            
        # [FIX] é—œéµä¿®æ­£ï¼šåªå…è¨±åœ¨æŒ‡å®šç¯€é»é‹è¡Œ
        nodeSelector:
          kubernetes.io/hostname: {{ gpu_node_hostname }}
          
        # [Optional] å¦‚æœç¯€é»æœ‰ Taintï¼Œéœ€è¦å®¹å¿å®ƒ
        tolerations:
          - key: "node-role.anxpert/gpu"
            operator: "Exists"
            effect: "NoSchedule"

        hostPath:
          root: "/"
        EOF

        # 3. å®‰è£
        helm upgrade --install dcgm-exporter gpu-helm-charts/dcgm-exporter \
          -n kubesphere-monitoring-system --create-namespace \
          -f /tmp/dcgm-values.yaml
        
        # 4. ç­‰å¾… Pod å•Ÿå‹• (é€™æ¬¡åªæœƒæœ‰ä¸€é¡† Pod è·‘èµ·ä¾†ï¼Œè€Œä¸”æ˜¯ Running)
        kubectl -n kubesphere-monitoring-system rollout status daemonset/dcgm-exporter --timeout=300s
        EOS
      changed_when: true

    # -----------------------------------------------------------
    # 2. ç²å– Kubeconfig ç”¨æ–¼è¨»å†Š
    # -----------------------------------------------------------
    - name: 2.1 ç²å– Machine 0 (Master) å¯¦é«” IP
      shell: "juju ssh --model {{ test_model }} {{ machine0 }} 'hostname -I' | awk '{print $1}'"
      register: master_ip_result

    - name: 2.2 æŠ“å–ä¸¦ä¿®æ­£ Kubeconfig (Base64)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
          cat ~/.kube/config | sed "s/127.0.0.1/{{ master_ip_result.stdout | trim }}/g" | sed "s/localhost/{{ master_ip_result.stdout | trim }}/g" | base64 -w 0
        EOS
      register: kubeconfig_b64

    # -----------------------------------------------------------
    # 3. æº–å‚™ KubeSphere Host é€£ç·š
    # -----------------------------------------------------------
    - name: 3.1 åŠ å…¥ KubeSphere Host åˆ° Inventory
      add_host:
        name: "ks_host"
        ansible_host: "{{ ks_host_ip }}"
        ansible_user: "{{ ks_host_user }}"
        cluster_name: "{{ k8s_cluster_name }}"
        cluster_config: "{{ kubeconfig_b64.stdout }}"

# ========================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šåœ¨ KubeSphere Host ä¸ŠåŸ·è¡Œè¨»å†Š
# ========================================================
- name: 5. åŸ·è¡Œ KubeSphere è¨»å†Š
  hosts: ks_host
  gather_facts: no
  vars:
    member_config_file: "/tmp/kubeconfig-{{ cluster_name }}"

  tasks:
    - name: 5.1 æ³¨å…¥ Member Cluster CRD
      shell: |
        cat <<EOF | kubectl apply -f -
        apiVersion: cluster.kubesphere.io/v1alpha1
        kind: Cluster
        metadata:
          name: {{ cluster_name }}
          labels:
            kubesphere.io/managed: "true"
            cluster-role.kubesphere.io/member: ""
        spec:
          provider: kubernetes
          joinFederation: true
          connection:
            type: direct
            kubeconfig: {{ cluster_config }}
        EOF

    - name: 5.2 å»ºç«‹ ServiceMonitor è£œä¸
      shell: |
        echo "{{ cluster_config }}" | base64 -d > {{ member_config_file }}

        cat <<EOF | kubectl --kubeconfig {{ member_config_file }} apply -f -
        apiVersion: monitoring.coreos.com/v1
        kind: ServiceMonitor
        metadata:
          name: dcgm-exporter-ks-patch
          namespace: kubesphere-monitoring-system
          labels:
            app.kubernetes.io/vendor: kubesphere
        spec:
          selector:
            matchLabels:
              app.kubernetes.io/name: dcgm-exporter
          endpoints:
          - port: metrics
            path: /metrics
            interval: 15s
          namespaceSelector:
            matchNames:
            - kubesphere-monitoring-system
        EOF

    - name: 5.3 æ¸…ç†
      file:
        path: "{{ member_config_file }}"
        state: absent

    - name: ğŸš€ å®Œæˆæç¤º
      debug:
        msg: 
          - "âœ… DCGM Exporter å·²ä¿®æ­£ (åªåœ¨ GPU ç¯€é»é‹è¡Œ)"
          - "âœ… Master ç¯€é»ä¸æœƒå†å‡ºç¾ CrashLoopBackOff çš„ Pod"
          - "âœ… å¢é›†è¨»å†Šå®Œæˆï¼è«‹å» KubeSphere é©—æ”¶ GPU ç›£æ§æ•¸æ“šã€‚"
