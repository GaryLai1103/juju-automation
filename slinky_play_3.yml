---
# ========================================================
# SKU: Slinky-SlurmOnK8s-Standardized (Merged, Repeatable)
#
# Two-mode:
#Â  Â reset_before_install=trueÂ  : clean rebuild (testing)
#Â  Â reset_before_install=false : normal upgrade (daily)
#
# Includes:
#Â  Â 1) NFS server (machine0) + nfs-subdir-external-provisioner + StorageClass
#Â  Â 2) NVIDIA k8s-device-plugin (Helm) with tolerations + nodeSelector + affinity={}
#Â  Â 3) cert-manager + slurm-operator-crds + slurm-operator + slurm (OCI chart)
#
# Pitfalls avoided:
#Â  Â - NEVER kubectl patch Controller.extraConf (Helm conflict)
#Â  Â - Partitions do NOT depend on Feature
#Â  Â - Device-plugin MUST toleration + nodeSelector; also clear affinity to avoid NFD dependency
# ========================================================

- name: Application Layer - Deploy Slinky Slurm on K8s (Standardized Merged)
  hosts: maasjuju
  gather_facts: yes
Â  vars:
Â  Â  # ---- Mode ----
Â  Â  reset_before_install: true

Â  Â  # ---- Juju / machines ----
Â  Â  test_model: "slinky-cluster"
Â  Â  machine0: "0"Â  Â  Â  Â  Â  Â  Â  Â  Â # control-plane node (slurmhn)
Â  Â  machine1: "1"Â  Â  Â  Â  Â  Â  Â  Â  Â # gpu worker node (gpu-node01)

Â  Â  # ---- K8s nodes ----
Â  Â  controlplane_hostname: "slurmhn"
Â  Â  gpu_node_hostname: "gpu-node01"

Â  Â  # ---- Namespaces ----
Â  Â  ns_nfs: "nfs-provisioner"
Â  Â  ns_nvidia: "nvidia-device-plugin"
Â  Â  ns_certmgr: "cert-manager"
Â  Â  ns_slurm_operator: "slinky"
Â  Â  ns_slurm: "slurm"

Â  Â  # ---- NFS (server on machine0) ----
Â  Â  nfs_server_setup: true
Â  Â  nfs_server: ""Â  Â  Â  Â  Â  Â  Â  Â  # leave empty => use machine0_ip
Â  Â  nfs_export_path: "/srv/nfs/k8s"
Â  Â  nfs_storageclass: "nfs-rwx"
Â  Â  nfs_make_default_sc: falseÂ  Â  Â # if you want nfs-rwx as default SC => true

Â  Â  # ---- NVIDIA device plugin ----
Â  Â  gpu_taint_key: "node-role.anxpert/gpu"
Â  Â  gpu_taint_value: "true"
Â  Â  slurm_gpu_count: 1

Â  Â  # ---- Versions ----
Â  Â  cert_manager_chart_version: "v1.19.2"
Â  Â  slurm_operator_chart_ver: "1.0.1"
Â  Â  slurm_chart_ver: "1.0.1"

Â  tasks:
Â  Â  # -----------------------------------------------------------
Â  Â  # 1) Discover machine IPs from Juju
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 1.1 Get Juju model status (json)
Â  Â  Â  shell: "juju status --model {{ test_model }} --format json"
Â  Â  Â  register: juju_status_raw
Â  Â  Â  changed_when: false

Â  Â  - name: 1.2 Parse machine0/machine1 IPv4
Â  Â  Â  set_fact:
Â  Â  Â  Â  machine0_ip: "{{ (juju_status_raw.stdout | from_json).machines[machine0]['ip-addresses'] | select('match','^[0-9.]+$') | first }}"
Â  Â  Â  Â  machine1_ip: "{{ (juju_status_raw.stdout | from_json).machines[machine1]['ip-addresses'] | select('match','^[0-9.]+$') | first }}"

Â  Â  - name: 1.3 Show discovered IPs
Â  Â  Â  debug:
Â  Â  Â  Â  msg:
Â  Â  Â  Â  Â  - "Machine0 (control-plane) IP: {{ machine0_ip }}"
Â  Â  Â  Â  Â  - "Machine1 (gpu worker)Â  Â  IP: {{ machine1_ip }}"

Â  Â  - name: 1.4 Decide NFS server IP
Â  Â  Â  set_fact:
Â  Â  Â  Â  nfs_server_ip: "{{ (nfs_server | trim) if (nfs_server | trim != '') else machine0_ip }}"

Â  Â  # -----------------------------------------------------------
Â  Â  # 2) Ensure Helm exists on machine0
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 2.1 Install Helm on machine0 if missing
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  set -e
Â  Â  Â  Â  Â  if ! command -v helm >/dev/null 2>&1; then
Â  Â  Â  Â  Â  Â  echo "[INFO] Installing Helm..."
Â  Â  Â  Â  Â  Â  curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
Â  Â  Â  Â  Â  else
Â  Â  Â  Â  Â  Â  echo "[INFO] Helm already installed"
Â  Â  Â  Â  Â  fi
Â  Â  Â  Â  '
Â  Â  Â  changed_when: false

Â  Â  # -----------------------------------------------------------
Â  Â  # 0) Reset (two-mode)
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 0.1 Reset (helm uninstall releases)
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  set +e
Â  Â  Â  Â  Â  echo "[RESET] uninstall releases..."
Â  Â  Â  Â  Â  helm -n {{ ns_slurm }} uninstall slurm 2>/dev/null || true
Â  Â  Â  Â  Â  helm -n {{ ns_slurm_operator }} uninstall slurm-operator 2>/dev/null || true
Â  Â  Â  Â  Â  helm -n default uninstall slurm-operator-crds 2>/dev/null || true
Â  Â  Â  Â  Â  helm -n {{ ns_certmgr }} uninstall cert-manager 2>/dev/null || true
Â  Â  Â  Â  Â  helm -n {{ ns_nvidia }} uninstall nvidia-device-plugin 2>/dev/null || true
Â  Â  Â  Â  Â  helm -n {{ ns_nfs }} uninstall nfs-provisioner 2>/dev/null || true
Â  Â  Â  Â  '
Â  Â  Â  when: reset_before_install | bool
Â  Â  Â  changed_when: true

Â  Â  - name: 0.2 Reset (delete namespaces)
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  set +e
Â  Â  Â  Â  Â  echo "[RESET] delete namespaces..."
Â  Â  Â  Â  Â  kubectl delete ns {{ ns_slurm }} --ignore-not-found=true --wait=true || true
Â  Â  Â  Â  Â  kubectl delete ns {{ ns_slurm_operator }} --ignore-not-found=true --wait=true || true
Â  Â  Â  Â  Â  kubectl delete ns {{ ns_certmgr }} --ignore-not-found=true --wait=true || true
Â  Â  Â  Â  Â  kubectl delete ns {{ ns_nvidia }} --ignore-not-found=true --wait=true || true
Â  Â  Â  Â  Â  kubectl delete ns {{ ns_nfs }} --ignore-not-found=true --wait=true || true
Â  Â  Â  Â  '
Â  Â  Â  when: reset_before_install | bool
Â  Â  Â  changed_when: true

    - name: 0.3 Reset (cluster-scoped MUTATING webhooks for slurm-operator only) - keep validating
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set +e
          echo "[RESET] delete MUTATING webhook configs for slurm-operator (keep validating)..."
          kubectl delete mutatingwebhookconfigurations -l app.kubernetes.io/name=slurm-operator --ignore-not-found=true
          echo "== mutatingwebhookconfigurations (filtered) =="
          kubectl get mutatingwebhookconfigurations | egrep -i "slurm|slinky|operator|webhook" || true
          echo "== validatingwebhookconfigurations (filtered) =="
          kubectl get validatingwebhookconfigurations | egrep -i "slurm|slinky|operator|webhook" || true
        '
      when: reset_before_install | bool
      changed_when: true

Â  Â  # -----------------------------------------------------------
Â  Â  # 3.0 Install NFS client utils on ALL nodes (IMPORTANT)
Â  Â  # - Fix: mount: bad option ... need /sbin/mount.nfs
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 3.0 Setup NFS server export on machine0 (robust)
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
Â  Â  Â  Â  set -euo pipefail
Â  Â  Â  Â  export DEBIAN_FRONTEND=noninteractive NEEDRESTART_MODE=a

Â  Â  Â  Â  sudo -n true

Â  Â  Â  Â  echo "[INFO] wait dpkg lock..."
Â  Â  Â  Â  while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
Â  Â  Â  Â  Â  echo "[WAIT] dpkg lock held..."; sleep 5
Â  Â  Â  Â  done

Â  Â  Â  Â  timeout 600 sudo apt-get -o Acquire::ForceIPv4=true update -y

Â  Â  Â  Â  while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
Â  Â  Â  Â  Â  echo "[WAIT] dpkg lock held..."; sleep 5
Â  Â  Â  Â  done

Â  Â  Â  Â  timeout 600 sudo apt-get -o Acquire::ForceIPv4=true install -y nfs-kernel-server

Â  Â  Â  Â  sudo mkdir -p {{ nfs_export_path }}
Â  Â  Â  Â  sudo chmod 777 {{ nfs_export_path }}
Â  Â  Â  Â  sudo mkdir -p /etc/exports.d

Â  Â  Â  Â  # MUST exist, or exportfs will complain
Â  Â  Â  Â  sudo touch /etc/exports
Â  Â  Â  Â  sudo chmod 644 /etc/exports

Â  Â  Â  Â  EXPORT_LINE="{{ nfs_export_path }} *(rw,sync,no_subtree_check,no_root_squash)"
Â  Â  Â  Â  echo "$EXPORT_LINE" | sudo tee /etc/exports.d/k8s.exports >/dev/null

Â  Â  Â  Â  sudo exportfs -ra
Â  Â  Â  Â  timeout 60 sudo systemctl enable --now nfs-server

Â  Â  Â  Â  echo "[INFO] exportfs:"
Â  Â  Â  Â  sudo exportfs -v | sed -n "1,120p"
Â  Â  Â  Â  EOS
Â  Â  Â  when: nfs_server_setup | bool
Â  Â  Â  changed_when: true

Â  Â  - name: 3.1 Install nfs-common on k8s nodes (required for NFS mounts) - robust + wait dpkg lock
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ item }} -- bash -s <<'EOS'
Â  Â  Â  Â  set -euo pipefail
Â  Â  Â  Â  export DEBIAN_FRONTEND=noninteractive NEEDRESTART_MODE=a
Â  Â Â 
Â  Â  Â  Â  sudo -n true
Â  Â Â 
Â  Â  Â  Â  echo "[INFO] wait dpkg/apt lock (unattended-upgrades)..."
Â  Â  Â  Â  while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
Â  Â  Â  Â  Â  echo "[WAIT] dpkg lock held..."; sleep 5
Â  Â  Â  Â  done
Â  Â Â 
Â  Â  Â  Â  timeout 600 sudo apt-get -o Acquire::ForceIPv4=true update -y
Â  Â Â 
Â  Â  Â  Â  while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
Â  Â  Â  Â  Â  echo "[WAIT] dpkg lock held..."; sleep 5
Â  Â  Â  Â  done
Â  Â Â 
Â  Â  Â  Â  timeout 600 sudo apt-get -o Acquire::ForceIPv4=true install -y nfs-common
Â  Â Â 
Â  Â  Â  Â  command -v mount.nfs || ls -l /sbin/mount.nfs* || true
Â  Â  Â  Â  EOS
Â  Â  Â  loop:
Â  Â  Â  Â  - "{{ machine0 }}"
Â  Â  Â  Â  - "{{ machine1 }}"
Â  Â  Â  changed_when: true

Â  Â  # -----------------------------------------------------------
Â  Â  # 4) Install NFS provisioner (no heredoc)
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 4.1 Create namespace for NFS provisioner
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  kubectl create ns {{ ns_nfs }} --dry-run=client -o yaml | kubectl apply -f -
Â  Â  Â  Â  '
Â  Â  Â  changed_when: false

Â  Â  - name: 4.2 Install/upgrade nfs-subdir-external-provisioner via Helm (values file via printf)
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  set -euo pipefail
Â  Â  Â  Â  Â  helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/ >/dev/null 2>&1 || true
Â  Â  Â  Â  Â  helm repo update >/dev/null 2>&1

Â  Â  Â  Â  Â  f=/tmp/nfs-values.yaml
Â  Â  Â  Â  Â  : > $f
Â  Â  Â  Â  Â  printf "nfs:\n" >> $f
Â  Â  Â  Â  Â  printf "Â  server: %s\n" "{{ nfs_server_ip }}" >> $f
Â  Â  Â  Â  Â  printf "Â  path: %s\n" "{{ nfs_export_path }}" >> $f
Â  Â  Â  Â  Â  printf "storageClass:\n" >> $f
Â  Â  Â  Â  Â  printf "Â  name: %s\n" "{{ nfs_storageclass }}" >> $f
Â  Â  Â  Â  Â  printf "Â  defaultClass: %s\n" "{{ (nfs_make_default_sc | bool) | lower }}" >> $f
Â  Â  Â  Â  Â  printf "Â  reclaimPolicy: Delete\n" >> $f
Â  Â  Â  Â  Â  printf "Â  archiveOnDelete: true\n" >> $f

Â  Â  Â  Â  Â  helm upgrade --install nfs-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \
Â  Â  Â  Â  Â  Â  -n {{ ns_nfs }} --create-namespace \
Â  Â  Â  Â  Â  Â  -f $f

Â  Â  Â  Â  Â  echo "[INFO] storageclass:"
Â  Â  Â  Â  Â  kubectl get sc | sed -n "1,120p"
Â  Â  Â  Â  '
Â  Â  Â  changed_when: true

Â  Â  - name: 4.5 Install NVIDIA Container Toolkit on GPU Node (Machine 1) - robust
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine1 }} -- bash -lc '
Â  Â  Â  Â  Â  set -euo pipefail
Â  Â  Â  Â  Â  export DEBIAN_FRONTEND=noninteractive NEEDRESTART_MODE=a

Â  Â  Â  Â  Â  sudo -n true

Â  Â  Â  Â  Â  # idempotency quick check
Â  Â  Â  Â  Â  if dpkg -l | grep -q "^iiÂ  nvidia-container-toolkit"; then
Â  Â  Â  Â  Â  Â  echo "[INFO] nvidia-container-toolkit already installed."
Â  Â  Â  Â  Â  fi

Â  Â  Â  Â  Â  echo "[INFO] wait dpkg/apt lock (unattended-upgrades)..."
Â  Â  Â  Â  Â  while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
Â  Â  Â  Â  Â  Â  echo "[WAIT] dpkg lock held..."; sleep 5
Â  Â  Â  Â  Â  done

Â  Â  Â  Â  Â  echo "[INFO] add NVIDIA Container Toolkit repo (IPv4 + retry)..."
Â  Â  Â  Â  Â  curl -4 --retry 6 --retry-delay 2 --retry-connrefused -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

Â  Â  Â  Â  Â  curl -4 --retry 6 --retry-delay 2 --retry-connrefused -fsSL https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
Â  Â  Â  Â  Â  Â  sed "s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g" | \
Â  Â  Â  Â  Â  Â  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list >/dev/null

Â  Â  Â  Â  Â  echo "[INFO] apt update/install (ForceIPv4 + lock wait)..."
Â  Â  Â  Â  Â  timeout 600 sudo apt-get -o Acquire::ForceIPv4=true update -y

Â  Â  Â  Â  Â  while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
Â  Â  Â  Â  Â  Â  echo "[WAIT] dpkg lock held..."; sleep 5
Â  Â  Â  Â  Â  done

Â  Â  Â  Â  Â  timeout 600 sudo apt-get -o Acquire::ForceIPv4=true install -y nvidia-container-toolkit

Â  Â  Â  Â  Â  echo "[INFO] configure containerd runtime..."
Â  Â  Â  Â  Â  sudo nvidia-ctk runtime configure --runtime=containerd

Â  Â  Â  Â  Â  echo "[INFO] restart containerd + kubelet..."
Â  Â  Â  Â  Â  sudo systemctl restart containerd
Â  Â  Â  Â  Â  sudo systemctl restart kubelet || true

Â  Â  Â  Â  Â  echo "[INFO] quick verify:"
Â  Â  Â  Â  Â  command -v nvidia-ctk || true
Â  Â  Â  Â  Â  sudo ctr version || true
Â  Â  Â  Â  Â  sudo grep -n "nvidia" /etc/containerd/config.toml | head -n 40 || true

Â  Â  Â  Â  Â  echo "âœ… NVIDIA Container Toolkit ready"
Â  Â  Â  Â  '
Â  Â  Â  changed_when: true


Â  Â  - name: 4.6 Prefer IPv4 for image pulls on ALL nodes (Machine 0 + 1)
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ item }} -- bash -lc '
Â  Â  Â  Â  Â  set -euo pipefail

Â  Â  Â  Â  Â  # 1) glibc resolver prefer IPv4-mapped
Â  Â  Â  Â  Â  if [ ! -f /etc/gai.conf ]; then
Â  Â  Â  Â  Â  Â  echo "precedence ::ffff:0:0/96Â  100" | sudo tee /etc/gai.conf >/dev/null
Â  Â  Â  Â  Â  else
Â  Â  Â  Â  Â  Â  grep -q "precedence ::ffff:0:0/96" /etc/gai.conf || echo "precedence ::ffff:0:0/96Â  100" | sudo tee -a /etc/gai.conf >/dev/null
Â  Â  Â  Â  Â  Â  sudo sed -i "s/^[# ]*precedence ::ffff:0:0\/96.*/precedence ::ffff:0:0\/96Â  100/" /etc/gai.conf
Â  Â  Â  Â  Â  fi

Â  Â  Â  Â  Â  echo "== /etc/gai.conf (effective) =="
Â  Â  Â  Â  Â  grep -nE "precedence ::ffff:0:0/96" /etc/gai.conf || true

Â  Â  Â  Â  Â  # 2) restart container runtime / kubelet (best-effort)
Â  Â  Â  Â  Â  sudo systemctl restart containerd || true
Â  Â  Â  Â  Â  sudo systemctl restart kubeletÂ  Â || true

Â  Â  Â  Â  Â  echo "âœ… Prefer IPv4 applied on node={{ item }}"
Â  Â  Â  Â  '
Â  Â  Â  loop:
Â  Â  Â  Â  - "{{ machine0 }}"
Â  Â  Â  Â  - "{{ machine1 }}"
Â  Â  Â  changed_when: true

Â  Â  # -----------------------------------------------------------
Â  Â  # 5) NVIDIA device plugin (Aæ–¹æ¡ˆï¼šæ¸…ç©º affinityï¼Œé¿å… NFD ä¾è³´)
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 5.0 Precheck gpu node labels/taints
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  set -e
Â  Â  Â  Â  Â  echo "== gpu node labels =="
Â  Â  Â  Â  Â  kubectl get node {{ gpu_node_hostname }} --show-labels | tr "," "\n" | egrep -n "kubernetes.io/hostname|hostname" || true
Â  Â  Â  Â  Â  echo
Â  Â  Â  Â  Â  echo "== gpu node taints =="
Â  Â  Â  Â  Â  kubectl describe node {{ gpu_node_hostname }} | egrep -n "Taints:" -A2 || true
Â  Â  Â  Â  '
Â  Â  Â  changed_when: false

Â  Â  - name: 5.1 Create namespace for NVIDIA device plugin
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  kubectl create ns {{ ns_nvidia }} --dry-run=client -o yaml | kubectl apply -f -
Â  Â  Â  Â  '
Â  Â  Â  changed_when: false

Â  Â  - name: "5.2 Install/upgrade NVIDIA device plugin (hostname pin + override default affinity)"
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  set -euo pipefail
Â  Â Â 
Â  Â  Â  Â  Â  helm repo add nvidia https://nvidia.github.io/k8s-device-plugin >/dev/null 2>&1 || true
Â  Â  Â  Â  Â  helm repo update >/dev/null 2>&1
Â  Â Â 
Â  Â  Â  Â  Â  f=/tmp/nvidia-values.yaml
Â  Â  Â  Â  Â  : > "$f"
Â  Â  Â  Â  Â  w(){ printf "%s\n" "$1" >> "$f"; }
Â  Â Â 
Â  Â  Â  Â  Â  # ç›®çš„ï¼š
Â  Â  Â  Â  Â  # 1) ç”¨ hostname nodeAffinity è¦†è“‹ chart é è¨­çš„ feature.node.kubernetes.io/* è¦å‰‡
Â  Â  Â  Â  Â  # 2) å†ç”¨ nodeSelector ç¶æ­» gpu-node01
Â  Â  Â  Â  Â  # 3) tolerations å¯ç•™ï¼ˆå³ä½¿ node æ²’ taint ä¹Ÿä¸å½±éŸ¿ï¼‰
Â  Â  Â  Â  Â  w "affinity:"
Â  Â  Â  Â  Â  w "Â  nodeAffinity:"
Â  Â  Â  Â  Â  w "Â  Â  requiredDuringSchedulingIgnoredDuringExecution:"
Â  Â  Â  Â  Â  w "Â  Â  Â  nodeSelectorTerms:"
Â  Â  Â  Â  Â  w "Â  Â  Â  - matchExpressions:"
Â  Â  Â  Â  Â  w "Â  Â  Â  Â  - key: kubernetes.io/hostname"
Â  Â  Â  Â  Â  w "Â  Â  Â  Â  Â  operator: In"
Â  Â  Â  Â  Â  w "Â  Â  Â  Â  Â  values:"
Â  Â  Â  Â  Â  w "Â  Â  Â  Â  Â  - {{ gpu_node_hostname }}"
Â  Â  Â  Â  Â  w "nodeSelector:"
Â  Â  Â  Â  Â  w "Â  kubernetes.io/hostname: {{ gpu_node_hostname }}"
Â  Â  Â  Â  Â  w "Â  kubernetes.io/os: linux"
Â  Â  Â  Â  Â  w "tolerations:"
Â  Â  Â  Â  Â  w "- key: {{ gpu_taint_key }}"
Â  Â  Â  Â  Â  w "Â  operator: Equal"
Â  Â  Â  Â  Â  w "Â  value: \"{{ gpu_taint_value }}\""
Â  Â  Â  Â  Â  w "Â  effect: NoSchedule"
Â  Â Â 
Â  Â  Â  Â  Â  echo "== values.yaml (show with line numbers) =="
Â  Â  Â  Â  Â  nl -ba "$f" | sed -n "1,120p"
Â  Â Â 
Â  Â  Â  Â  Â  echo "== helm upgrade/install =="
Â  Â  Â  Â  Â  helm upgrade --install nvidia-device-plugin nvidia/nvidia-device-plugin \
Â  Â  Â  Â  Â  Â  -n {{ ns_nvidia }} --create-namespace \
Â  Â  Â  Â  Â  Â  --reset-values \
Â  Â  Â  Â  Â  Â  -f "$f"
Â  Â Â 
Â  Â  Â  Â  Â  echo "== helm status/list =="
Â  Â  Â  Â  Â  helm -n {{ ns_nvidia }} status nvidia-device-plugin || true
Â  Â  Â  Â  Â  helm list -n {{ ns_nvidia }} || true
Â  Â Â 
Â  Â  Â  Â  Â  echo "== rollout + resources =="
Â  Â  Â  Â  Â  kubectl -n {{ ns_nvidia }} rollout status ds/nvidia-device-plugin --timeout=240s
Â  Â  Â  Â  Â  kubectl -n {{ ns_nvidia }} get ds,pod -o wide
Â  Â Â 
Â  Â  Â  Â  Â  echo "== node gpu capacity/allocatable =="
Â  Â  Â  Â  Â  kubectl describe node {{ gpu_node_hostname }} | egrep -n "Capacity:|Allocatable:|nvidia.com/gpu" -A6 || true
Â  Â  Â  Â  '
Â  Â  Â  changed_when: true

Â  Â  - name: 5.3 Verify nvidia.com/gpu on gpu node
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  set -e
Â  Â  Â  Â  Â  kubectl describe node {{ gpu_node_hostname }} | egrep -n "Taints:|Capacity:|Allocatable:|nvidia.com/gpu" -n
Â  Â  Â  Â  '
Â  Â  Â  changed_when: false

Â  Â  # -----------------------------------------------------------
Â  Â  # 6) cert-manager
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 6.1 Create namespace cert-manager
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  kubectl create ns {{ ns_certmgr }} --dry-run=client -o yaml | kubectl apply -f -
Â  Â  Â  Â  '
Â  Â  Â  changed_when: false

Â  Â  - name: 6.2 Install/upgrade cert-manager via Helm
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  set -euo pipefail
Â  Â  Â  Â  Â  helm repo add jetstack https://charts.jetstack.io >/dev/null 2>&1 || true
Â  Â  Â  Â  Â  helm repo update >/dev/null 2>&1

Â  Â  Â  Â  Â  helm upgrade --install cert-manager jetstack/cert-manager \
Â  Â  Â  Â  Â  Â  -n {{ ns_certmgr }} --create-namespace \
Â  Â  Â  Â  Â  Â  --version {{ cert_manager_chart_version }} \
Â  Â  Â  Â  Â  Â  --set crds.enabled=true

Â  Â  Â  Â  Â  kubectl -n {{ ns_certmgr }} rollout status deploy/cert-manager --timeout=240s
Â  Â  Â  Â  Â  kubectl -n {{ ns_certmgr }} rollout status deploy/cert-manager-webhook --timeout=240s
Â  Â  Â  Â  Â  kubectl -n {{ ns_certmgr }} rollout status deploy/cert-manager-cainjector --timeout=240s
Â  Â  Â  Â  '
Â  Â  Â  changed_when: true

Â  Â  # -----------------------------------------------------------
Â  Â  # 7) slurm-operator-crds + slurm-operator (OCI charts)
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 7.1 Create namespace for slurm operator
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  kubectl create ns {{ ns_slurm_operator }} --dry-run=client -o yaml | kubectl apply -f -
Â  Â  Â  Â  '
Â  Â  Â  changed_when: false

Â  Â  - name: 7.2 Install/upgrade slurm-operator-crds (OCI)
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  set -euo pipefail
Â  Â  Â  Â  Â  helm upgrade --install slurm-operator-crds oci://ghcr.io/slinkyproject/charts/slurm-operator-crds \
Â  Â  Â  Â  Â  Â  -n default --create-namespace \
Â  Â  Â  Â  Â  Â  --version {{ slurm_operator_chart_ver }}
Â  Â  Â  Â  '
Â  Â  Â  changed_when: true

Â  Â  - name: 7.3 Install/upgrade slurm-operator (OCI)
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  set -euo pipefail
Â  Â  Â  Â  Â  helm upgrade --install slurm-operator oci://ghcr.io/slinkyproject/charts/slurm-operator \
Â  Â  Â  Â  Â  Â  -n {{ ns_slurm_operator }} --create-namespace \
Â  Â  Â  Â  Â  Â  --version {{ slurm_operator_chart_ver }}

Â  Â  Â  Â  Â  kubectl -n {{ ns_slurm_operator }} rollout status deploy/slurm-operator --timeout=240s
Â  Â  Â  Â  '
Â  Â  Â  changed_when: true

Â  Â  - name: 7.4 Wait for Slurm Operator Webhook endpoints (robust)
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
Â  Â  Â  Â  set -euo pipefail
Â  Â  Â  Â  NS="{{ ns_slurm_operator }}"
Â  Â Â 
Â  Â  Â  Â  echo "[INFO] wait webhook deployment ready..."
Â  Â  Â  Â  kubectl -n "$NS" rollout status deploy/slurm-operator-webhook --timeout=300s || true
Â  Â Â 
Â  Â  Â  Â  echo "[INFO] discover webhook service..."
Â  Â  Â  Â  SVC=$(kubectl -n "$NS" get svc -o name | grep -i webhook | head -n1 | cut -d/ -f2 || true)
Â  Â  Â  Â  if [ -z "$SVC" ]; then
Â  Â  Â  Â  Â  echo "[FAIL] no webhook service found"
Â  Â  Â  Â  Â  kubectl -n "$NS" get svc -o wide || true
Â  Â  Â  Â  Â  exit 1
Â  Â  Â  Â  fi
Â  Â  Â  Â  echo "[INFO] webhook svc=$SVC"
Â  Â Â 
Â  Â  Â  Â  echo "[INFO] wait endpoints..."
Â  Â  Â  Â  for i in {1..120}; do
Â  Â  Â  Â  Â  EP=$(kubectl -n "$NS" get ep "$SVC" -o jsonpath="{.subsets[*].addresses[*].ip}" 2>/dev/null || true)
Â  Â  Â  Â  Â  if [ -n "$EP" ]; then
Â  Â  Â  Â  Â  Â  echo "âœ… Webhook endpoints ready: $EP"
Â  Â  Â  Â  Â  Â  exit 0
Â  Â  Â  Â  Â  fi
Â  Â  Â  Â  Â  echo "â³ waiting endpoints... ($i/120)"
Â  Â  Â  Â  Â  sleep 5
Â  Â  Â  Â  done
Â  Â Â 
Â  Â  Â  Â  echo "âŒ timeout"
Â  Â  Â  Â  kubectl -n "$NS" get pods,svc,ep -o wide || true
Â  Â  Â  Â  kubectl -n "$NS" get events --sort-by=.lastTimestamp | tail -n 60 || true
Â  Â  Â  Â  exit 1
Â  Â  Â  Â  EOS
Â  Â  Â  changed_when: false

Â  Â  # -----------------------------------------------------------
Â  Â  # 8) slurm chart (OCI)
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 8.1 Create namespace slurm
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  kubectl create ns {{ ns_slurm }} --dry-run=client -o yaml | kubectl apply -f -
Â  Â  Â  Â  '
Â  Â  Â  changed_when: false

Â  Â  - name: 8.2 Install/upgrade slurm chart (OCI) - Pin controller/restapi to slurmhn, worker to gpu-node01 (no patch; fix dup partition; force tcpSocket probes; wait webhook)
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
Â  Â  Â  Â  set -euo pipefail
Â  Â Â 
Â  Â  Â  Â  NS="{{ ns_slurm }}"
Â  Â  Â  Â  CHART_VER="{{ slurm_chart_ver }}"
Â  Â Â 
Â  Â  Â  Â  echo "[INFO] Write values.yaml ..."
Â  Â  Â  Â  cat > /tmp/slurm-values.yaml <<EOF
Â  Â  Â  Â  controller:
Â  Â  Â  Â  Â  persistence:
Â  Â  Â  Â  Â  Â  enabled: true
Â  Â  Â  Â  Â  Â  storageClassName: "{{ nfs_storageclass }}"
Â  Â  Â  Â  Â  Â  accessModes:
Â  Â  Â  Â  Â  Â  Â  - ReadWriteOnce
Â  Â  Â  Â  Â  Â  resources:
Â  Â  Â  Â  Â  Â  Â  requests:
Â  Â  Â  Â  Â  Â  Â  Â  storage: 10Gi
Â  Â Â 
Â  Â  Â  Â  Â  # é€™è¡Œæœƒåœ¨ log å‡ºç¾ã€ŒGresTypes é‡è¤‡ã€(éè‡´å‘½)ï¼›è‹¥ä½ æƒ³æ¶ˆæ‰ï¼Œå°±æŠŠé€™æ®µæ•´æ®µæ‹¿æ‰
Â  Â  Â  Â  Â  extraConf: |
Â  Â  Â  Â  Â  Â  GresTypes=gpu
Â  Â Â 
Â  Â  Â  Â  Â  podSpec:
Â  Â  Â  Â  Â  Â  nodeSelector:
Â  Â  Â  Â  Â  Â  Â  kubernetes.io/hostname: {{ controlplane_hostname }}
Â  Â  Â  Â  Â  Â  Â  kubernetes.io/os: linux
Â  Â  Â  Â  Â  Â  tolerations:
Â  Â  Â  Â  Â  Â  Â  - key: node-role.kubernetes.io/control-plane
Â  Â  Â  Â  Â  Â  Â  Â  operator: Exists
Â  Â  Â  Â  Â  Â  Â  Â  effect: NoSchedule
Â  Â  Â  Â  Â  Â  Â  - key: node-role.kubernetes.io/master
Â  Â  Â  Â  Â  Â  Â  Â  operator: Exists
Â  Â  Â  Â  Â  Â  Â  Â  effect: NoSchedule
Â  Â Â 
Â  Â  Â  Â  restapi:
Â  Â  Â  Â  Â  replicas: 1
Â  Â  Â  Â  Â  podSpec:
Â  Â  Â  Â  Â  Â  nodeSelector:
Â  Â  Â  Â  Â  Â  Â  kubernetes.io/hostname: {{ controlplane_hostname }}
Â  Â  Â  Â  Â  Â  Â  kubernetes.io/os: linux
Â  Â  Â  Â  Â  Â  tolerations:
Â  Â  Â  Â  Â  Â  Â  - key: node-role.kubernetes.io/control-plane
Â  Â  Â  Â  Â  Â  Â  Â  operator: Exists
Â  Â  Â  Â  Â  Â  Â  Â  effect: NoSchedule
Â  Â Â 
Â  Â  Â  Â  nodesets:
Â  Â  Â  Â  Â  slinky:
Â  Â  Â  Â  Â  Â  enabled: true
Â  Â Â 
Â  Â  Â  Â  Â  Â  # âœ… é—œéµï¼šä½ å·²ç¶“åœ¨ partitions: æ‰‹å‹•å®£å‘Š slinkyï¼Œæ‰€ä»¥è¦é—œæ‰ nodeset çš„è‡ªå‹•åˆ†å‰²ï¼Œé¿å… PartitionName=slinky é‡è¤‡
Â  Â  Â  Â  Â  Â  partition:
Â  Â  Â  Â  Â  Â  Â  enabled: false
Â  Â Â 
Â  Â  Â  Â  Â  Â  useResourceLimits: true
Â  Â  Â  Â  Â  Â  podSpec:
Â  Â  Â  Â  Â  Â  Â  nodeSelector:
Â  Â  Â  Â  Â  Â  Â  Â  kubernetes.io/hostname: {{ gpu_node_hostname }}
Â  Â  Â  Â  Â  Â  Â  Â  kubernetes.io/os: linux
Â  Â  Â  Â  Â  Â  Â  tolerations:
Â  Â  Â  Â  Â  Â  Â  Â  - key: {{ gpu_taint_key }}
Â  Â  Â  Â  Â  Â  Â  Â  Â  operator: Equal
Â  Â  Â  Â  Â  Â  Â  Â  Â  value: "{{ gpu_taint_value }}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  effect: NoSchedule
Â  Â Â 
Â  Â  Â  Â  Â  Â  slurmd:
Â  Â  Â  Â  Â  Â  Â  resources:
Â  Â  Â  Â  Â  Â  Â  Â  limits:
Â  Â  Â  Â  Â  Â  Â  Â  Â  nvidia.com/gpu: {{ slurm_gpu_count }}
Â  Â  Â  Â  Â  Â  Â  args:
Â  Â  Â  Â  Â  Â  Â  Â  - --conf
Â  Â  Â  Â  Â  Â  Â  Â  - Gres=gpu:{{ slurm_gpu_count }}
Â  Â Â 
Â  Â  Â  Â  partitions:
Â  Â  Â  Â  Â  all:
Â  Â  Â  Â  Â  Â  enabled: true
Â  Â  Â  Â  Â  Â  nodesets: [ALL]
Â  Â  Â  Â  Â  Â  configMap:
Â  Â  Â  Â  Â  Â  Â  Default: "YES"
Â  Â  Â  Â  Â  Â  Â  MaxTime: UNLIMITED
Â  Â  Â  Â  Â  Â  Â  State: UP
Â  Â  Â  Â  Â  slinky:
Â  Â  Â  Â  Â  Â  enabled: true
Â  Â  Â  Â  Â  Â  nodesets: [ALL]
Â  Â  Â  Â  Â  Â  configMap:
Â  Â  Â  Â  Â  Â  Â  Default: "NO"
Â  Â  Â  Â  Â  Â  Â  MaxTime: UNLIMITED
Â  Â  Â  Â  Â  Â  Â  State: UP
Â  Â Â 
Â  Â  Â  Â  configFiles:
Â  Â  Â  Â  Â  gres.conf: |
Â  Â  Â  Â  Â  Â  AutoDetect=nvidia
Â  Â  Â  Â  EOF
Â  Â Â 
Â  Â  Â  Â  echo "[INFO] values head:"
Â  Â  Â  Â  head -n 220 /tmp/slurm-values.yaml
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "[INFO] Ensure yq in /tmp (no root needed)..."
Â  Â  Â  Â  if ! [ -x /tmp/yq ]; then
Â  Â  Â  Â  Â  curl -fsSL -o /tmp/yq https://github.com/mikefarah/yq/releases/download/v4.44.3/yq_linux_amd64
Â  Â  Â  Â  Â  chmod +x /tmp/yq
Â  Â  Â  Â  fi
Â  Â  Â  Â  /tmp/yq --version
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "[INFO] Write helm post-renderer (move initContainers->containers + force probes tcpSocket)..."
Â  Â  Â  Â  cat > /tmp/slurm-post-renderer.sh <<'SH'
Â  Â  Â  Â  #!/usr/bin/env bash
Â  Â  Â  Â  set -euo pipefail
Â  Â Â 
Â  Â  Â  Â  YQ="/tmp/yq"
Â  Â  Â  Â  tmpdir="$(mktemp -d)"
Â  Â  Â  Â  trap 'rm -rf "$tmpdir"' EXIT
Â  Â  Â  Â  in="$tmpdir/in.yaml"
Â  Â Â 
Â  Â  Â  Â  cat > "$in"
Â  Â Â 
Â  Â  Â  Â  # -----------------------------
Â  Â  Â  Â  # FIX #1: slurm-controller initContainers æ°¸é è·‘ä¸å®Œ
Â  Â  Â  Â  # => å¿…é ˆæ¬åˆ° containers (sidecar) æ‰èƒ½è®“ slurmctld å•Ÿå‹•
Â  Â  Â  Â  # -----------------------------
Â  Â  Â  Â  "$YQ" eval -i '
Â  Â  Â  Â  Â  (select(.kind=="StatefulSet" and .metadata.name=="slurm-controller")
Â  Â  Â  Â  Â  Â  .spec.template.spec.containers
Â  Â  Â  Â  Â  ) += (select(.kind=="StatefulSet" and .metadata.name=="slurm-controller")
Â  Â  Â  Â  Â  Â  .spec.template.spec.initContainers
Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  |
Â  Â  Â  Â  Â  (select(.kind=="StatefulSet" and .metadata.name=="slurm-controller")
Â  Â  Â  Â  Â  Â  .spec.template.spec.initContainers
Â  Â  Â  Â  Â  ) = []
Â  Â  Â  Â  ' "$in"
Â  Â Â 
Â  Â  Â  Â  # -----------------------------
Â  Â  Â  Â  # FIX #2: probes å¼·åˆ¶æ”¹ tcpSocketï¼Œé¿å… httpGet å¡ä½
Â  Â  Â  Â  # -----------------------------
Â  Â  Â  Â  "$YQ" eval -i '
Â  Â  Â  Â  Â  (select(.kind=="StatefulSet" and .metadata.name=="slurm-controller")
Â  Â  Â  Â  Â  Â  .spec.template.spec.containers[] | select(.name=="slurmctld")
Â  Â  Â  Â  Â  ).startupProbe = {"tcpSocket":{"port":6817},"failureThreshold":240,"periodSeconds":5,"timeoutSeconds":1}
Â  Â  Â  Â  Â  |
Â  Â  Â  Â  Â  (select(.kind=="StatefulSet" and .metadata.name=="slurm-controller")
Â  Â  Â  Â  Â  Â  .spec.template.spec.containers[] | select(.name=="slurmctld")
Â  Â  Â  Â  Â  ).readinessProbe = {"tcpSocket":{"port":6817},"failureThreshold":24,"periodSeconds":5,"timeoutSeconds":1}
Â  Â  Â  Â  Â  |
Â  Â  Â  Â  Â  (select(.kind=="StatefulSet" and .metadata.name=="slurm-controller")
Â  Â  Â  Â  Â  Â  .spec.template.spec.containers[] | select(.name=="slurmctld")
Â  Â  Â  Â  Â  ).livenessProbe = {"tcpSocket":{"port":6817},"failureThreshold":12,"periodSeconds":10,"timeoutSeconds":1}
Â  Â  Â  Â  Â  |
Â  Â  Â  Â  Â  (select(.kind=="NodeSet" and .metadata.name=="slurm-worker-slinky").spec.slurmd).startupProbe =
Â  Â  Â  Â  Â  Â  {"tcpSocket":{"port":6818},"failureThreshold":240,"periodSeconds":5,"timeoutSeconds":1}
Â  Â  Â  Â  Â  |
Â  Â  Â  Â  Â  (select(.kind=="NodeSet" and .metadata.name=="slurm-worker-slinky").spec.slurmd).readinessProbe =
Â  Â  Â  Â  Â  Â  {"tcpSocket":{"port":6818},"failureThreshold":24,"periodSeconds":5,"timeoutSeconds":1}
Â  Â  Â  Â  Â  |
Â  Â  Â  Â  Â  (select(.kind=="NodeSet" and .metadata.name=="slurm-worker-slinky").spec.slurmd).livenessProbe =
Â  Â  Â  Â  Â  Â  {"tcpSocket":{"port":6818},"failureThreshold":12,"periodSeconds":10,"timeoutSeconds":1}
Â  Â  Â  Â  ' "$in"
Â  Â Â 
Â  Â  Â  Â  cat "$in"
Â  Â  Â  Â  SH
Â  Â  Â  Â  chmod +x /tmp/slurm-post-renderer.sh
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "[INFO] Wait slurm-operator webhook ready (avoid TLS not yet valid)..."
Â  Â  Â  Â  for i in 1 2 3 4 5 6; do
Â  Â  Â  Â  Â  if kubectl -n slinky get deploy slurm-operator-webhook >/dev/null 2>&1; then
Â  Â  Â  Â  Â  Â  kubectl -n slinky rollout status deploy/slurm-operator-webhook --timeout=60s && break || true
Â  Â  Â  Â  Â  fi
Â  Â  Â  Â  Â  sleep 5
Â  Â  Â  Â  done
Â  Â  Â  Â  sleep 5
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "[INFO] Helm upgrade/install (with post-renderer)..."
Â  Â  Â  Â  for try in 1 2 3 4 5; do
Â  Â  Â  Â  Â  set +e
Â  Â  Â  Â  Â  helm upgrade --install slurm oci://ghcr.io/slinkyproject/charts/slurm \
Â  Â  Â  Â  Â  Â  -n "$NS" --create-namespace \
Â  Â  Â  Â  Â  Â  --version "$CHART_VER" \
Â  Â  Â  Â  Â  Â  -f /tmp/slurm-values.yaml \
Â  Â  Â  Â  Â  Â  --post-renderer /tmp/slurm-post-renderer.sh \
Â  Â  Â  Â  Â  Â  --wait --timeout=600s
Â  Â  Â  Â  Â  rc=$?
Â  Â  Â  Â  Â  set -e
Â  Â  Â  Â  Â  if [ "$rc" -eq 0 ]; then
Â  Â  Â  Â  Â  Â  echo "[INFO] helm success"
Â  Â  Â  Â  Â  Â  break
Â  Â  Â  Â  Â  fi
Â  Â  Â  Â  Â  echo "[WARN] helm failed (try=$try rc=$rc), sleep 5s then retry..."
Â  Â  Â  Â  Â  sleep 5
Â  Â  Â  Â  done
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "[INFO] Verify probes rendered in manifest:"
Â  Â  Â  Â  helm -n "$NS" get manifest slurm | egrep -n "kind: StatefulSet|name: slurm-controller|startupProbe:|readinessProbe:|livenessProbe:|httpGet:|tcpSocket:" | head -n 260
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "[INFO] Verify slurm-controller has NO initContainers (must be empty):"
Â  Â  Â  Â  kubectl -n "$NS" get sts slurm-controller -o jsonpath='init={.spec.template.spec.initContainers[*].name}{"\n"}containers={.spec.template.spec.containers[*].name}{"\n"}'
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "[INFO] Pods:"
Â  Â  Â  Â  kubectl -n "$NS" get pods -o wide
Â  Â  Â  Â  EOS
Â  Â  Â  changed_when: true

Â  Â  # -----------------------------------------------------------
Â  Â  # 8.25 Verify worker got correct gres.conf and GPU device (K8s layer only)
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 8.25 Verify worker Ready + gres.conf + /dev/nvidia0 (no srun here)
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
Â  Â  Â  Â  set -euo pipefail
Â  Â Â 
Â  Â  Â  Â  NS="{{ ns_slurm }}"
Â  Â  Â  Â  WRK="slurm-worker-slinky-0"
Â  Â Â 
Â  Â  Â  Â  echo "[INFO] wait worker Ready..."
Â  Â  Â  Â  kubectl -n "$NS" wait --for=condition=Ready pod/"$WRK" --timeout=300s
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "[CHECK] worker gres.conf:"
Â  Â  Â  Â  kubectl -n "$NS" exec "$WRK" -c slurmd -- cat /run/slurm/conf/gres.conf
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "[CHECK] worker /dev/nvidia0:"
Â  Â  Â  Â  kubectl -n "$NS" exec "$WRK" -c slurmd -- ls -l /dev/nvidia0
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "[CHECK] node GPU capacity (k8s):"
Â  Â  Â  Â  kubectl describe node {{ gpu_node_hostname }} | egrep -n "Capacity:|Allocatable:|nvidia.com/gpu" -A6 || true
Â  Â  Â  Â  EOS
Â  Â  Â  changed_when: false

Â  Â  # -----------------------------------------------------------
Â  Â  # 9) Restart controller + worker (Robust check)
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 9.1 Restart slurm pods and Wait for Ready
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
Â  Â  Â  Â  Â  set -e
Â  Â  Â  Â  Â  echo "[INFO] 1. Deleting old pods..."
Â  Â  Â  Â  Â  kubectl -n {{ ns_slurm }} delete pod slurm-controller-0 --ignore-not-found=true --wait=true
Â  Â  Â  Â  Â  kubectl -n {{ ns_slurm }} delete pod slurm-worker-slinky-0 --ignore-not-found=true --wait=true

Â  Â  Â  Â  Â  echo "[INFO] 2. Waiting for StatefulSet to recreate pods..."
Â  Â  Â  Â  Â  sleep 10

Â  Â  Â  Â  Â  echo "[INFO] 3. Waiting for pods to become Ready..."
Â  Â  Â  Â  Â  # å¦‚æœé€™è£¡é‚„å¤±æ•—ï¼Œæœƒè‡ªå‹•å°å‡ºç‹€æ…‹
Â  Â  Â  Â  Â  if ! kubectl -n {{ ns_slurm }} wait --for=condition=Ready pod/slurm-controller-0 --timeout=300s; then
Â  Â  Â  Â  Â  Â  Â echo "DEBUG: Controller Failed. PVC Status:"
Â  Â  Â  Â  Â  Â  Â kubectl -n {{ ns_slurm }} get pvc
Â  Â  Â  Â  Â  Â  Â exit 1
Â  Â  Â  Â  Â  fi

Â  Â  Â  Â  Â  if ! kubectl -n {{ ns_slurm }} wait --for=condition=Ready pod/slurm-worker-slinky-0 --timeout=300s; then
Â  Â  Â  Â  Â  Â  Â echo "DEBUG: Worker Failed. Describe:"
Â  Â  Â  Â  Â  Â  Â kubectl -n {{ ns_slurm }} describe pod slurm-worker-slinky-0
Â  Â  Â  Â  Â  Â  Â exit 1
Â  Â  Â  Â  Â  fi

Â  Â  Â  Â  Â  echo "ğŸ‰ All Pods Ready!"
Â  Â  Â  Â  Â  kubectl -n {{ ns_slurm }} get pods -o wide
Â  Â  Â  Â  '
Â  Â  Â  changed_when: true

Â  Â  # -----------------------------------------------------------
Â  Â  # 10.1 Verify partitions/nodes/GRES and run GPU job (Slurm layer)
Â  Â  # - robust: use srun --wrap (avoid nested bash -lc quoting issues)
Â  Â  # - bounded: --time + --immediate
Â  Â  # - cleanup: scancel old gpu-smoke-* jobs
Â  Â  # -----------------------------------------------------------
Â  Â  - name: 10.1 Verify partitions/nodes/GRES and run GPU job (inside slurmctld) - robust (no --wrap) + cleanup
Â  Â  Â  shell: |
Â  Â  Â  Â  juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
Â  Â  Â  Â  set -euo pipefail
Â  Â Â 
Â  Â  Â  Â  NS="{{ ns_slurm }}"
Â  Â  Â  Â  CTL="slurm-controller-0"
Â  Â  Â  Â  GPU_CNT="{{ slurm_gpu_count | default(1) }}"
Â  Â Â 
Â  Â  Â  Â  echo "== sinfo (brief) =="
Â  Â  Â  Â  kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc 'sinfo -o "%P %a %l %D %t %N"'
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "== slurm.conf partitions =="
Â  Â  Â  Â  kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc 'grep -n "^PartitionName=" /etc/slurm/slurm.conf 2>/dev/null || true'
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "== node GRES / TRES (from slurmctld) =="
Â  Â  Â  Â  kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc 'scontrol show node slinky-0 | egrep -i "NodeName=|State=|Reason=|Gres=|CfgTRES=|AllocTRES="'
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "== cleanup old test jobs (by name gpu-smoke-*) =="
Â  Â  Â  Â  kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc '
Â  Â  Â  Â  Â  squeue -u slurm -o "%.18i %.9P %.16j %.8u %.2t %.10M %.6D %R" || true
Â  Â  Â  Â  Â  scancel -u slurm -n gpu-smoke-allÂ  Â  Â >/dev/null 2>&1 || true
Â  Â  Â  Â  Â  scancel -u slurm -n gpu-smoke-slinkyÂ  >/dev/null 2>&1 || true
Â  Â  Â  Â  Â  squeue -u slurm -o "%.18i %.9P %.16j %.8u %.2t %.10M %.6D %R" || true
Â  Â  Â  Â  '
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "== srun GPU test (default partition=all) [bounded] =="
Â  Â  Â  Â  kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc "
Â  Â  Â  Â  Â  timeout 90s srun -N1 -n1 --job-name=gpu-smoke-all \
Â  Â  Â  Â  Â  Â  --mpi=none \
Â  Â  Â  Â  Â  Â  --gres=gpu:${GPU_CNT} --time=00:01:00 --immediate=30 \
Â  Â  Â  Â  Â  Â  bash -lc 'hostname; ls -l /dev/nvidia0 || true; echo GPU_OK_all'
Â  Â  Â  Â  "
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "== srun GPU test (partition=slinky) [bounded] =="
Â  Â  Â  Â  kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc "
Â  Â  Â  Â  Â  timeout 90s srun -p slinky -N1 -n1 --job-name=gpu-smoke-slinky \
Â  Â  Â  Â  Â  Â  --mpi=none \
Â  Â  Â  Â  Â  Â  --gres=gpu:${GPU_CNT} --time=00:01:00 --immediate=30 \
Â  Â  Â  Â  Â  Â  bash -lc 'hostname; ls -l /dev/nvidia0 || true; echo GPU_OK_slinky'
Â  Â  Â  Â  "
Â  Â Â 
Â  Â  Â  Â  echo
Â  Â  Â  Â  echo "== final squeue =="
Â  Â  Â  Â  kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc 'squeue -u slurm -o "%.18i %.9P %.16j %.8u %.2t %.10M %.6D %R" || true'
Â  Â  Â  Â  EOS
Â  Â  Â  changed_when: false

Â  Â  - name: Done
Â  Â  Â  debug:
Â  Â  Â  Â  msg:
Â  Â  Â  Â  Â  - "ğŸ‰ Standardized Slinky Slurm on K8s deployed"
Â  Â  Â  Â  Â  - "Mode reset_before_install={{ reset_before_install }}"
Â  Â  Â  Â  Â  - "NFS SC={{ nfs_storageclass }} (default={{ nfs_make_default_sc }})"
Â  Â  Â  Â  Â  - "NVIDIA device-plugin ns={{ ns_nvidia }} (nodeSelector={{ gpu_node_hostname }}, toleration {{ gpu_taint_key }}={{ gpu_taint_value }}, affinity cleared)"
Â  Â  Â  Â  Â  - "Slurm ns={{ ns_slurm }} partitions=all(default)+slinky, GRES autodetect nvidia"
