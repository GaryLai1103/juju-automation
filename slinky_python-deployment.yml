---
# ========================================================
# Scenario: Slinky Offline AI Environment - Deployment Only
# Goal: Upload files & Prep Env, BUT DO NOT RUN JOBS.
# ========================================================
- name: ä½ˆç½² Slinky PyTorch æ¸¬è©¦æª”æ¡ˆ (ä¸è‡ªå‹•åŸ·è¡Œ)
  hosts: maasjuju
  gather_facts: no
  vars:
    # ---- æœ¬åœ°æª”æ¡ˆä½ç½® (Jumpbox) ----
    local_wheel_path: "/home/gary/torch.whl"
    
    # ---- Slinky è¨­å®š ----
    test_model: "slinky-cluster"
    k8s_machine: "0"
    slurm_ns: "slurm"
    controller_pod: "slurm-controller-0"
    shared_dir: "/home/slurm"

  tasks:
    # ----------------------------------------------------
    # 1. æª¢æŸ¥èˆ‡ç¢ºèª
    # ----------------------------------------------------
    - name: 1.1 æª¢æŸ¥ Jumpbox ä¸Šæ˜¯å¦æœ‰ torch.whl
      stat:
        path: "{{ local_wheel_path }}"
      register: wheel_stat
      failed_when: not wheel_stat.stat.exists

    - name: 1.2 ç¢ºèª Slurm Controller æ´»è‘—
      shell: |
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- \
          "kubectl get pod -n {{ slurm_ns }} {{ controller_pod }} -o jsonpath='{.status.phase}'"
      register: pod_status
      failed_when: "'Running' not in pod_status.stdout"

    # ----------------------------------------------------
    # 2. æ¬é‹å¤§æª”æ¡ˆ (Wheel)
    # ----------------------------------------------------
    - name: 2.1 ä¸Šå‚³ torch.whl åˆ° Controller å…±äº«ç›®éŒ„
      shell: |
        # 1. Jumpbox -> Machine 0
        juju scp {{ local_wheel_path }} {{ test_model }}/{{ k8s_machine }}:/tmp/torch.whl
        
        # 2. Machine 0 -> Pod (NFS Shared Dir)
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- \
          "kubectl cp /tmp/torch.whl {{ slurm_ns }}/{{ controller_pod }}:{{ shared_dir }}/torch.whl"
        
        # 3. æ¸…é™¤æš«å­˜
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- "rm -f /tmp/torch.whl"
      async: 1200
      poll: 10

    # ----------------------------------------------------
    # 3. é å…ˆå®‰è£ç’°å¢ƒ (å¹«ä½ çœå»æ‰“è¤‡é›œæŒ‡ä»¤çš„æ™‚é–“)
    # ----------------------------------------------------
    - name: 3.1 å»ºç«‹ venv ä¸¦é›¢ç·šå®‰è£ PyTorch
      shell: |
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- bash -s <<'EOS'
          cat << 'SCRIPT' > /tmp/install_env.sh
          #!/bin/bash
          cd {{ shared_dir }}
          
          # 1. å»ºç«‹ venv (å¦‚æœæ²’æœ‰çš„è©±)
          if [ ! -d "ai-env" ]; then
             echo "ğŸ“‚ Creating Virtual Environment (ai-env)..."
             python3 -m venv ai-env
          fi

          # 2. å•Ÿå‹•ä¸¦å®‰è£
          source ai-env/bin/activate
          
          # æª¢æŸ¥æ˜¯å¦å·²å®‰è£ï¼Œé¿å…é‡è¤‡è·‘
          if python3 -c "import torch" >/dev/null 2>&1; then
             echo "âœ… PyTorch already installed, skipping."
          else
             echo "ğŸ“¦ Installing PyTorch from Offline Wheel (this takes time)..."
             pip install {{ shared_dir }}/torch.whl --no-index --find-links {{ shared_dir }}
          fi
          SCRIPT
          
          chmod +x /tmp/install_env.sh
          kubectl cp /tmp/install_env.sh {{ slurm_ns }}/{{ controller_pod }}:/tmp/install_env.sh
          
          # åŸ·è¡Œå®‰è£
          kubectl exec -n {{ slurm_ns }} {{ controller_pod }} -- /tmp/install_env.sh
        EOS
      async: 600
      poll: 10

    # ----------------------------------------------------
    # 4. ä½ˆç½²æ¸¬è©¦è…³æœ¬ (Python & Sbatch)
    # ----------------------------------------------------
    - name: 4.1 æ³¨å…¥ train.py (çŸ©é™£é‹ç®—ç¨‹å¼)
      shell: |
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- bash -s <<'EOS'
          cat << 'PY' > /tmp/train.py
        import torch
        import time
        import os
        import socket

        node_name = socket.gethostname()
        job_id = os.environ.get('SLURM_JOB_ID', 'Interactive')
        
        print(f"\nğŸš€ [Job {job_id}] Running on Node: {node_name}")
        
        if torch.cuda.is_available():
            print(f"âœ… GPU Detected: {torch.cuda.get_device_name(0)}")
            dev = torch.device("cuda")
        else:
            print("âŒ No GPU found! Check your configuration.")
            dev = torch.device("cpu")

        N = 8000
        print(f"ğŸ”¥ Allocating Tensors ({N}x{N})...")
        a = torch.randn(N, N, device=dev)
        b = torch.randn(N, N, device=dev)

        print("ğŸ”„ Starting Compute Loop (10 iterations)...")
        start = time.time()
        for i in range(10):
            c = torch.mm(a, b)
            torch.cuda.synchronize() # Wait for GPU
            print(f"   -> Batch {i+1} completed.")
            
        print(f"âœ… Finished in {time.time() - start:.2f} seconds.\n")
        PY
          
          kubectl cp /tmp/train.py {{ slurm_ns }}/{{ controller_pod }}:{{ shared_dir }}/train.py
        EOS

    - name: 4.2 æ³¨å…¥ run_job.sh (Slurm æ’ç¨‹è…³æœ¬)
      shell: |
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- bash -s <<'EOS'
          cat << 'SBATCH' > /tmp/run_job.sh
        #!/bin/bash
        #SBATCH --job-name=gpu-test
        #SBATCH --output=gpu-%j.out
        #SBATCH --ntasks=1
        #SBATCH --gres=gpu:1
        #SBATCH --time=00:05:00
        #SBATCH --partition=slinky

        echo "â¡ï¸ Loading AI Environment..."
        source {{ shared_dir }}/ai-env/bin/activate

        echo "â¡ï¸ Starting Training..."
        python {{ shared_dir }}/train.py
        SBATCH
        
          kubectl cp /tmp/run_job.sh {{ slurm_ns }}/{{ controller_pod }}:{{ shared_dir }}/run_job.sh
        EOS

    # ----------------------------------------------------
    # 5. æ‰‹å‹•æ“ä½œæŒ‡å¼•
    # ----------------------------------------------------
    - name: ğŸš€ ä½ˆç½²å®Œæˆï¼è«‹æ‰‹å‹•é–‹å§‹æ¸¬è©¦
      debug:
        msg: 
          - "========================================================"
          - "âœ… æª”æ¡ˆèˆ‡ç’°å¢ƒå·²å°±ç·’ï¼Œè«‹ä¾ç…§ä¸‹åˆ—æ­¥é©Ÿæ‰‹å‹•æ¸¬è©¦ï¼š"
          - "========================================================"
          - "1. [ç™»å…¥ Controller Pod]"
          - "   juju ssh -m {{ test_model }} 0 -- kubectl exec -it -n slurm slurm-controller-0 -- bash"
          - ""
          - "2. [é€²å…¥å…±äº«ç›®éŒ„]"
          - "   cd /home/slurm"
          - ""
          - "3. [æ–¹å¼ A: äº’å‹•å¼æ¸¬è©¦ (æ¨è–¦! å¯ä»¥ç›´æ¥çœ‹è¢å¹•è¼¸å‡º)]"
          - "   source ai-env/bin/activate"
          - "   srun --gres=gpu:1 --pty python train.py"
          - ""
          - "4. [æ–¹å¼ B: æ’ç¨‹æ¸¬è©¦ (æ¨™æº–åšæ³•)]"
          - "   sbatch run_job.sh"
          - "   squeue (æŸ¥çœ‹ç‹€æ…‹)"
          - "   cat gpu-*.out (æŸ¥çœ‹çµæœ)"
          - "========================================================"
