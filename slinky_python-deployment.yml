# ----------------------------------------------------
    # 4. ä½ˆç½²æ¸¬è©¦è…³æœ¬ (30ç§’å€’æ•¸ + å¯ä¸­æ–·)
    # ----------------------------------------------------
    - name: 4.1 æ³¨å…¥ train.py (30ç§’è‡ªå‹•å€’æ•¸ï¼Œå¯ Ctrl+C)
      shell: |
        juju ssh -m {{ test_model }} {{ k8s_machine }} -- bash -s <<'EOS'
          cat << 'PY' > /tmp/train.py
        import torch
        import time
        import os
        import socket
        import sys

        # 1. è¨­å®š
        TARGET_DURATION = 60  # è¨­å®šè·‘ 30 ç§’
        node_name = socket.gethostname()
        job_id = os.environ.get('SLURM_JOB_ID', 'Interactive')

        print(f"\nğŸš€ [Job {job_id}] GPU Stress Test (Duration: {TARGET_DURATION}s)")
        print(f"ğŸ“ Node: {node_name}")
        print("-" * 65)

        # 2. æª¢æŸ¥ GPU
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            print(f"âœ… GPU Detected: {gpu_name}")
            dev = torch.device("cuda")
        else:
            print("âŒ No GPU found! Running on CPU.")
            dev = torch.device("cpu")

        # 3. æº–å‚™çŸ©é™£
        N = 10000
        print(f"ğŸ”¥ Allocating Tensors ({N}x{N})...")
        a = torch.randn(N, N, device=dev)
        b = torch.randn(N, N, device=dev)

        print(f"â³ Starting Countdown... Press [Ctrl+C] to stop early.")
        print("-" * 65)

        # 4. åŸ·è¡Œè¿´åœˆ
        start_time = time.time()
        count = 0

        try:
            while True:
                # è¨ˆç®—ç¶“éæ™‚é–“
                current_time = time.time()
                elapsed = current_time - start_time
                remaining = TARGET_DURATION - elapsed

                # æ™‚é–“åˆ°å°±è‡ªå‹•è·³å‡º
                if remaining <= 0:
                    break

                # é‹ç®—è² è¼‰
                c = torch.mm(a, b)
                torch.cuda.synchronize() # ç­‰å¾… GPU ç®—å®Œ
                
                count += 1
                
                # å‹•æ…‹é¡¯ç¤ºé€²åº¦æ¢
                # \r å›åˆ°è¡Œé¦–ï¼Œè¦†è“‹èˆŠæ–‡å­—
                sys.stdout.write(f"\râš¡ Batch: {count} | â±ï¸ Used: {elapsed:4.1f}s | â³ Left: {remaining:4.1f}s ")
                sys.stdout.flush()

        except KeyboardInterrupt:
            print("\n\nğŸ›‘ Test Stopped by User (Ctrl+C).")
        
        # 5. çµç®—
        final_time = time.time() - start_time
        print(f"\n\n" + "="* 65)
        print(f"âœ… Test Finished in {final_time:.2f} seconds.")
        print(f"ğŸ“Š Total Batches Processed: {count}")
        print("="* 65 + "\n")
        PY
          
          kubectl cp /tmp/train.py {{ slurm_ns }}/{{ controller_pod }}:{{ shared_dir }}/train.py
        EOS
