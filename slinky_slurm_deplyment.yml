---
# ==========================================
# SKU: Slinky-K8s-v1.6-Remote-Exec
# ç‰¹é»ï¼š
#   1. å®Œå…¨ä¸å‹• maasjuju (ä¸è£ Python åº«ï¼Œä¸æ”¹ Kubeconfig)
#   2. é€é juju ssh åœ¨ Master ç¯€é»å…§éƒ¨åŸ·è¡Œ kubectl
#   3. ç¢ºä¿ Local Path è£åœ¨æ­£ç¢ºçš„æ–°å¢é›†ä¸Š
# ==========================================
- name: Infrastructure Test - Deploy Modern Charmed Kubernetes
  hosts: maasjuju
  gather_facts: yes
  vars:
    test_model: "slinky-cluster"
    k8s_channel: "1.31/stable"
    bundle_path: "{{ ansible_user_dir }}/charmed-k8s-modern.yaml"

  tasks:
    # 1. ç’°å¢ƒæ¸…ç†
    - name: 1.0 å¼·åˆ¶æ¸…ç†èˆŠæ¨¡å‹
      command: "juju destroy-model {{ test_model }} --no-prompt --force --destroy-storage"
      register: destroy_result
      failed_when: 
        - destroy_result.rc != 0 
        - '"not found" not in destroy_result.stderr'
      ignore_errors: yes

    - name: 1.1 ç­‰å¾…æ¨¡å‹é‡‹æ”¾
      pause:
        seconds: 15

    - name: 1.2 å»ºç«‹å…¨æ–° Juju Model
      shell: juju add-model {{ test_model }}

    # 2. è£½ä½œè—åœ–
    - name: 2.0 æ¸…é™¤èˆŠçš„ Bundle æª”æ¡ˆ
      become: yes
      file:
        path: "{{ bundle_path }}"
        state: absent
        
    - name: 2.1 ç”¢ç”Ÿæœ¬åœ° Bundle æª”æ¡ˆ
      copy:
        dest: "{{ bundle_path }}"
        mode: '0644'
        content: |
          description: Slinky Modern K8s Cluster
          base: ubuntu@22.04
          
          machines:
            "0":
              constraints: tags=virtual
            "1":
              constraints: tags=slurm-node

          applications:
            easyrsa:
              charm: easyrsa
              channel: latest/stable
              num_units: 1
              to: ["0"]
            
            etcd:
              charm: etcd
              channel: latest/stable
              num_units: 1
              to: ["0"]

            kubernetes-control-plane:
              charm: kubernetes-control-plane
              channel: {{ k8s_channel }}
              num_units: 1
              to: ["0"]
              options:
                allow-privileged: "true"

            kubernetes-worker:
              charm: kubernetes-worker
              channel: {{ k8s_channel }}
              num_units: 1
              to: ["1"]
              expose: true

            calico:
              charm: calico
              channel: latest/stable
              
            containerd:
              charm: containerd
              channel: latest/stable

          relations:
            - ["kubernetes-control-plane:kube-control", "kubernetes-worker:kube-control"]
            - ["kubernetes-control-plane:certificates", "easyrsa:client"]
            - ["etcd:certificates", "easyrsa:client"]
            - ["kubernetes-control-plane:etcd", "etcd:db"]
            - ["kubernetes-worker:certificates", "easyrsa:client"]
            - ["calico:etcd", "etcd:db"]
            - ["calico:cni", "kubernetes-control-plane:cni"]
            - ["calico:cni", "kubernetes-worker:cni"]
            - ["containerd:containerd", "kubernetes-worker:container-runtime"]
            - ["containerd:containerd", "kubernetes-control-plane:container-runtime"]

    # 3. åŸ·è¡Œéƒ¨ç½²
    - name: 3.1 éƒ¨ç½² Bundle
      shell: |
        juju deploy {{ bundle_path }} --model {{ test_model }} --trust
      register: deploy_out
      until: deploy_out.rc == 0
      retries: 3
      delay: 10

    # -----------------------------------------------------------
    # 4. ç›£æ§ (ç„¡é™ç­‰å¾…ç‰ˆ)
    # -----------------------------------------------------------
    - name: 4.1 ç­‰å¾… K8s ç‹€æ…‹è®Šç‚º Active
      shell: |
        echo "â³ é€²å…¥ç„¡é™ç›£æ¸¬æ¨¡å¼... (è«‹æ‰‹å‹•ç›£æ§ juju status)"
        
        while true; do
          STATUS=$(juju status --model {{ test_model }} --format json | jq -r '.applications["kubernetes-worker"]["application-status"].current')
          CP_STATUS=$(juju status --model {{ test_model }} --format json | jq -r '.applications["kubernetes-control-plane"]["application-status"].current')

          if [ "$STATUS" == "active" ] && [ "$CP_STATUS" == "active" ]; then
            echo "âœ… Kubernetes Cluster is Ready!"
            exit 0
          fi
          sleep 10
        done
      args:
        executable: /bin/bash
      register: k8s_wait_result
      changed_when: false 

    # -----------------------------------------------------------
    # 5. Local Path Provisioner (é ç«¯åŸ·è¡Œ - ä¸å‹• maasjuju)
    # -----------------------------------------------------------
    # [ä¿®æ­£é‡é»]
    # 1. ç§»é™¤äº†æ‰€æœ‰ pip/apt å®‰è£æ­¥é©Ÿ (Task 4.2 å·²åˆªé™¤)
    # 2. æ”¹ç”¨ juju ssh åˆ° Machine 0 å…§éƒ¨åŸ·è¡Œ kubectl
    # 3. é€™æ¨£ maasjuju ä¸éœ€è¦ä»»ä½• K8s è¨­å®šï¼Œä¹Ÿä¸æœƒè£éŒ¯åˆ°èˆŠå¢é›†
    
    - name: 5.1 å®‰è£ Local Path Provisioner (Remote Exec)
      shell: |
        juju ssh --model {{ test_model }} 0 -- \
        "kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.30/deploy/local-path-storage.yaml"
      register: install_sc
      # ç‚ºäº†è®“ Ansible é¡¯ç¤º changed ç‹€æ…‹ï¼Œæˆ‘å€‘ç°¡å–®åˆ¤æ–·è¼¸å‡º
      changed_when: "'created' in install_sc.stdout or 'configured' in install_sc.stdout"

    - name: 5.2 è¨­å®šç‚ºé è¨­ StorageClass (Remote Exec)
      shell: |
        juju ssh --model {{ test_model }} 0 -- \
        "kubectl patch storageclass local-path -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}'"
      register: patch_sc
      changed_when: "'patched' in patch_sc.stdout"

    - name: âœ… éƒ¨ç½²å®Œæˆ
      debug:
        msg: "Charmed Kubernetes å·²æˆåŠŸéƒ¨ç½²ã€‚StorageClass å·²é€é Machine 0 å…§éƒ¨æŒ‡ä»¤å®Œæˆé…ç½®ï¼Œæœªæ›´å‹• maasjuju ç’°å¢ƒã€‚"



# -----------------------------------------------------------
# GATE) Wait cluster fully ready (Juju active + K8s nodes/pods ready)
# - ä¸å‹• maasjuju çš„ kubeconfig
# - å…¨éƒ¨é€é juju ssh åˆ° machine0 å…§éƒ¨åŸ·è¡Œ
# -----------------------------------------------------------
- name: GATE - Wait Juju apps active (control-plane/worker/calico/containerd)
  shell: |
    set -euo pipefail
    for i in $(seq 1 240); do
      j=$(juju status --model {{ test_model }} --format json)

      cp=$(echo "$j" | jq -r '.applications["kubernetes-control-plane"]["application-status"].current // "unknown"')
      wk=$(echo "$j" | jq -r '.applications["kubernetes-worker"]["application-status"].current // "unknown"')
      ca=$(echo "$j" | jq -r '.applications["calico"]["application-status"].current // "unknown"')
      cd=$(echo "$j" | jq -r '.applications["containerd"]["application-status"].current // "unknown"')

      echo "[Juju] cp=$cp worker=$wk calico=$ca containerd=$cd (try=$i)"

      if [ "$cp" = "active" ] && [ "$wk" = "active" ] && [ "$ca" = "active" ] && [ "$cd" = "active" ]; then
        echo "âœ… Juju layer active"
        exit 0
      fi
      sleep 5
    done
    echo "âŒ Timeout waiting Juju apps active"
    juju status --model {{ test_model }} --color || true
    exit 1
  args:
    executable: /bin/bash
  changed_when: false

- name: GATE - Wait K8s nodes Ready + kube-system core pods Ready (remote exec on machine0)
  shell: |
    juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
    set -euo pipefail

    echo "== nodes =="
    kubectl get nodes -o wide

    echo "[WAIT] nodes Ready..."
    kubectl wait node/{{ controlplane_hostname }} --for=condition=Ready --timeout=900s
    kubectl wait node/{{ gpu_node_hostname }}     --for=condition=Ready --timeout=900s

    echo
    echo "== kube-system pods (non-Running) =="
    kubectl -n kube-system get pods | egrep -v "Running|Completed" || true

    echo "[WAIT] calico-node Ready..."
    kubectl -n kube-system wait pod -l k8s-app=calico-node --for=condition=Ready --timeout=900s

    # coredns label å¯èƒ½æ˜¯ k8s-app=kube-dns æˆ– k8s-app=corednsï¼Œå…©å€‹éƒ½è©¦ï¼Œé¿å…å¡æ­»
    echo "[WAIT] coredns/kube-dns Ready..."
    kubectl -n kube-system wait pod -l k8s-app=kube-dns --for=condition=Ready --timeout=600s 2>/dev/null || \
    kubectl -n kube-system wait pod -l k8s-app=coredns  --for=condition=Ready --timeout=600s 2>/dev/null || true

    echo
    echo "âœ… K8s layer ready"
    kubectl get nodes -o wide
    kubectl -n kube-system get pods -o wide
    EOS
  changed_when: false

# ========================================================
# SKU: Slinky-SlurmOnK8s-Standardized (Merged, Repeatable)
#
# Two-mode:
#   reset_before_install=true  : clean rebuild (testing)
#   reset_before_install=false : normal upgrade (daily)
#
# Includes:
#   1) NFS server (machine0) + nfs-subdir-external-provisioner + StorageClass
#   2) NVIDIA k8s-device-plugin (Helm) with tolerations + nodeSelector + affinity={}
#   3) cert-manager + slurm-operator-crds + slurm-operator + slurm (OCI chart)
#
# Pitfalls avoided:
#   - NEVER kubectl patch Controller.extraConf (Helm conflict)
#   - Partitions do NOT depend on Feature
#   - Device-plugin MUST toleration + nodeSelector; also clear affinity to avoid NFD dependency
# ========================================================

- name: Application Layer - Deploy Slinky Slurm on K8s (Standardized Merged)
  hosts: maasjuju
  gather_facts: yes

  vars:
    # ---- Mode ----
    reset_before_install: true

    # ---- Juju / machines ----
    test_model: "slinky-cluster"
    machine0: "0"                 # control-plane node (slurmhn)
    machine1: "1"                 # gpu worker node (gpu-node01)

    # ---- K8s nodes ----
    controlplane_hostname: "slurmhn"
    gpu_node_hostname: "gpu-node01"

    # ---- Namespaces ----
    ns_nfs: "nfs-provisioner"
    ns_nvidia: "nvidia-device-plugin"
    ns_certmgr: "cert-manager"
    ns_slurm_operator: "slinky"
    ns_slurm: "slurm"

    # ---- NFS (server on machine0) ----
    nfs_server_setup: true
    nfs_server: ""                # leave empty => use machine0_ip
    nfs_export_path: "/srv/nfs/k8s"
    nfs_storageclass: "nfs-rwx"
    nfs_make_default_sc: false     # if you want nfs-rwx as default SC => true

    # ---- NVIDIA device plugin ----
    gpu_taint_key: "node-role.anxpert/gpu"
    gpu_taint_value: "true"
    slurm_gpu_count: 1

    # ---- Versions ----
    cert_manager_chart_version: "v1.19.2"
    slurm_operator_chart_ver: "1.0.1"
    slurm_chart_ver: "1.0.1"

  tasks:
    # -----------------------------------------------------------
    # 1) Discover machine IPs from Juju
    # -----------------------------------------------------------
    - name: 1.1 Get Juju model status (json)
      shell: "juju status --model {{ test_model }} --format json"
      register: juju_status_raw
      changed_when: false

    - name: 1.2 Parse machine0/machine1 IPv4
      set_fact:
        machine0_ip: "{{ (juju_status_raw.stdout | from_json).machines[machine0]['ip-addresses'] | select('match','^[0-9.]+$') | first }}"
        machine1_ip: "{{ (juju_status_raw.stdout | from_json).machines[machine1]['ip-addresses'] | select('match','^[0-9.]+$') | first }}"

    - name: 1.3 Show discovered IPs
      debug:
        msg:
          - "Machine0 (control-plane) IP: {{ machine0_ip }}"
          - "Machine1 (gpu worker)    IP: {{ machine1_ip }}"

    - name: 1.4 Decide NFS server IP
      set_fact:
        nfs_server_ip: "{{ (nfs_server | trim) if (nfs_server | trim != '') else machine0_ip }}"

    # -----------------------------------------------------------
    # 2) Ensure Helm exists on machine0
    # -----------------------------------------------------------
    - name: 2.1 Install Helm on machine0 if missing
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -e
          if ! command -v helm >/dev/null 2>&1; then
            echo "[INFO] Installing Helm..."
            curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          else
            echo "[INFO] Helm already installed"
          fi
        '
      changed_when: false

    # -----------------------------------------------------------
    # 0) Reset (two-mode)
    # -----------------------------------------------------------
    - name: 0.1 Reset (helm uninstall releases)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set +e
          echo "[RESET] uninstall releases..."
          helm -n {{ ns_slurm }} uninstall slurm 2>/dev/null || true
          helm -n {{ ns_slurm_operator }} uninstall slurm-operator 2>/dev/null || true
          helm -n default uninstall slurm-operator-crds 2>/dev/null || true
          helm -n {{ ns_certmgr }} uninstall cert-manager 2>/dev/null || true
          helm -n {{ ns_nvidia }} uninstall nvidia-device-plugin 2>/dev/null || true
          helm -n {{ ns_nfs }} uninstall nfs-provisioner 2>/dev/null || true
        '
      when: reset_before_install | bool
      changed_when: true

    - name: 0.2 Reset (delete namespaces)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set +e
          echo "[RESET] delete namespaces..."
          kubectl delete ns {{ ns_slurm }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_slurm_operator }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_certmgr }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_nvidia }} --ignore-not-found=true --wait=true || true
          kubectl delete ns {{ ns_nfs }} --ignore-not-found=true --wait=true || true
        '
      when: reset_before_install | bool
      changed_when: true

    # -----------------------------------------------------------
    # 3.0 Install NFS client utils on ALL nodes (IMPORTANT)
    # - Fix: mount: bad option ... need /sbin/mount.nfs
    # -----------------------------------------------------------
    - name: 3.0 Setup NFS server export on machine0 (robust)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
        set -euo pipefail
        export DEBIAN_FRONTEND=noninteractive NEEDRESTART_MODE=a

        sudo -n true

        echo "[INFO] wait dpkg lock..."
        while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
          echo "[WAIT] dpkg lock held..."; sleep 5
        done

        timeout 600 sudo apt-get -o Acquire::ForceIPv4=true update -y

        while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
          echo "[WAIT] dpkg lock held..."; sleep 5
        done

        timeout 600 sudo apt-get -o Acquire::ForceIPv4=true install -y nfs-kernel-server

        sudo mkdir -p {{ nfs_export_path }}
        sudo chmod 777 {{ nfs_export_path }}
        sudo mkdir -p /etc/exports.d

        # MUST exist, or exportfs will complain
        sudo touch /etc/exports
        sudo chmod 644 /etc/exports

        EXPORT_LINE="{{ nfs_export_path }} *(rw,sync,no_subtree_check,no_root_squash)"
        echo "$EXPORT_LINE" | sudo tee /etc/exports.d/k8s.exports >/dev/null

        sudo exportfs -ra
        timeout 60 sudo systemctl enable --now nfs-server

        echo "[INFO] exportfs:"
        sudo exportfs -v | sed -n "1,120p"
        EOS
      when: nfs_server_setup | bool
      changed_when: true

    - name: 3.1 Install nfs-common on k8s nodes (required for NFS mounts) - robust + wait dpkg lock
      shell: |
        juju ssh --model {{ test_model }} {{ item }} -- bash -s <<'EOS'
        set -euo pipefail
        export DEBIAN_FRONTEND=noninteractive NEEDRESTART_MODE=a
    
        sudo -n true
    
        echo "[INFO] wait dpkg/apt lock (unattended-upgrades)..."
        while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
          echo "[WAIT] dpkg lock held..."; sleep 5
        done
    
        timeout 600 sudo apt-get -o Acquire::ForceIPv4=true update -y
    
        while sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do
          echo "[WAIT] dpkg lock held..."; sleep 5
        done
    
        timeout 600 sudo apt-get -o Acquire::ForceIPv4=true install -y nfs-common
    
        command -v mount.nfs || ls -l /sbin/mount.nfs* || true
        EOS
      loop:
        - "{{ machine0 }}"
        - "{{ machine1 }}"
      changed_when: true

    # -----------------------------------------------------------
    # 4) Install NFS provisioner (no heredoc)
    # -----------------------------------------------------------
    - name: 4.1 Create namespace for NFS provisioner
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          kubectl create ns {{ ns_nfs }} --dry-run=client -o yaml | kubectl apply -f -
        '
      changed_when: false

    - name: 4.2 Install/upgrade nfs-subdir-external-provisioner via Helm (values file via printf)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -euo pipefail
          helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/ >/dev/null 2>&1 || true
          helm repo update >/dev/null 2>&1

          f=/tmp/nfs-values.yaml
          : > $f
          printf "nfs:\n" >> $f
          printf "  server: %s\n" "{{ nfs_server_ip }}" >> $f
          printf "  path: %s\n" "{{ nfs_export_path }}" >> $f
          printf "storageClass:\n" >> $f
          printf "  name: %s\n" "{{ nfs_storageclass }}" >> $f
          printf "  defaultClass: %s\n" "{{ (nfs_make_default_sc | bool) | lower }}" >> $f
          printf "  reclaimPolicy: Delete\n" >> $f
          printf "  archiveOnDelete: true\n" >> $f

          helm upgrade --install nfs-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \
            -n {{ ns_nfs }} --create-namespace \
            -f $f

          echo "[INFO] storageclass:"
          kubectl get sc | sed -n "1,120p"
        '
      changed_when: true

    # -----------------------------------------------------------
    # [æ–°å¢] 4.5 å®‰è£ NVIDIA Container Toolkit (Host Level)
    # é€™æ˜¯ç‚ºäº†è®“ Containerd çŸ¥é“å¦‚ä½•æŠŠ GPU æ›é€²å®¹å™¨
    # æ³¨æ„ï¼šç›®æ¨™æ˜¯ machine1 (GPU Node)ï¼Œä¸æ˜¯ machine0
    # -----------------------------------------------------------
    - name: 4.5 Install NVIDIA Container Toolkit on GPU Node (Machine 1)
      shell: |
        juju ssh --model {{ test_model }} {{ machine1 }} -- bash -lc '
          set -e
          
          # 1. æª¢æŸ¥æ˜¯å¦å·²å®‰è£ï¼Œé¿å…é‡è¤‡åŸ·è¡Œ (å†ªç­‰æ€§æª¢æŸ¥)
          if dpkg -l | grep -q nvidia-container-toolkit; then
            echo "[INFO] Toolkit already installed."
            # æª¢æŸ¥ config æ˜¯å¦å·²ç¶“ä¿®æ”¹é
            if grep -q "nvidia-container-runtime" /etc/containerd/config.toml; then
               echo "[INFO] Containerd already configured."
               exit 0
            fi
          fi

          echo "[INFO] Installing NVIDIA Container Toolkit..."
          curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
          
          curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
            sed "s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g" | \
            sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

          sudo apt-get update
          sudo apt-get install -y nvidia-container-toolkit

          echo "[INFO] Configuring containerd to use NVIDIA runtime..."
          # é€™è¡ŒæŒ‡ä»¤æœƒè‡ªå‹•ä¿®æ”¹ /etc/containerd/config.toml
          sudo nvidia-ctk runtime configure --runtime=containerd
          
          echo "[INFO] Restarting containerd..."
          sudo systemctl restart containerd
          
          echo "[INFO] Done. GPU Node is ready for passthrough."
        '
      changed_when: true

    # -----------------------------------------------------------
    # 5) NVIDIA device plugin (Aæ–¹æ¡ˆï¼šæ¸…ç©º affinityï¼Œé¿å… NFD ä¾è³´)
    # -----------------------------------------------------------
    - name: 5.0 Precheck gpu node labels/taints
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -e
          echo "== gpu node labels =="
          kubectl get node {{ gpu_node_hostname }} --show-labels | tr "," "\n" | egrep -n "kubernetes.io/hostname|hostname" || true
          echo
          echo "== gpu node taints =="
          kubectl describe node {{ gpu_node_hostname }} | egrep -n "Taints:" -A2 || true
        '
      changed_when: false

    - name: 5.1 Create namespace for NVIDIA device plugin
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          kubectl create ns {{ ns_nvidia }} --dry-run=client -o yaml | kubectl apply -f -
        '
      changed_when: false

    - name: "5.2 Install/upgrade NVIDIA device plugin (hostname pin + override default affinity)"
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -euo pipefail
    
          helm repo add nvidia https://nvidia.github.io/k8s-device-plugin >/dev/null 2>&1 || true
          helm repo update >/dev/null 2>&1
    
          f=/tmp/nvidia-values.yaml
          : > "$f"
          w(){ printf "%s\n" "$1" >> "$f"; }
    
          # ç›®çš„ï¼š
          # 1) ç”¨ hostname nodeAffinity è¦†è“‹ chart é è¨­çš„ feature.node.kubernetes.io/* è¦å‰‡
          # 2) å†ç”¨ nodeSelector ç¶æ­» gpu-node01
          # 3) tolerations å¯ç•™ï¼ˆå³ä½¿ node æ²’ taint ä¹Ÿä¸å½±éŸ¿ï¼‰
          w "affinity:"
          w "  nodeAffinity:"
          w "    requiredDuringSchedulingIgnoredDuringExecution:"
          w "      nodeSelectorTerms:"
          w "      - matchExpressions:"
          w "        - key: kubernetes.io/hostname"
          w "          operator: In"
          w "          values:"
          w "          - {{ gpu_node_hostname }}"
          w "nodeSelector:"
          w "  kubernetes.io/hostname: {{ gpu_node_hostname }}"
          w "  kubernetes.io/os: linux"
          w "tolerations:"
          w "- key: {{ gpu_taint_key }}"
          w "  operator: Equal"
          w "  value: \"{{ gpu_taint_value }}\""
          w "  effect: NoSchedule"
    
          echo "== values.yaml (show with line numbers) =="
          nl -ba "$f" | sed -n "1,120p"
    
          echo "== helm upgrade/install =="
          helm upgrade --install nvidia-device-plugin nvidia/nvidia-device-plugin \
            -n {{ ns_nvidia }} --create-namespace \
            --reset-values \
            -f "$f"
    
          echo "== helm status/list =="
          helm -n {{ ns_nvidia }} status nvidia-device-plugin || true
          helm list -n {{ ns_nvidia }} || true
    
          echo "== rollout + resources =="
          kubectl -n {{ ns_nvidia }} rollout status ds/nvidia-device-plugin --timeout=240s
          kubectl -n {{ ns_nvidia }} get ds,pod -o wide
    
          echo "== node gpu capacity/allocatable =="
          kubectl describe node {{ gpu_node_hostname }} | egrep -n "Capacity:|Allocatable:|nvidia.com/gpu" -A6 || true
        '
      changed_when: true

    - name: 5.3 Verify nvidia.com/gpu on gpu node
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -e
          kubectl describe node {{ gpu_node_hostname }} | egrep -n "Taints:|Capacity:|Allocatable:|nvidia.com/gpu" -n
        '
      changed_when: false

    # -----------------------------------------------------------
    # 6) cert-manager
    # -----------------------------------------------------------
    - name: 6.1 Create namespace cert-manager
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          kubectl create ns {{ ns_certmgr }} --dry-run=client -o yaml | kubectl apply -f -
        '
      changed_when: false

    - name: 6.2 Install/upgrade cert-manager via Helm
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -euo pipefail
          helm repo add jetstack https://charts.jetstack.io >/dev/null 2>&1 || true
          helm repo update >/dev/null 2>&1

          helm upgrade --install cert-manager jetstack/cert-manager \
            -n {{ ns_certmgr }} --create-namespace \
            --version {{ cert_manager_chart_version }} \
            --set crds.enabled=true

          kubectl -n {{ ns_certmgr }} rollout status deploy/cert-manager --timeout=240s
          kubectl -n {{ ns_certmgr }} rollout status deploy/cert-manager-webhook --timeout=240s
          kubectl -n {{ ns_certmgr }} rollout status deploy/cert-manager-cainjector --timeout=240s
        '
      changed_when: true

    # -----------------------------------------------------------
    # 7) slurm-operator-crds + slurm-operator (OCI charts)
    # -----------------------------------------------------------
    - name: 7.1 Create namespace for slurm operator
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          kubectl create ns {{ ns_slurm_operator }} --dry-run=client -o yaml | kubectl apply -f -
        '
      changed_when: false

    - name: 7.2 Install/upgrade slurm-operator-crds (OCI)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -euo pipefail
          helm upgrade --install slurm-operator-crds oci://ghcr.io/slinkyproject/charts/slurm-operator-crds \
            -n default --create-namespace \
            --version {{ slurm_operator_chart_ver }}
        '
      changed_when: true

    - name: 7.3 Install/upgrade slurm-operator (OCI)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -euo pipefail
          helm upgrade --install slurm-operator oci://ghcr.io/slinkyproject/charts/slurm-operator \
            -n {{ ns_slurm_operator }} --create-namespace \
            --version {{ slurm_operator_chart_ver }}

          kubectl -n {{ ns_slurm_operator }} rollout status deploy/slurm-operator --timeout=240s
        '
      changed_when: true

    - name: 7.4 Wait for Slurm Operator Webhook endpoints (robust)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
        set -euo pipefail
        NS="{{ ns_slurm_operator }}"
    
        echo "[INFO] wait webhook deployment ready..."
        kubectl -n "$NS" rollout status deploy/slurm-operator-webhook --timeout=300s || true
    
        echo "[INFO] discover webhook service..."
        SVC=$(kubectl -n "$NS" get svc -o name | grep -i webhook | head -n1 | cut -d/ -f2 || true)
        if [ -z "$SVC" ]; then
          echo "[FAIL] no webhook service found"
          kubectl -n "$NS" get svc -o wide || true
          exit 1
        fi
        echo "[INFO] webhook svc=$SVC"
    
        echo "[INFO] wait endpoints..."
        for i in {1..120}; do
          EP=$(kubectl -n "$NS" get ep "$SVC" -o jsonpath="{.subsets[*].addresses[*].ip}" 2>/dev/null || true)
          if [ -n "$EP" ]; then
            echo "âœ… Webhook endpoints ready: $EP"
            exit 0
          fi
          echo "â³ waiting endpoints... ($i/120)"
          sleep 5
        done
    
        echo "âŒ timeout"
        kubectl -n "$NS" get pods,svc,ep -o wide || true
        kubectl -n "$NS" get events --sort-by=.lastTimestamp | tail -n 60 || true
        exit 1
        EOS
      changed_when: false

    # -----------------------------------------------------------
    # 8) slurm chart (OCI)
    # -----------------------------------------------------------
    - name: 8.1 Create namespace slurm
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          kubectl create ns {{ ns_slurm }} --dry-run=client -o yaml | kubectl apply -f -
        '
      changed_when: false

    - name: 8.2 Install/upgrade slurm chart (OCI) - Pin controller/restapi to slurmhn, worker to gpu-node01 (no patch; fix dup partition; force tcpSocket probes; wait webhook)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
        set -euo pipefail
    
        NS="{{ ns_slurm }}"
        CHART_VER="{{ slurm_chart_ver }}"
    
        echo "[INFO] Write values.yaml ..."
        cat > /tmp/slurm-values.yaml <<EOF
        controller:
          persistence:
            enabled: true
            storageClassName: "{{ nfs_storageclass }}"
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 10Gi
    
          # é€™è¡Œæœƒåœ¨ log å‡ºç¾ã€ŒGresTypes é‡è¤‡ã€(éè‡´å‘½)ï¼›è‹¥ä½ æƒ³æ¶ˆæ‰ï¼Œå°±æŠŠé€™æ®µæ•´æ®µæ‹¿æ‰
          extraConf: |
            GresTypes=gpu
    
          podSpec:
            nodeSelector:
              kubernetes.io/hostname: {{ controlplane_hostname }}
              kubernetes.io/os: linux
            tolerations:
              - key: node-role.kubernetes.io/control-plane
                operator: Exists
                effect: NoSchedule
              - key: node-role.kubernetes.io/master
                operator: Exists
                effect: NoSchedule
    
        restapi:
          replicas: 1
          podSpec:
            nodeSelector:
              kubernetes.io/hostname: {{ controlplane_hostname }}
              kubernetes.io/os: linux
            tolerations:
              - key: node-role.kubernetes.io/control-plane
                operator: Exists
                effect: NoSchedule
    
        nodesets:
          slinky:
            enabled: true
    
            # âœ… é—œéµï¼šä½ å·²ç¶“åœ¨ partitions: æ‰‹å‹•å®£å‘Š slinkyï¼Œæ‰€ä»¥è¦é—œæ‰ nodeset çš„è‡ªå‹•åˆ†å‰²ï¼Œé¿å… PartitionName=slinky é‡è¤‡
            partition:
              enabled: false
    
            useResourceLimits: true
            podSpec:
              nodeSelector:
                kubernetes.io/hostname: {{ gpu_node_hostname }}
                kubernetes.io/os: linux
              tolerations:
                - key: {{ gpu_taint_key }}
                  operator: Equal
                  value: "{{ gpu_taint_value }}"
                  effect: NoSchedule
    
            slurmd:
              resources:
                limits:
                  nvidia.com/gpu: {{ slurm_gpu_count }}
              args:
                - --conf
                - Gres=gpu:{{ slurm_gpu_count }}
    
        partitions:
          all:
            enabled: true
            nodesets: [ALL]
            configMap:
              Default: "YES"
              MaxTime: UNLIMITED
              State: UP
          slinky:
            enabled: true
            nodesets: [ALL]
            configMap:
              Default: "NO"
              MaxTime: UNLIMITED
              State: UP
    
        configFiles:
          gres.conf: |
            AutoDetect=nvidia
        EOF
    
        echo "[INFO] values head:"
        head -n 200 /tmp/slurm-values.yaml
    
        echo "[INFO] Ensure yq in /tmp (no root needed)..."
        if ! [ -x /tmp/yq ]; then
          curl -fsSL -o /tmp/yq https://github.com/mikefarah/yq/releases/download/v4.44.3/yq_linux_amd64
          chmod +x /tmp/yq
        fi
        /tmp/yq --version
    
        echo "[INFO] Write helm post-renderer to force probes tcpSocket..."
        cat > /tmp/slurm-post-renderer.sh <<'SH'
        #!/usr/bin/env bash
        set -euo pipefail
    
        YQ="/tmp/yq"
        tmpdir="$(mktemp -d)"
        trap 'rm -rf "$tmpdir"' EXIT
        in="$tmpdir/in.yaml"
    
        cat > "$in"
    
        "$YQ" eval-all -i '
          (select(.kind=="StatefulSet" and .metadata.name=="slurm-controller")
            .spec.template.spec.containers[] | select(.name=="slurmctld")
          ).startupProbe = {"tcpSocket":{"port":6817},"failureThreshold":240,"periodSeconds":5,"timeoutSeconds":1}
          |
          (select(.kind=="StatefulSet" and .metadata.name=="slurm-controller")
            .spec.template.spec.containers[] | select(.name=="slurmctld")
          ).readinessProbe = {"tcpSocket":{"port":6817},"failureThreshold":24,"periodSeconds":5,"timeoutSeconds":1}
          |
          (select(.kind=="StatefulSet" and .metadata.name=="slurm-controller")
            .spec.template.spec.containers[] | select(.name=="slurmctld")
          ).livenessProbe = {"tcpSocket":{"port":6817},"failureThreshold":12,"periodSeconds":10,"timeoutSeconds":1}
          |
          (select(.kind=="NodeSet" and .metadata.name=="slurm-worker-slinky").spec.slurmd).startupProbe =
            {"tcpSocket":{"port":6818},"failureThreshold":240,"periodSeconds":5,"timeoutSeconds":1}
          |
          (select(.kind=="NodeSet" and .metadata.name=="slurm-worker-slinky").spec.slurmd).readinessProbe =
            {"tcpSocket":{"port":6818},"failureThreshold":24,"periodSeconds":5,"timeoutSeconds":1}
          |
          (select(.kind=="NodeSet" and .metadata.name=="slurm-worker-slinky").spec.slurmd).livenessProbe =
            {"tcpSocket":{"port":6818},"failureThreshold":12,"periodSeconds":10,"timeoutSeconds":1}
        ' "$in"
    
        cat "$in"
        SH
        chmod +x /tmp/slurm-post-renderer.sh
    
        echo "[INFO] Wait slurm-operator webhook ready (avoid TLS not yet valid)..."
        # å…ˆç­‰ webhook deployment ready
        for i in 1 2 3 4 5 6; do
          if kubectl -n slinky get deploy slurm-operator-webhook >/dev/null 2>&1; then
            kubectl -n slinky rollout status deploy/slurm-operator-webhook --timeout=60s && break || true
          fi
          sleep 5
        done
        # ä½ é‡åˆ°çš„æ˜¯ notBefore å·®å¹¾ç§’ï¼Œé¡å¤–å†ç­‰ä¸€ä¸‹è·¨éå®ƒ
        sleep 5
    
        echo "[INFO] Helm upgrade/install (with post-renderer)..."
        # notBefore ä»å¯èƒ½å·®å¹¾ç§’ï¼Œåš retry æœ€ä¿éšª
        for try in 1 2 3 4 5; do
          set +e
          helm upgrade --install slurm oci://ghcr.io/slinkyproject/charts/slurm \
            -n "$NS" --create-namespace \
            --version "$CHART_VER" \
            -f /tmp/slurm-values.yaml \
            --post-renderer /tmp/slurm-post-renderer.sh \
            --wait --timeout=600s
          rc=$?
          set -e
          if [ "$rc" -eq 0 ]; then
            break
          fi
          echo "[WARN] helm failed (try=$try rc=$rc), sleep 5s then retry..."
          sleep 5
        done
    
        echo "[INFO] Verify probes rendered in manifest:"
        helm -n "$NS" get manifest slurm | egrep -n "kind: StatefulSet|name: slurm-controller|startupProbe:|readinessProbe:|livenessProbe:|httpGet:|tcpSocket:" | head -n 260
    
        echo "[INFO] Pods:"
        kubectl -n "$NS" get pods -o wide
        EOS
      changed_when: true

    # -----------------------------------------------------------
    # 8.25 Verify worker got correct gres.conf and GPU device (K8s layer only)
    # -----------------------------------------------------------
    - name: 8.25 Verify worker Ready + gres.conf + /dev/nvidia0 (no srun here)
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
        set -euo pipefail
    
        NS="{{ ns_slurm }}"
        WRK="slurm-worker-slinky-0"
    
        echo "[INFO] wait worker Ready..."
        kubectl -n "$NS" wait --for=condition=Ready pod/"$WRK" --timeout=300s
    
        echo
        echo "[CHECK] worker gres.conf:"
        kubectl -n "$NS" exec "$WRK" -c slurmd -- cat /run/slurm/conf/gres.conf
    
        echo
        echo "[CHECK] worker /dev/nvidia0:"
        kubectl -n "$NS" exec "$WRK" -c slurmd -- ls -l /dev/nvidia0
    
        echo
        echo "[CHECK] node GPU capacity (k8s):"
        kubectl describe node {{ gpu_node_hostname }} | egrep -n "Capacity:|Allocatable:|nvidia.com/gpu" -A6 || true
        EOS
      changed_when: false

    # -----------------------------------------------------------
    # 9) Restart controller + worker (Robust check)
    # -----------------------------------------------------------
    - name: 9.1 Restart slurm pods and Wait for Ready
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -lc '
          set -e
          echo "[INFO] 1. Deleting old pods..."
          kubectl -n {{ ns_slurm }} delete pod slurm-controller-0 --ignore-not-found=true --wait=true
          kubectl -n {{ ns_slurm }} delete pod slurm-worker-slinky-0 --ignore-not-found=true --wait=true

          echo "[INFO] 2. Waiting for StatefulSet to recreate pods..."
          sleep 10

          echo "[INFO] 3. Waiting for pods to become Ready..."
          # å¦‚æœé€™è£¡é‚„å¤±æ•—ï¼Œæœƒè‡ªå‹•å°å‡ºç‹€æ…‹
          if ! kubectl -n {{ ns_slurm }} wait --for=condition=Ready pod/slurm-controller-0 --timeout=300s; then
             echo "DEBUG: Controller Failed. PVC Status:"
             kubectl -n {{ ns_slurm }} get pvc
             exit 1
          fi

          if ! kubectl -n {{ ns_slurm }} wait --for=condition=Ready pod/slurm-worker-slinky-0 --timeout=300s; then
             echo "DEBUG: Worker Failed. Describe:"
             kubectl -n {{ ns_slurm }} describe pod slurm-worker-slinky-0
             exit 1
          fi

          echo "ğŸ‰ All Pods Ready!"
          kubectl -n {{ ns_slurm }} get pods -o wide
        '
      changed_when: true

    # -----------------------------------------------------------
    # 10.1 Verify partitions/nodes/GRES and run GPU job (Slurm layer)
    # - robust: use srun --wrap (avoid nested bash -lc quoting issues)
    # - bounded: --time + --immediate
    # - cleanup: scancel old gpu-smoke-* jobs
    # -----------------------------------------------------------
    - name: 10.1 Verify partitions/nodes/GRES and run GPU job (inside slurmctld) - robust (no --wrap) + cleanup
      shell: |
        juju ssh --model {{ test_model }} {{ machine0 }} -- bash -s <<'EOS'
        set -euo pipefail
    
        NS="{{ ns_slurm }}"
        CTL="slurm-controller-0"
        GPU_CNT="{{ slurm_gpu_count | default(1) }}"
    
        echo "== sinfo (brief) =="
        kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc 'sinfo -o "%P %a %l %D %t %N"'
    
        echo
        echo "== slurm.conf partitions =="
        kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc 'grep -n "^PartitionName=" /etc/slurm/slurm.conf 2>/dev/null || true'
    
        echo
        echo "== node GRES / TRES (from slurmctld) =="
        kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc 'scontrol show node slinky-0 | egrep -i "NodeName=|State=|Reason=|Gres=|CfgTRES=|AllocTRES="'
    
        echo
        echo "== cleanup old test jobs (by name gpu-smoke-*) =="
        kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc '
          squeue -u slurm -o "%.18i %.9P %.16j %.8u %.2t %.10M %.6D %R" || true
          scancel -u slurm -n gpu-smoke-all     >/dev/null 2>&1 || true
          scancel -u slurm -n gpu-smoke-slinky  >/dev/null 2>&1 || true
          squeue -u slurm -o "%.18i %.9P %.16j %.8u %.2t %.10M %.6D %R" || true
        '
    
        echo
        echo "== srun GPU test (default partition=all) [bounded] =="
        kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc "
          timeout 90s srun -N1 -n1 --job-name=gpu-smoke-all \
            --mpi=none \
            --gres=gpu:${GPU_CNT} --time=00:01:00 --immediate=30 \
            bash -lc 'hostname; ls -l /dev/nvidia0 || true; echo GPU_OK_all'
        "
    
        echo
        echo "== srun GPU test (partition=slinky) [bounded] =="
        kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc "
          timeout 90s srun -p slinky -N1 -n1 --job-name=gpu-smoke-slinky \
            --mpi=none \
            --gres=gpu:${GPU_CNT} --time=00:01:00 --immediate=30 \
            bash -lc 'hostname; ls -l /dev/nvidia0 || true; echo GPU_OK_slinky'
        "
    
        echo
        echo "== final squeue =="
        kubectl -n "$NS" exec "$CTL" -c slurmctld -- bash -lc 'squeue -u slurm -o "%.18i %.9P %.16j %.8u %.2t %.10M %.6D %R" || true'
        EOS
      changed_when: false

    - name: Done
      debug:
        msg:
          - "ğŸ‰ Standardized Slinky Slurm on K8s deployed"
          - "Mode reset_before_install={{ reset_before_install }}"
          - "NFS SC={{ nfs_storageclass }} (default={{ nfs_make_default_sc }})"
          - "NVIDIA device-plugin ns={{ ns_nvidia }} (nodeSelector={{ gpu_node_hostname }}, toleration {{ gpu_taint_key }}={{ gpu_taint_value }}, affinity cleared)"
          - "Slurm ns={{ ns_slurm }} partitions=all(default)+slinky, GRES autodetect nvidia"
